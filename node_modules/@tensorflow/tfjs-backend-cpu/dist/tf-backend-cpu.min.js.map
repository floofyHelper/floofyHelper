{"version":3,"file":"tf-backend-cpu.min.js","sources":["../../../../node_modules/tslib/tslib.es6.js","../../../../tfjs-backend-cpu/src/cpu_util.ts","../../../../tfjs-backend-cpu/src/backend_cpu.ts","../../../../tfjs-backend-cpu/src/kernels/Abs.ts","../../../../tfjs-backend-cpu/src/utils/binary_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Complex.ts","../../../../tfjs-backend-cpu/src/utils/zeros_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Identity.ts","../../../../tfjs-backend-cpu/src/kernels/Real.ts","../../../../tfjs-backend-cpu/src/kernels/Cast.ts","../../../../tfjs-backend-cpu/src/utils/binary_utils.ts","../../../../tfjs-backend-cpu/src/kernels/Add.ts","../../../../tfjs-backend-cpu/src/kernels/Bincount_impl.ts","../../../../tfjs-backend-cpu/src/utils/unary_impl.ts","../../../../tfjs-backend-cpu/src/utils/unary_utils.ts","../../../../tfjs-backend-cpu/src/kernels/Ceil.ts","../../../../tfjs-backend-cpu/src/kernels/Concat_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Equal.ts","../../../../tfjs-backend-cpu/src/kernels/Exp.ts","../../../../tfjs-backend-cpu/src/kernels/Expm1.ts","../../../../tfjs-backend-cpu/src/kernels/Floor.ts","../../../../tfjs-backend-cpu/src/kernels/GatherNd_Impl.ts","../../../../tfjs-backend-cpu/src/kernels/GatherV2_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Greater.ts","../../../../tfjs-backend-cpu/src/kernels/GreaterEqual.ts","../../../../tfjs-backend-cpu/src/kernels/Less.ts","../../../../tfjs-backend-cpu/src/kernels/LessEqual.ts","../../../../tfjs-backend-cpu/src/kernels/LinSpace_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Log.ts","../../../../tfjs-backend-cpu/src/kernels/Max_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Maximum.ts","../../../../tfjs-backend-cpu/src/kernels/Minimum.ts","../../../../tfjs-backend-cpu/src/kernels/Multiply.ts","../../../../tfjs-backend-cpu/src/kernels/Neg.ts","../../../../tfjs-backend-cpu/src/kernels/NotEqual.ts","../../../../tfjs-backend-cpu/src/kernels/Transpose_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Transpose.ts","../../../../tfjs-backend-cpu/src/kernels/Prod.ts","../../../../tfjs-backend-cpu/src/kernels/RaggedTensorToTensor_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Range_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Rsqrt.ts","../../../../tfjs-backend-cpu/src/kernels/Scatter_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Sigmoid.ts","../../../../tfjs-backend-cpu/src/kernels/Slice.ts","../../../../tfjs-backend-cpu/src/kernels/SparseFillEmptyRows_impl.ts","../../../../tfjs-backend-cpu/src/kernels/SparseReshape_impl.ts","../../../../tfjs-backend-cpu/src/kernels/SparseSegmentReduction_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Sqrt.ts","../../../../tfjs-backend-cpu/src/kernels/SquaredDifference.ts","../../../../tfjs-backend-cpu/src/kernels/StridedSlice_impl.ts","../../../../tfjs-backend-cpu/src/kernels/StringNGrams_impl.ts","../../../../tfjs-backend-cpu/src/kernels/StringSplit_impl.ts","../../../../tfjs-backend-cpu/src/kernels/StringToHashBucketFast_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Sub.ts","../../../../tfjs-backend-cpu/src/kernels/Tile_impl.ts","../../../../tfjs-backend-cpu/src/kernels/TopK_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Unique_impl.ts","../../../../tfjs-backend-cpu/src/base.ts","../../../../tfjs-backend-cpu/src/kernels/Elu.ts","../../../../tfjs-backend-cpu/src/kernels/LeakyRelu.ts","../../../../tfjs-backend-cpu/src/kernels/Prelu.ts","../../../../tfjs-backend-cpu/src/kernels/Relu.ts","../../../../tfjs-backend-cpu/src/kernels/Relu6.ts","../../../../tfjs-backend-cpu/src/utils/fused_utils.ts","../../../../tfjs-backend-cpu/src/kernels/Reshape.ts","../../../../tfjs-backend-cpu/src/kernels/BatchMatMul.ts","../../../../tfjs-backend-cpu/src/kernels/_FusedMatMul.ts","../../../../tfjs-backend-cpu/src/kernels/Acos.ts","../../../../tfjs-backend-cpu/src/kernels/Acosh.ts","../../../../tfjs-backend-cpu/src/kernels/AddN.ts","../../../../tfjs-backend-cpu/src/kernels/All.ts","../../../../tfjs-backend-cpu/src/kernels/Any.ts","../../../../tfjs-backend-cpu/src/kernels/ArgMax.ts","../../../../tfjs-backend-cpu/src/kernels/ArgMin.ts","../../../../tfjs-backend-cpu/src/kernels/Asin.ts","../../../../tfjs-backend-cpu/src/kernels/Asinh.ts","../../../../tfjs-backend-cpu/src/kernels/Atan.ts","../../../../tfjs-backend-cpu/src/kernels/Atan2.ts","../../../../tfjs-backend-cpu/src/kernels/Atanh.ts","../../../../tfjs-backend-cpu/src/utils/pool_utils.ts","../../../../tfjs-backend-cpu/src/kernels/AvgPool.ts","../../../../tfjs-backend-cpu/src/kernels/AvgPool3D.ts","../../../../tfjs-backend-cpu/src/kernels/AvgPool3DGrad.ts","../../../../tfjs-backend-cpu/src/kernels/AvgPoolGrad.ts","../../../../tfjs-backend-cpu/src/kernels/BatchNorm.ts","../../../../tfjs-backend-cpu/src/kernels/BatchToSpaceND.ts","../../../../tfjs-backend-cpu/src/kernels/Bincount.ts","../../../../tfjs-backend-cpu/src/kernels/BroadcastArgs.ts","../../../../tfjs-backend-cpu/src/kernels/ClipByValue.ts","../../../../tfjs-backend-cpu/src/kernels/ComplexAbs.ts","../../../../tfjs-backend-cpu/src/kernels/Imag.ts","../../../../tfjs-backend-cpu/src/kernels/Concat.ts","../../../../tfjs-backend-cpu/src/kernels/Conv2D.ts","../../../../tfjs-backend-cpu/src/kernels/Conv2DBackpropFilter.ts","../../../../tfjs-backend-cpu/src/kernels/Conv2DBackpropInput.ts","../../../../tfjs-backend-cpu/src/kernels/Conv3D.ts","../../../../tfjs-backend-cpu/src/kernels/Conv3DBackpropFilterV2.ts","../../../../tfjs-backend-cpu/src/kernels/Conv3DBackpropInputV2.ts","../../../../tfjs-backend-cpu/src/kernels/Cos.ts","../../../../tfjs-backend-cpu/src/kernels/Cosh.ts","../../../../tfjs-backend-cpu/src/kernels/CropAndResize.ts","../../../../tfjs-backend-cpu/src/kernels/Cumprod.ts","../../../../tfjs-backend-cpu/src/kernels/Cumsum.ts","../../../../tfjs-backend-cpu/src/kernels/DenseBincount.ts","../../../../tfjs-backend-cpu/src/kernels/DepthToSpace.ts","../../../../tfjs-backend-cpu/src/kernels/DepthwiseConv2dNative.ts","../../../../tfjs-backend-cpu/src/kernels/DepthwiseConv2dNativeBackpropFilter.ts","../../../../tfjs-backend-cpu/src/kernels/DepthwiseConv2dNativeBackpropInput.ts","../../../../tfjs-backend-cpu/src/kernels/Diag.ts","../../../../tfjs-backend-cpu/src/kernels/Dilation2D.ts","../../../../tfjs-backend-cpu/src/kernels/Dilation2DBackpropFilter.ts","../../../../tfjs-backend-cpu/src/kernels/Dilation2DBackpropInput.ts","../../../../tfjs-backend-cpu/src/kernels/Sum.ts","../../../../tfjs-backend-cpu/src/kernels/Einsum.ts","../../../../tfjs-backend-cpu/src/kernels/EluGrad.ts","../../../../tfjs-backend-cpu/src/kernels/Erf.ts","../../../../tfjs-backend-cpu/src/kernels/ExpandDims.ts","../../../../tfjs-backend-cpu/src/kernels/RealDiv.ts","../../../../tfjs-backend-cpu/src/utils/fft_utils.ts","../../../../tfjs-backend-cpu/src/kernels/FFT.ts","../../../../tfjs-backend-cpu/src/kernels/Fill.ts","../../../../tfjs-backend-cpu/src/kernels/FlipLeftRight.ts","../../../../tfjs-backend-cpu/src/kernels/FloorDiv.ts","../../../../tfjs-backend-cpu/src/kernels/FusedConv2D.ts","../../../../tfjs-backend-cpu/src/kernels/FusedDepthwiseConv2D.ts","../../../../tfjs-backend-cpu/src/kernels/GatherNd.ts","../../../../tfjs-backend-cpu/src/kernels/GatherV2.ts","../../../../tfjs-backend-cpu/src/kernels/IFFT.ts","../../../../tfjs-backend-cpu/src/kernels/IsFinite.ts","../../../../tfjs-backend-cpu/src/kernels/IsInf.ts","../../../../tfjs-backend-cpu/src/kernels/IsNaN.ts","../../../../tfjs-backend-cpu/src/kernels/LinSpace.ts","../../../../tfjs-backend-cpu/src/kernels/Log1p.ts","../../../../tfjs-backend-cpu/src/kernels/LogicalAnd.ts","../../../../tfjs-backend-cpu/src/kernels/LogicalNot.ts","../../../../tfjs-backend-cpu/src/kernels/LogicalOr.ts","../../../../tfjs-backend-cpu/src/kernels/LRN.ts","../../../../tfjs-backend-cpu/src/kernels/LRNGrad.ts","../../../../tfjs-backend-cpu/src/kernels/Max.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPool.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPool3D.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPool3DGrad.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPoolGrad.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPoolWithArgmax.ts","../../../../tfjs-backend-cpu/src/kernels/MaxPoolWithArgmax_impl.ts","../../../../tfjs-backend-cpu/src/kernels/Mean.ts","../../../../tfjs-backend-cpu/src/kernels/Min.ts","../../../../tfjs-backend-cpu/src/kernels/MirrorPad.ts","../../../../tfjs-backend-cpu/src/kernels/Mod.ts","../../../../tfjs-backend-cpu/src/kernels/Softmax.ts","../../../../tfjs-backend-cpu/src/kernels/Multinomial.ts","../../../../tfjs-backend-cpu/src/kernels/NonMaxSuppressionV3.ts","../../../../tfjs-backend-cpu/src/kernels/NonMaxSuppressionV4.ts","../../../../tfjs-backend-cpu/src/kernels/NonMaxSuppressionV5.ts","../../../../tfjs-backend-cpu/src/kernels/OneHot.ts","../../../../tfjs-backend-cpu/src/kernels/ZerosLike.ts","../../../../tfjs-backend-cpu/src/kernels/OnesLike.ts","../../../../tfjs-backend-cpu/src/kernels/Pack.ts","../../../../tfjs-backend-cpu/src/kernels/PadV2.ts","../../../../tfjs-backend-cpu/src/kernels/Pow.ts","../../../../tfjs-backend-cpu/src/kernels/RaggedTensorToTensor.ts","../../../../tfjs-backend-cpu/src/kernels/Range.ts","../../../../tfjs-backend-cpu/src/kernels/Reciprocal.ts","../../../../tfjs-backend-cpu/src/kernels/ResizeBilinear.ts","../../../../tfjs-backend-cpu/src/kernels/ResizeBilinearGrad.ts","../../../../tfjs-backend-cpu/src/kernels/ResizeNearestNeighbor.ts","../../../../tfjs-backend-cpu/src/kernels/ResizeNearestNeighborGrad.ts","../../../../tfjs-backend-cpu/src/kernels/Reverse.ts","../../../../tfjs-backend-cpu/src/kernels/RotateWithOffset.ts","../../../../tfjs-backend-cpu/src/kernels/Round.ts","../../../../tfjs-backend-cpu/src/kernels/ScatterNd.ts","../../../../tfjs-backend-cpu/src/kernels/SearchSorted_impl.ts","../../../../tfjs-backend-cpu/src/kernels/SearchSorted.ts","../../../../tfjs-backend-cpu/src/kernels/Select.ts","../../../../tfjs-backend-cpu/src/kernels/Selu.ts","../../../../tfjs-backend-cpu/src/kernels/Sign.ts","../../../../tfjs-backend-cpu/src/kernels/Sin.ts","../../../../tfjs-backend-cpu/src/kernels/Sinh.ts","../../../../tfjs-backend-cpu/src/kernels/Softplus.ts","../../../../tfjs-backend-cpu/src/kernels/SpaceToBatchND.ts","../../../../tfjs-backend-cpu/src/kernels/SparseFillEmptyRows.ts","../../../../tfjs-backend-cpu/src/kernels/SparseReshape.ts","../../../../tfjs-backend-cpu/src/kernels/SparseSegmentMean.ts","../../../../tfjs-backend-cpu/src/kernels/SparseSegmentSum.ts","../../../../tfjs-backend-cpu/src/kernels/SparseToDense.ts","../../../../tfjs-backend-cpu/src/kernels/SplitV.ts","../../../../tfjs-backend-cpu/src/kernels/Square.ts","../../../../tfjs-backend-cpu/src/kernels/Step.ts","../../../../tfjs-backend-cpu/src/kernels/StridedSlice.ts","../../../../tfjs-backend-cpu/src/kernels/StringNGrams.ts","../../../../tfjs-backend-cpu/src/kernels/StringSplit.ts","../../../../tfjs-backend-cpu/src/kernels/StringToHashBucketFast.ts","../../../../tfjs-backend-cpu/src/kernels/Tan.ts","../../../../tfjs-backend-cpu/src/kernels/Tanh.ts","../../../../tfjs-backend-cpu/src/kernels/Tile.ts","../../../../tfjs-backend-cpu/src/kernels/TopK.ts","../../../../tfjs-backend-cpu/src/kernels/Transform.ts","../../../../tfjs-backend-cpu/src/kernels/Unique.ts","../../../../tfjs-backend-cpu/src/kernels/Unpack.ts","../../../../tfjs-backend-cpu/src/kernels/UnsortedSegmentSum.ts","../../../../tfjs-backend-cpu/src/register_all_kernels.ts","../../../../tfjs-backend-cpu/src/version.ts"],"sourcesContent":["/******************************************************************************\r\nCopyright (c) Microsoft Corporation.\r\n\r\nPermission to use, copy, modify, and/or distribute this software for any\r\npurpose with or without fee is hereby granted.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\r\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\r\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\r\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\r\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\r\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\r\nPERFORMANCE OF THIS SOFTWARE.\r\n***************************************************************************** */\r\n/* global Reflect, Promise */\r\n\r\nvar extendStatics = function(d, b) {\r\n    extendStatics = Object.setPrototypeOf ||\r\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\r\n        function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\r\n    return extendStatics(d, b);\r\n};\r\n\r\nexport function __extends(d, b) {\r\n    if (typeof b !== \"function\" && b !== null)\r\n        throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\r\n    extendStatics(d, b);\r\n    function __() { this.constructor = d; }\r\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\r\n}\r\n\r\nexport var __assign = function() {\r\n    __assign = Object.assign || function __assign(t) {\r\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\r\n            s = arguments[i];\r\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\r\n        }\r\n        return t;\r\n    }\r\n    return __assign.apply(this, arguments);\r\n}\r\n\r\nexport function __rest(s, e) {\r\n    var t = {};\r\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\r\n        t[p] = s[p];\r\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\r\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\r\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\r\n                t[p[i]] = s[p[i]];\r\n        }\r\n    return t;\r\n}\r\n\r\nexport function __decorate(decorators, target, key, desc) {\r\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\r\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\r\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\r\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\r\n}\r\n\r\nexport function __param(paramIndex, decorator) {\r\n    return function (target, key) { decorator(target, key, paramIndex); }\r\n}\r\n\r\nexport function __metadata(metadataKey, metadataValue) {\r\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\r\n}\r\n\r\nexport function __awaiter(thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n}\r\n\r\nexport function __generator(thisArg, body) {\r\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\r\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\r\n    function verb(n) { return function (v) { return step([n, v]); }; }\r\n    function step(op) {\r\n        if (f) throw new TypeError(\"Generator is already executing.\");\r\n        while (_) try {\r\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\r\n            if (y = 0, t) op = [op[0] & 2, t.value];\r\n            switch (op[0]) {\r\n                case 0: case 1: t = op; break;\r\n                case 4: _.label++; return { value: op[1], done: false };\r\n                case 5: _.label++; y = op[1]; op = [0]; continue;\r\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\r\n                default:\r\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\r\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\r\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\r\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\r\n                    if (t[2]) _.ops.pop();\r\n                    _.trys.pop(); continue;\r\n            }\r\n            op = body.call(thisArg, _);\r\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\r\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\r\n    }\r\n}\r\n\r\nexport var __createBinding = Object.create ? (function(o, m, k, k2) {\r\n    if (k2 === undefined) k2 = k;\r\n    var desc = Object.getOwnPropertyDescriptor(m, k);\r\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\r\n        desc = { enumerable: true, get: function() { return m[k]; } };\r\n    }\r\n    Object.defineProperty(o, k2, desc);\r\n}) : (function(o, m, k, k2) {\r\n    if (k2 === undefined) k2 = k;\r\n    o[k2] = m[k];\r\n});\r\n\r\nexport function __exportStar(m, o) {\r\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);\r\n}\r\n\r\nexport function __values(o) {\r\n    var s = typeof Symbol === \"function\" && Symbol.iterator, m = s && o[s], i = 0;\r\n    if (m) return m.call(o);\r\n    if (o && typeof o.length === \"number\") return {\r\n        next: function () {\r\n            if (o && i >= o.length) o = void 0;\r\n            return { value: o && o[i++], done: !o };\r\n        }\r\n    };\r\n    throw new TypeError(s ? \"Object is not iterable.\" : \"Symbol.iterator is not defined.\");\r\n}\r\n\r\nexport function __read(o, n) {\r\n    var m = typeof Symbol === \"function\" && o[Symbol.iterator];\r\n    if (!m) return o;\r\n    var i = m.call(o), r, ar = [], e;\r\n    try {\r\n        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\r\n    }\r\n    catch (error) { e = { error: error }; }\r\n    finally {\r\n        try {\r\n            if (r && !r.done && (m = i[\"return\"])) m.call(i);\r\n        }\r\n        finally { if (e) throw e.error; }\r\n    }\r\n    return ar;\r\n}\r\n\r\n/** @deprecated */\r\nexport function __spread() {\r\n    for (var ar = [], i = 0; i < arguments.length; i++)\r\n        ar = ar.concat(__read(arguments[i]));\r\n    return ar;\r\n}\r\n\r\n/** @deprecated */\r\nexport function __spreadArrays() {\r\n    for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\r\n    for (var r = Array(s), k = 0, i = 0; i < il; i++)\r\n        for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\r\n            r[k] = a[j];\r\n    return r;\r\n}\r\n\r\nexport function __spreadArray(to, from, pack) {\r\n    if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {\r\n        if (ar || !(i in from)) {\r\n            if (!ar) ar = Array.prototype.slice.call(from, 0, i);\r\n            ar[i] = from[i];\r\n        }\r\n    }\r\n    return to.concat(ar || Array.prototype.slice.call(from));\r\n}\r\n\r\nexport function __await(v) {\r\n    return this instanceof __await ? (this.v = v, this) : new __await(v);\r\n}\r\n\r\nexport function __asyncGenerator(thisArg, _arguments, generator) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\r\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\r\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\r\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\r\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\r\n    function fulfill(value) { resume(\"next\", value); }\r\n    function reject(value) { resume(\"throw\", value); }\r\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\r\n}\r\n\r\nexport function __asyncDelegator(o) {\r\n    var i, p;\r\n    return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\r\n    function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: n === \"return\" } : f ? f(v) : v; } : f; }\r\n}\r\n\r\nexport function __asyncValues(o) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var m = o[Symbol.asyncIterator], i;\r\n    return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\r\n    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\r\n    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\r\n}\r\n\r\nexport function __makeTemplateObject(cooked, raw) {\r\n    if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\r\n    return cooked;\r\n};\r\n\r\nvar __setModuleDefault = Object.create ? (function(o, v) {\r\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\r\n}) : function(o, v) {\r\n    o[\"default\"] = v;\r\n};\r\n\r\nexport function __importStar(mod) {\r\n    if (mod && mod.__esModule) return mod;\r\n    var result = {};\r\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\r\n    __setModuleDefault(result, mod);\r\n    return result;\r\n}\r\n\r\nexport function __importDefault(mod) {\r\n    return (mod && mod.__esModule) ? mod : { default: mod };\r\n}\r\n\r\nexport function __classPrivateFieldGet(receiver, state, kind, f) {\r\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\r\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\r\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\r\n}\r\n\r\nexport function __classPrivateFieldSet(receiver, state, value, kind, f) {\r\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\r\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\r\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\r\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\r\n}\r\n\r\nexport function __classPrivateFieldIn(state, receiver) {\r\n    if (receiver === null || (typeof receiver !== \"object\" && typeof receiver !== \"function\")) throw new TypeError(\"Cannot use 'in' operator on non-object\");\r\n    return typeof state === \"function\" ? receiver === state : state.has(receiver);\r\n}\r\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, util} from '@tensorflow/tfjs-core';\n\nexport function assertNotComplex(\n    tensor: TensorInfo|TensorInfo[], opName: string): void {\n  if (!Array.isArray(tensor)) {\n    tensor = [tensor];\n  }\n  tensor.forEach(t => {\n    if (t != null) {\n      util.assert(\n          t.dtype !== 'complex64',\n          () => `${\n              opName} does not support complex64 tensors in the CPU backend.`);\n    }\n  });\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendTimingInfo, buffer, DataStorage, DataType, engine, env, kernel_impls, KernelBackend, Rank, ShapeMap, Tensor, Tensor2D, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nconst whereImpl = kernel_impls.whereImpl;\nimport {assertNotComplex} from './cpu_util';\n\ninterface DataId {}\n\nexport interface TensorData<D extends DataType> {\n  values?: backend_util.BackendValues;\n  dtype: D;\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensorInfos field.\n  complexTensorInfos?: {real: TensorInfo, imag: TensorInfo};\n  // refCount keeps track of how many tensors reference it. Used for memory\n  // management.\n  refCount: number;\n}\n\nexport class MathBackendCPU extends KernelBackend {\n  public blockSize = 48;\n\n  data: DataStorage<TensorData<DataType>>;\n  private firstUse = true;\n  private static nextDataId = 0;\n  private nextDataId(): number {\n    return MathBackendCPU.nextDataId++;\n  }\n\n  constructor() {\n    super();\n    this.data = new DataStorage(this, engine());\n  }\n\n  write(values: backend_util.BackendValues, shape: number[], dtype: DataType):\n      DataId {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn(\n            '\\n============================\\n' +\n            'Hi, looks like you are running TensorFlow.js in ' +\n            'Node.js. To speed things up dramatically, install our node ' +\n            'backend, visit https://github.com/tensorflow/tfjs-node for more details. ' +\n            '\\n============================');\n      }\n    }\n    const dataId = {id: this.nextDataId()};\n\n    this.data.set(dataId, {values, dtype, refCount: 1});\n\n    return dataId;\n  }\n\n  /**\n   * Create a data bucket in cpu backend.\n   * @param shape Shape of the `TensorInfo`.\n   * @param dtype DType of the `TensorInfo`.\n   * @param values The value of the `TensorInfo` stored as a flattened array.\n   */\n  makeTensorInfo(\n      shape: number[], dtype: DataType,\n      values?: backend_util.BackendValues|string[]): TensorInfo {\n    let outId;\n    if (dtype === 'string' && values != null && values.length > 0 &&\n        util.isString(values[0])) {\n      const encodedValues =\n          (values as {} as string[]).map(d => util.encodeString(d));\n\n      outId = this.write(encodedValues, shape, dtype);\n    } else {\n      outId = this.write(values as TypedArray, shape, dtype);\n    }\n\n    return {dataId: outId, shape, dtype};\n  }\n\n  /** Return refCount of a `TensorData`. */\n  refCount(dataId: DataId): number {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      return tensorData.refCount;\n    }\n    return 0;\n  }\n\n  /** Increase refCount of a `TensorData`. */\n  incRef(dataId: DataId): void {\n    const tensorData = this.data.get(dataId);\n    tensorData.refCount++;\n  }\n\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n\n  move(\n      dataId: DataId, values: backend_util.BackendValues, shape: number[],\n      dtype: DataType, refCount: number): void {\n    this.data.set(dataId, {values, dtype, refCount});\n  }\n\n  numDataIds(): number {\n    return this.data.numDataIds();\n  }\n\n  async read(dataId: DataId): Promise<backend_util.BackendValues> {\n    return this.readSync(dataId);\n  }\n  readSync(dataId: DataId): backend_util.BackendValues {\n    const {dtype, complexTensorInfos} = this.data.get(dataId);\n\n    if (dtype === 'complex64') {\n      const realValues =\n          this.readSync(complexTensorInfos.real.dataId) as Float32Array;\n      const imagValues =\n          this.readSync(complexTensorInfos.imag.dataId) as Float32Array;\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n\n    return this.data.get(dataId).values;\n  }\n\n  bufferSync<R extends Rank, D extends DataType>(t: TensorInfo):\n      TensorBuffer<R, D> {\n    const data = this.readSync(t.dataId);\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        const strings = (data as Uint8Array[]).map(d => util.decodeString(d));\n        return buffer(t.shape as ShapeMap[R], t.dtype, strings) as\n            TensorBuffer<R, D>;\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return buffer(t.shape as ShapeMap[R], t.dtype, data as TypedArray) as\n        TensorBuffer<R, D>;\n  }\n\n  makeOutput<T extends Tensor>(\n      values: backend_util.BackendValues, shape: number[], dtype: DataType): T {\n    return engine().makeTensorFromTensorInfo(\n               this.makeTensorInfo(shape, dtype, values), this) as T;\n  }\n\n  /**\n   * Dispose the memory if the dataId has 0 refCount. Return true if the memory\n   * is released or memory is not managed in this backend, false if memory is\n   * not cleared.\n   * @param dataId\n   * @oaram force Optional, remove the data regardless of refCount\n   */\n  disposeData(dataId: DataId, force = false): boolean {\n    if (this.data.has(dataId)) {\n      this.data.get(dataId).refCount--;\n      if (!force && this.data.get(dataId).refCount > 0) {\n        return false;\n      }\n\n      const {complexTensorInfos} = this.data.get(dataId);\n\n      if (complexTensorInfos != null) {\n        this.disposeData(complexTensorInfos.real.dataId, true);\n        this.disposeData(complexTensorInfos.imag.dataId, true);\n      }\n\n      this.data.delete(dataId);\n    }\n    return true;\n  }\n\n  disposeIntermediateTensorInfo(tensorInfo: TensorInfo): void {\n    this.disposeData(tensorInfo.dataId);\n  }\n\n  async time(f: () => void): Promise<BackendTimingInfo> {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {kernelMs};\n  }\n\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons:\n          ['The reported memory is an upper bound. Due to automatic garbage ' +\n           'collection, the true allocated memory may be less.']\n    };\n  }\n\n  where(condition: Tensor): Tensor2D {\n    assertNotComplex([condition], 'where');\n\n    const condVals = this.readSync(condition.dataId) as TypedArray;\n    return whereImpl(condition.shape, condVals);\n  }\n\n  dispose() {}\n\n  floatPrecision(): 16|32 {\n    return 32;\n  }\n\n  /** Returns the smallest representable number.  */\n  epsilon(): number {\n    return super.epsilon();\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Abs, AbsInputs, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function simpleAbsImpl(vals: TypedArray): Float32Array {\n  const resultValues = new Float32Array(vals.length);\n  for (let i = 0; i < vals.length; ++i) {\n    resultValues[i] = Math.abs(vals[i]);\n  }\n  return resultValues;\n}\n\nexport const abs = (args: {inputs: AbsInputs, backend: MathBackendCPU}) => {\n  const {x} = args.inputs;\n  const cpuBackend = args.backend;\n\n  assertNotComplex(x, 'abs');\n\n  let resultValues = new Float32Array(util.sizeFromShape(x.shape));\n  const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n  resultValues = simpleAbsImpl(values);\n\n  return cpuBackend.makeOutput(resultValues, x.shape, x.dtype);\n};\n\nexport const absConfig: KernelConfig = {\n  kernelName: Abs,\n  backendName: 'cpu',\n  kernelFunc: abs as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, DataValues, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleBinaryKernelImpl, SimpleBinaryOperation} from './binary_types';\n\n/**\n * Template that creates implementation for binary ops. Supports broadcast.\n */\nexport function createSimpleBinaryKernelImpl(op: SimpleBinaryOperation):\n    SimpleBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aVals: DataValues,\n          bVals: DataValues, dtype: DataType): [TypedArray, number[]] => {\n    const newShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n\n    const resultRank = newShape.length;\n    const resultStrides = util.computeStrides(newShape);\n    const resultSize = util.sizeFromShape(newShape);\n\n    const result =\n        util.getTypedArrayFromDType(dtype as NumericDataType, resultSize);\n\n    const aRank = aShape.length;\n    const bRank = bShape.length;\n\n    const aStrides = util.computeStrides(aShape);\n    const bStrides = util.computeStrides(bShape);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, newShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < result.length; ++i) {\n        result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      for (let i = 0; i < result.length; ++i) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        result[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n\n    return [result, newShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Complex, ComplexInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function complex(args: {inputs: ComplexInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {real, imag} = inputs;\n\n  const realVals = backend.data.get(real.dataId).values as TypedArray;\n  const imagVals = backend.data.get(imag.dataId).values as TypedArray;\n\n  const complexInfo = backend.makeTensorInfo(real.shape, 'complex64');\n\n  const complex = backend.data.get(complexInfo.dataId);\n\n  // The complex tensor owns the underlying real and imag tensorInfos, only the\n  // complex tensor tracks refCount, when complexData is disposed the\n  // underlying tensorData will be disposed.\n  complex.complexTensorInfos = {\n    real: backend.makeTensorInfo(real.shape, 'float32', realVals),\n    imag: backend.makeTensorInfo(imag.shape, 'float32', imagVals)\n  };\n\n  return complexInfo;\n}\n\nexport const complexConfig: KernelConfig = {\n  kernelName: Complex,\n  backendName: 'cpu',\n  kernelFunc: complex as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, TensorInfo, util} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {complex} from '../kernels/Complex';\n\n/**\n * Generates a tensorInfo with all zeros value.\n * @param backend cpu backend.\n * @param shape Shape for the zeros tensor.\n * @param dtype Optional. If set, the result has this dtype.\n */\nexport function zeros(\n    backend: MathBackendCPU, shape: number[],\n    dtype: DataType = 'float32'): TensorInfo {\n  if (dtype === 'complex64') {\n    const real = zeros(backend, shape, 'float32');\n    const imag = zeros(backend, shape, 'float32');\n\n    return complex({inputs: {real, imag}, backend});\n  }\n\n  const values = util.makeZerosTypedArray(util.sizeFromShape(shape), dtype);\n\n  return backend.makeTensorInfo(shape, dtype, values);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Identity, IdentityInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function identity(\n    args: {inputs: IdentityInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  backend.incRef(x.dataId);\n\n  return {dataId: x.dataId, shape: x.shape, dtype: x.dtype};\n}\n\nexport const identityConfig: KernelConfig = {\n  kernelName: Identity,\n  backendName: 'cpu',\n  kernelFunc: identity as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Real, RealInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function real(args: {inputs: RealInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const real = backend.data.get(input.dataId).complexTensorInfos.real;\n  const realVal = backend.data.get(real.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the real value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(real.shape, real.dtype, realVal);\n}\n\nexport const realConfig: KernelConfig = {\n  kernelName: Real,\n  backendName: 'cpu',\n  kernelFunc: real as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Cast, CastAttrs, CastInputs, DataType, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {zeros} from '../utils/zeros_impl';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {real} from './Real';\n\nexport function castImpl(\n    values: TypedArray, shape: number[], inputType: DataType,\n    dtype: DataType): [number[], DataType, TypedArray] {\n  if (dtype === 'int32') {\n    const resultValues = Int32Array.from(values);\n    return [shape, 'int32', resultValues];\n  }\n\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const zero = util.toTypedArray([0], inputType);\n\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl(\n        (a, b) => (a !== b) ? 1 : 0)(shape, [], values, zero, 'bool');\n\n    return [resultShape, 'bool', resultData];\n  }\n  throw new Error(`Error in Cast: failed to cast ${inputType} to ${dtype}`);\n}\n\nexport function cast(\n    args: {inputs: CastInputs, backend: MathBackendCPU, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    const zerosTensorInfo = zeros(backend, x.shape, x.dtype);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensorInfo}, backend});\n\n    backend.disposeIntermediateTensorInfo(zerosTensorInfo);\n    backend.disposeIntermediateTensorInfo(floatX);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  const values = backend.data.get(x.dataId).values as TypedArray;\n  const [resultShape, resultType, resultData] =\n      castImpl(values, x.shape, x.dtype, dtype);\n  return backend.makeTensorInfo(resultShape, resultType, resultData);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {cast} from '../kernels/Cast';\nimport {complex} from '../kernels/Complex';\n\nimport {ComplexBinaryKernelImpl, ComplexBinaryOperation, SimpleBinaryKernelImpl} from './binary_types';\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param name Kernel name.\n * @param binaryKernelImpl A `SimpleBinaryKernelImpl` for the kernel.\n * @param binaryKernelComplexImpl Optional. If exists, represents a\n *     `ComplexBinaryKernelImpl` for the kernel, will be used when input dtype\n *     is `complex64`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc(\n    name: string, simpleImpl: SimpleBinaryKernelImpl,\n    complexImpl?: ComplexBinaryKernelImpl, dtype?: DataType): KernelFunc {\n  if (complexImpl == null) {\n    return ({inputs, backend}) => {\n      const {a, b} = inputs as BinaryInputs;\n      const cpuBackend = backend as MathBackendCPU;\n\n      assertNotComplex([a, b], name);\n\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const decodedAVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(aVals as any as Uint8Array[]) :\n          aVals;\n      const decodedBVals = a.dtype === 'string' ?\n          // tslint:disable-next-line: no-any\n          backend_util.fromUint8ToStringArray(bVals as any as Uint8Array[]) :\n          bVals;\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    };\n  }\n\n  return ({inputs, backend}) => {\n    const {a, b} = inputs as BinaryInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      const $aComplex = cast(\n          {inputs: {x: a}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $aComplexVals = cpuBackend.data.get($aComplex.dataId);\n\n      const aReal = $aComplexVals.complexTensorInfos.real;\n      const aImag = $aComplexVals.complexTensorInfos.imag;\n\n      const aRealVals =\n          cpuBackend.data.get(aReal.dataId).values as Float32Array;\n      const aImagVals =\n          cpuBackend.data.get(aImag.dataId).values as Float32Array;\n\n      const $bComplex = cast(\n          {inputs: {x: b}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $bComplexVals = cpuBackend.data.get($bComplex.dataId);\n\n      const bReal = $bComplexVals.complexTensorInfos.real;\n      const bImag = $bComplexVals.complexTensorInfos.imag;\n\n      const bRealVals =\n          cpuBackend.data.get(bReal.dataId).values as Float32Array;\n      const bImagVals =\n          cpuBackend.data.get(bImag.dataId).values as Float32Array;\n\n      const [resultRealData, resultImagData, resultShape] = complexImpl(\n          a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);\n\n      const resultReal =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultRealData);\n\n      const resultImag =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultImagData);\n\n      const result = complex(\n          {inputs: {real: resultReal, imag: resultImag}, backend: cpuBackend});\n\n      cpuBackend.disposeIntermediateTensorInfo($aComplex);\n      cpuBackend.disposeIntermediateTensorInfo($bComplex);\n      cpuBackend.disposeIntermediateTensorInfo(resultReal);\n      cpuBackend.disposeIntermediateTensorInfo(resultImag);\n\n      return result;\n    } else {\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    }\n  };\n}\n\n/**\n * Template that creates the complex type implementation for binary ops.\n * Supports broadcast.\n */\nexport function createComplexBinaryKernelImpl(op: ComplexBinaryOperation):\n    ComplexBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aRealVals: Float32Array,\n          aImagVals: Float32Array, bRealVals: Float32Array,\n          bImagVals: Float32Array): [TypedArray, TypedArray, number[]] => {\n    const resultShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    const resultSize = util.sizeFromShape(resultShape);\n    const resultRank = resultShape.length;\n    const resultStrides = util.computeStrides(resultShape);\n\n    const resultRealVals = util.getTypedArrayFromDType('float32', resultSize);\n    const resultImagVals = util.getTypedArrayFromDType('float32', resultSize);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, resultShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, resultShape);\n\n    const aVals = backend_util.mergeRealAndImagArrays(aRealVals, aImagVals);\n    const bVals = backend_util.mergeRealAndImagArrays(bRealVals, bImagVals);\n\n    const aRank = aShape.length;\n    const aStrides = util.computeStrides(aShape);\n\n    const bRank = bShape.length;\n    const bStrides = util.computeStrides(bShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const aIdx = i % aVals.length;\n        const bIdx = i % bVals.length;\n\n        const result =\n            op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2],\n               bVals[bIdx * 2 + 1]);\n\n        resultRealVals[i] = result.real;\n        resultImagVals[i] = result.imag;\n      }\n    } else {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        const opResult =\n            op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2],\n               bVals[bIndex * 2 + 1]);\n\n        resultRealVals[i] = opResult.real;\n        resultImagVals[i] = opResult.imag;\n      }\n    }\n    return [resultRealVals, resultImagVals, resultShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const addImpl =\n    createSimpleBinaryKernelImpl(((a: number, b: number) => a + b));\nexport const addComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal + bReal, imag: aImag + bImag};\n    }));\n\nexport const add = binaryKernelFunc(Add, addImpl, addComplexImpl);\n\nexport const addConfig: KernelConfig = {\n  kernelName: Add,\n  backendName: 'cpu',\n  kernelFunc: add\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function bincountImpl(\n    xVals: TypedArray, weightsVals: TypedArray, weightsDtype: DataType,\n    weightsShape: number[], size: number): TypedArray {\n  const weightsSize = util.sizeFromShape(weightsShape);\n  const outVals = util.makeZerosTypedArray(size, weightsDtype) as TypedArray;\n\n  for (let i = 0; i < xVals.length; i++) {\n    const value = xVals[i];\n    if (value < 0) {\n      throw new Error('Input x must be non-negative!');\n    }\n\n    if (value >= size) {\n      continue;\n    }\n\n    if (weightsSize > 0) {\n      outVals[value] += weightsVals[i];\n    } else {\n      outVals[value] += 1;\n    }\n  }\n\n  return outVals;\n}\n\nexport function bincountReduceImpl<R extends Rank>(\n    xBuf: TensorBuffer<R>, weightsBuf: TensorBuffer<R>, size: number,\n    binaryOutput = false): TensorBuffer<R> {\n  const numRows = xBuf.shape[0];\n  const numCols = xBuf.shape[1];\n\n  const outBuf = buffer([numRows, size], weightsBuf.dtype);\n\n  for (let i = 0; i < numRows; i++) {\n    for (let j = 0; j < numCols; j++) {\n      const value = xBuf.get(i, j);\n      if (value < 0) {\n        throw new Error('Input x must be non-negative!');\n      }\n\n      if (value >= size) {\n        continue;\n      }\n\n      if (binaryOutput) {\n        outBuf.set(1, i, value);\n      } else {\n        if (weightsBuf.size > 0) {\n          outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);\n        } else {\n          outBuf.set(outBuf.get(i, value) + 1, i, value);\n        }\n      }\n    }\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NumericDataType, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates implementation for unary op.\n */\nexport function createSimpleUnaryImpl(op: SimpleUnaryOperation):\n    SimpleUnaryImpl {\n  return (values, dtype, attrs) => {\n    const newValues =\n        util.getTypedArrayFromDType(dtype as NumericDataType, values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return newValues;\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelFunc, TypedArray, UnaryInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param name Kernel name.\n * @param op A `SimpleUnaryOperation` for the kernel.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFunc(\n    name: string, op: SimpleUnaryOperation, dtype?: DataType): KernelFunc {\n  return ({inputs, attrs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    assertNotComplex(x, name);\n    if (x.dtype === 'string' || dtype === 'string') {\n      throw new Error('unaryKernelFunc does not support string input/output');\n    }\n\n    const cpuBackend = backend as MathBackendCPU;\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xSize = util.sizeFromShape(x.shape);\n    const $dtype = dtype || x.dtype;\n    const newValues = util.getArrayFromDType($dtype, xSize);\n    for (let i = 0; i < xSize; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n  };\n}\n\n/**\n * Template that creates a `KernelFunc` for unary ops from the given\n * `SimpleUnaryImpl`..\n * @param name Kernel name.\n * @param unaryImpl A `SimpleUnaryImpl` that implements the op.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFuncFromImpl(\n    name: string, unaryImpl: SimpleUnaryImpl, dtype?: DataType): KernelFunc {\n  return ({inputs, attrs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    assertNotComplex(x, name);\n    if (x.dtype === 'string' || dtype === 'string') {\n      throw new Error('unaryKernelFunc does not support string input/output');\n    }\n\n    const cpuBackend = backend as MathBackendCPU;\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const $dtype = dtype || x.dtype;\n    const newValues = unaryImpl(values, $dtype, attrs);\n    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Ceil, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));\nexport const ceil = unaryKernelFuncFromImpl(Ceil, ceilImpl);\n\nexport const ceilConfig: KernelConfig = {\n  kernelName: Ceil,\n  backendName: 'cpu',\n  kernelFunc: ceil,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function concatImpl(\n    inputs: Array<{vals: BackendValues, shape: number[]}>, outShape: number[],\n    dtype: DataType, simplyConcat: boolean): TypedArray|string[] {\n  const outVals = util.getArrayFromDType(dtype, util.sizeFromShape(outShape));\n\n  if (simplyConcat && dtype !== 'string') {\n    // Use built-in TypedArray.set() method for speed.\n    let offset = 0;\n    inputs.forEach(input => {\n      const size = util.sizeFromShape(input.shape);\n\n      (outVals as TypedArray).set(input.vals as TypedArray, offset);\n      offset += size;\n    });\n  } else {\n    let colOffset = 0;\n\n    inputs.forEach(input => {\n      const decodedData = dtype === 'string' ?\n          backend_util.fromUint8ToStringArray(input.vals as Uint8Array[]) :\n          input.vals as TypedArray;\n\n      let tIdx = 0;\n\n      for (let row = 0; row < input.shape[0]; ++row) {\n        const resIdx = row * outShape[1] + colOffset;\n        for (let col = 0; col < input.shape[1]; ++col) {\n          outVals[resIdx + col] = decodedData[tIdx++];\n        }\n      }\n\n      colOffset += input.shape[1];\n    });\n  }\n\n  return outVals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Equal, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const equalImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a === b) ? 1 : 0);\nexport const equal =\n    binaryKernelFunc(Equal, equalImpl, null /* complexImpl */, 'bool');\n\nexport const equalConfig: KernelConfig = {\n  kernelName: Equal,\n  backendName: 'cpu',\n  kernelFunc: equal\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));\nexport const exp = unaryKernelFuncFromImpl(Exp, expImpl, 'float32');\n\nexport const expConfig: KernelConfig = {\n  kernelName: Exp,\n  backendName: 'cpu',\n  kernelFunc: exp,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));\nexport const expm1 = unaryKernelFuncFromImpl(Expm1, expm1Impl);\n\nexport const expm1Config: KernelConfig = {\n  kernelName: Expm1,\n  backendName: 'cpu',\n  kernelFunc: expm1,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));\nexport const floor = unaryKernelFuncFromImpl(Floor, floorImpl);\n\nexport const floorConfig: KernelConfig = {\n  kernelName: Floor,\n  backendName: 'cpu',\n  kernelFunc: floor,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function gatherNdImpl<R extends Rank>(\n    indicesData: TypedArray, paramsBuf: TensorBuffer<R>, dtype: DataType,\n    numSlices: number, sliceRank: number, sliceSize: number, strides: number[],\n    paramsShape: number[], paramsSize: number): TensorBuffer<R> {\n  const outBuf = buffer([numSlices, sliceSize], dtype);\n\n  for (let i = 0; i < numSlices; i++) {\n    const index = [];\n    let flattenIndex = 0;\n    for (let j = 0; j < sliceRank; j++) {\n      const dim = indicesData[i * sliceRank + j];\n      flattenIndex += dim * strides[j];\n      index.push(dim);\n    }\n    if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {\n      throw new Error(\n          `Invalid indices: ${index} does not index into ${paramsShape}`);\n    }\n\n    for (let k = 0; k < sliceSize; k++) {\n      outBuf.values[i * sliceSize + k] =\n          paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex * sliceSize + k));\n    }\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\nexport function gatherV2Impl<R extends Rank, D extends DataType>(\n    xBuf: TensorBuffer<R, D>, indicesBuf: TensorBuffer<R, D>,\n    flattenOutputShape: number[]): TensorBuffer<R, D> {\n  const outBuf = buffer(flattenOutputShape, xBuf.dtype);\n  for (let i = 0; i < outBuf.size; ++i) {\n    const newLoc = outBuf.indexToLoc(i);\n\n    const originalLoc: number[] = newLoc.slice();\n    const batchIdx = originalLoc[0];\n    const indicesIdx = originalLoc[2];\n    const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);\n    originalLoc[2] = indicesBuf.values[indicesIndex] as number;\n\n    const originalIndex = xBuf.locToIndex(originalLoc);\n\n    if (0 <= originalIndex && originalIndex < xBuf.values.length) {\n      outBuf.values[i] = xBuf.values[originalIndex];\n    } // Else, index is out of bounds, so leave the default zero val in outBuf.\n  }\n\n  return outBuf as TensorBuffer<R, D>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Greater, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const greaterImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a > b) ? 1 : 0);\nexport const greater =\n    binaryKernelFunc(Greater, greaterImpl, null /* complexImpl */, 'bool');\n\nexport const greaterConfig: KernelConfig = {\n  kernelName: Greater,\n  backendName: 'cpu',\n  kernelFunc: greater\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {GreaterEqual, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const greaterEqualImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a >= b) ? 1 : 0);\nexport const greaterEqual = binaryKernelFunc(\n    GreaterEqual, greaterEqualImpl, null /* complexImpl */, 'bool');\n\nexport const greaterEqualConfig: KernelConfig = {\n  kernelName: GreaterEqual,\n  backendName: 'cpu',\n  kernelFunc: greaterEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Less} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const lessImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a < b) ? 1 : 0);\nexport const less =\n    binaryKernelFunc(Less, lessImpl, null /* complexImpl */, 'bool');\n\nexport const lessConfig: KernelConfig = {\n  kernelName: Less,\n  backendName: 'cpu',\n  kernelFunc: less\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LessEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const lessEqualImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => (a <= b) ? 1 : 0);\nexport const lessEqual =\n    binaryKernelFunc(LessEqual, lessEqualImpl, null /* complexImpl */, 'bool');\n\nexport const lessEqualConfig: KernelConfig = {\n  kernelName: LessEqual,\n  backendName: 'cpu',\n  kernelFunc: lessEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function linSpaceImpl(\n    start: number, stop: number, num: number): TypedArray {\n  const step = (stop - start) / (num - 1);\n\n  const values = util.makeZerosTypedArray(num, 'float32');\n  values[0] = start;\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n\n  return values;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));\nexport const log = unaryKernelFuncFromImpl(Log, logImpl);\n\nexport const logConfig: KernelConfig = {\n  kernelName: Log,\n  backendName: 'cpu',\n  kernelFunc: log,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function maxImpl(\n    aVals: TypedArray, reduceSize: number, outShape: number[],\n    dtype: DataType): TypedArray {\n  const vals = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (Number.isNaN(value) ||\n          value > max) {  // comparison with NaN always return false\n        max = value;\n      }\n    }\n    vals[i] = max;\n  }\n  return vals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Maximum} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const maximumImpl = createSimpleBinaryKernelImpl(\n    ((aValue, bValue) => Math.max(aValue as number, bValue as number)));\nexport const maximum = binaryKernelFunc(Maximum, maximumImpl);\n\nexport const maximumConfig: KernelConfig = {\n  kernelName: Maximum,\n  backendName: 'cpu',\n  kernelFunc: maximum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Minimum} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const minimumImpl = createSimpleBinaryKernelImpl(\n    ((aValue, bValue) => Math.min(aValue as number, bValue as number)));\nexport const minimum = binaryKernelFunc(Minimum, minimumImpl);\n\nexport const minimumConfig: KernelConfig = {\n  kernelName: Minimum,\n  backendName: 'cpu',\n  kernelFunc: minimum\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const multiplyImpl = createSimpleBinaryKernelImpl(\n    ((aValue: number, bValue: number) => aValue * bValue));\nexport const multiplyComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {\n        real: aReal * bReal - aImag * bImag,\n        imag: aReal * bImag + aImag * bReal\n      };\n    }));\n\nexport const multiply =\n    binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);\n\nexport const multiplyConfig: KernelConfig = {\n  kernelName: Multiply,\n  backendName: 'cpu',\n  kernelFunc: multiply\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelConfig, KernelFunc, Neg, TensorInfo, TypedArray, UnaryInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {multiplyImpl} from './Multiply';\n\nexport function negImpl(xVals: TypedArray, xShape: number[], xDtype: DataType):\n    [TypedArray, number[]] {\n  const minusOne =\n      util.createScalarValue(-1 as {} as 'float32', xDtype) as TypedArray;\n  return multiplyImpl([], xShape, minusOne, xVals, xDtype);\n}\n\nexport function neg(args: {inputs: UnaryInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  assertNotComplex(x, 'neg');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const [res, newShape] = negImpl(xVals, x.shape, x.dtype);\n\n  return backend.makeTensorInfo(newShape, x.dtype, res);\n}\n\nexport const negConfig: KernelConfig = {\n  kernelName: Neg,\n  backendName: 'cpu',\n  kernelFunc: neg as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const notEqualImpl =\n    createSimpleBinaryKernelImpl(((a, b) => (a !== b) ? 1 : 0));\nexport const notEqual =\n    binaryKernelFunc(NotEqual, notEqualImpl, null /* complexOp */, 'bool');\n\nexport const notEqualConfig: KernelConfig = {\n  kernelName: NotEqual,\n  backendName: 'cpu',\n  kernelFunc: notEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {util} from '@tensorflow/tfjs-core';\n\nexport function transposeImpl(\n    xVals: TypedArray, xShape: number[], dtype: DataType, perm: number[],\n    newShape: number[]): TypedArray {\n  const xRank = xShape.length;\n  const xSize = util.sizeFromShape(xShape);\n  const xStrides = util.computeStrides(xShape);\n  const newStrides = util.computeStrides(newShape);\n\n  const result = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(newShape));\n\n  for (let i = 0; i < xSize; ++i) {\n    const loc = util.indexToLoc(i, xRank, xStrides);\n\n    // Permute location.\n    const newLoc: number[] = new Array(loc.length);\n    for (let i = 0; i < newLoc.length; i++) {\n      newLoc[i] = loc[perm[i]];\n    }\n\n    const newIndex = util.locToIndex(newLoc, xRank, newStrides);\n    result[newIndex] = xVals[i];\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transpose, TransposeAttrs, TransposeInputs, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {transposeImpl} from './Transpose_impl';\n\nexport function transpose(args: {\n  inputs: TransposeInputs,\n  attrs: TransposeAttrs,\n  backend: MathBackendCPU\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {x} = inputs;\n  const {perm} = attrs;\n\n  assertNotComplex(x, 'transpose');\n\n  const xRank = x.shape.length;\n\n  const newShape: number[] = new Array(xRank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = x.shape[perm[i]];\n  }\n\n  const values = backend.data.get(x.dataId).values as TypedArray;\n  const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);\n\n  const dataId = backend.write(result, newShape, x.dtype);\n  return {dataId, shape: newShape, dtype: x.dtype};\n}\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'cpu',\n  kernelFunc: transpose as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, KernelConfig, KernelFunc, Prod, ProdAttrs, ProdInputs, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function prodImpl(\n    xShape: number[], xDtype: DataType, xVals: TypedArray,\n    reductionAxes: number[]):\n    {outVals: TypedArray, outShape: number[], outDtype: DataType} {\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(xShape, reductionAxes);\n  const outDtype = upcastType(xDtype, 'int32');\n  const outVals = util.makeZerosTypedArray(\n                      util.sizeFromShape(outShape), outDtype) as TypedArray;\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  for (let i = 0; i < outVals.length; ++i) {\n    const offset = i * reduceSize;\n    let prod = 1;\n    for (let j = 0; j < reduceSize; ++j) {\n      prod *= xVals[offset + j];\n    }\n    outVals[i] = prod;\n  }\n\n  return {outVals, outShape, outDtype};\n}\n\nexport function prod(\n    args: {inputs: ProdInputs, backend: MathBackendCPU, attrs: ProdAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'prod');\n\n  const xRank = x.shape.length;\n  const axes = util.parseAxisParam(axis, x.shape);\n\n  const permutation = backend_util.getAxesPermutation(axes, xRank);\n  let reductionAxes = axes;\n  let permutedX = x;\n  const intermediateTensorInfos = [];\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n    intermediateTensorInfos.push(permutedX);\n    reductionAxes = backend_util.getInnerMostAxes(reductionAxes.length, xRank);\n  }\n\n  const xVals = backend.data.get(permutedX.dataId).values as TypedArray;\n  const {outVals, outShape, outDtype} =\n      prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes);\n\n  let resultShape = outShape;\n  if (keepDims) {\n    resultShape = backend_util.expandShapeToKeepDim(outShape, axes);\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(resultShape, outDtype, outVals);\n}\n\nexport const prodConfig: KernelConfig = {\n  kernelName: Prod,\n  backendName: 'cpu',\n  kernelFunc: prod as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, broadcastTo, DataType, reshape, tidy, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport RowPartitionType = backend_util.RowPartitionType;\n// Based on\n// https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc\nclass RaggedTensorToTensorOp {\n  private readonly rowPartitionTypes: RowPartitionType[];\n  private readonly raggedRank: number;\n  constructor(\n      private shape: TypedArray, private shapeShape: number[],\n      private values: TypedArray, private valuesShape: number[],\n      private valuesDType: DataType, private defaultValue: TypedArray,\n      private defaultValueShape: number[],\n      private readonly rowPartitionValues: TypedArray[],\n      private readonly rowPartitionValuesShapes: number[][],\n      rowPartitionTypeStrings: string[]) {\n    this.rowPartitionTypes =\n        backend_util.getRowPartitionTypesHelper(rowPartitionTypeStrings);\n    this.raggedRank = backend_util.getRaggedRank(this.rowPartitionTypes);\n  }\n\n  private getRowPartitionTypeByDimension(dimension: number) {\n    if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {\n      return this.rowPartitionTypes[dimension + 1];\n    } else {\n      return this.rowPartitionTypes[dimension];\n    }\n  }\n\n  // Returns the relationship between dimension and dimension + 1.\n  private getRowPartitionTensor(dimension: number) {\n    if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {\n      return this.rowPartitionValues[dimension + 1];\n    } else {\n      return this.rowPartitionValues[dimension];\n    }\n  }\n\n  private getMaxWidth(dimension: number) {\n    const rowPartitionTensor = this.getRowPartitionTensor(dimension - 1);\n    switch (this.getRowPartitionTypeByDimension(dimension - 1)) {\n      case RowPartitionType.VALUE_ROWIDS:\n        return RaggedTensorToTensorOp.getMaxWidthValueRowID(rowPartitionTensor);\n      case RowPartitionType.ROW_SPLITS:\n        return RaggedTensorToTensorOp.getMaxWidthRowSplit(rowPartitionTensor);\n      default:\n        throw new Error(`Cannot handle partition type ${\n            RowPartitionType[this.getRowPartitionTypeByDimension(\n                dimension - 1)]}`);\n    }\n  }\n\n  static getMaxWidthRowSplit(rowSplit: TypedArray) {\n    const tensorLength = rowSplit.length;\n    if (tensorLength === 0 || tensorLength === 1) {\n      return 0;\n    }\n    let maxWidth = 0;\n    for (let i = 0; i < tensorLength - 1; ++i) {\n      const currentWidth = rowSplit[i + 1] - rowSplit[i];\n      if (currentWidth > maxWidth) {\n        maxWidth = currentWidth;\n      }\n    }\n    return maxWidth;\n  }\n\n  static getMaxWidthValueRowID(valueRowIds: TypedArray) {\n    const indexLength = valueRowIds.length;\n    if (indexLength === 0) {\n      return 0;\n    }\n    let firstEqualIndex = 0;\n    let firstEqualIndexValue = valueRowIds[0];\n    let maxWidth = 0;\n    for (let i = 1; i < indexLength; ++i) {\n      const value = valueRowIds[i];\n      if (value !== firstEqualIndexValue) {\n        firstEqualIndexValue = value;\n        maxWidth = Math.max(i - firstEqualIndex, maxWidth);\n        firstEqualIndex = i;\n      }\n    }\n    return Math.max(indexLength - firstEqualIndex, maxWidth);\n  }\n\n  private tensorShapeFromTensor(\n      t: TypedArray, tShape: number[], isPartial = true) {\n    if (tShape.length === 0) {\n      if (t[0] === -1) {\n        return [];\n      }\n      throw new Error(\n          `The only valid scalar shape tensor is the fully unknown shape specified as -1.`);\n    }\n    // MakePartialShape/MakeShapeHelper.\n    return makeShape(t, isPartial);\n  }\n\n  private calculateOutputSize(firstDim: number) {\n    const valueShape = this.valuesShape;\n    const defaultValueShape = this.defaultValueShape;\n\n    backend_util.validateDefaultValueShape(defaultValueShape, valueShape);\n\n    const shape = this.tensorShapeFromTensor(this.shape, this.shapeShape);\n    const outputShape = backend_util.combineRaggedTensorToTensorShapes(\n        this.raggedRank, shape, valueShape);\n\n    const result = outputShape;\n\n    if (result[0] < 0) {\n      result[0] = firstDim;\n    }\n    for (let i = 1; i <= this.raggedRank; ++i) {\n      if (result[i] < 0) {\n        result[i] = this.getMaxWidth(i);\n      }\n    }\n\n    return result;\n  }\n\n  /**\n   * The outputIndex represents the index in the output tensor\n   * where the first element of a particular dimension would be written.\n   * If it is -1, it indicates that the index is out of scope.\n   * Example, given firstDimension = 10, firstDimensionOutput = 6,\n   * and outputIndexMultiplier = 100:\n   * result = [0 100 200 300 400 500 -1 -1 -1 -1]\n   * If firstDimensionOutput = 11 instead, then:\n   * result = [0 100 200 300 400 500 600 700 800 900]\n   */\n  private calculateFirstParentOutputIndex(\n      firstDimension: number, outputIndexMultiplier: number,\n      firstDimensionOutput: number) {\n    const minDimension = Math.min(firstDimension, firstDimensionOutput);\n    const result: number[] = [];\n    let currentOutputIndex = 0;\n    for (let i = 0; i < minDimension;\n         ++i, currentOutputIndex += outputIndexMultiplier) {\n      result.push(currentOutputIndex);\n    }\n    for (let i = minDimension; i < firstDimension; ++i) {\n      result.push(-1);\n    }\n    util.assert(\n        result.length === firstDimension,\n        () => 'Final length of result must be equal to firstDimension.');\n\n    return result;\n  }\n\n  private calculateOutputIndexRowSplit(\n      rowSplit: TypedArray, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const rowSplitSize = rowSplit.length;\n    const result: number[] = [];\n    for (let i = 0; i < rowSplitSize - 1; ++i) {\n      const rowLength = rowSplit[i + 1] - rowSplit[i];\n      let realLength = Math.min(outputSize, rowLength);\n      let parentOutputIndexCurrent = parentOutputIndex[i];\n\n      if (parentOutputIndexCurrent === -1) {\n        realLength = 0;\n      }\n      for (let j = 0; j < realLength; ++j) {\n        result.push(parentOutputIndexCurrent);\n        parentOutputIndexCurrent += outputIndexMultiplier;\n      }\n      for (let j = 0; j < rowLength - realLength; ++j) {\n        result.push(-1);\n      }\n    }\n    if (rowSplitSize > 0 && result.length !== rowSplit[rowSplitSize - 1]) {\n      throw new Error('Invalid row split size.');\n    }\n\n    return result;\n  }\n\n  // Calculate the output index of the first element of a list.\n  // The parentOutputIndex is the same computation for the previous list.\n  // -1 indicates an element or list that is out of range.\n  // The outputIndexMultiplier is the number of output indices one moves\n  // forward for each column.\n  // E.g., given:\n  // valueRowIds:[0 1 2 2 2 3 5 5 6]\n  // parentOutputIndex:[1000 1100 2000 2100 -1 3000 4000]\n  // outputIndexMultiplier: 10\n  // outputSize: 2\n  // You get:\n  // result = [1000 1100 2000 2010 -1 2100 -1 -1 3000]\n  // result[0] = parentOutputIndex[valueRowIds[0]]\n  // result[1] = parentOutputIndex[valueRowIds[1]]\n  // result[2] = parentOutputIndex[valueRowIds[2]]\n  // result[3] = parentOutputIndex[valueRowIds[2] + 10]\n  // result[4] = -1 because it is the third element the size is 2.\n  // result[5] = parentOutputIndex[valueRowIds[3]]\n  // result[6] = -1 because parentOutputIndex[valueRowIds[6]] == -1\n  // result[7] = -1 because parentOutputIndex[valueRowIds[6]] == -1\n  // result[8] = parentOutputIndex[valueRowIds[7]]\n  private calculateOutputIndexValueRowID(\n      valueRowIds: TypedArray, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const indexSize = valueRowIds.length;\n    const result: number[] = [];\n    if (indexSize === 0) {\n      return [];\n    }\n\n    let currentOutputColumn = 0;\n    let currentValueRowId = valueRowIds[0];\n\n    if (currentValueRowId >= parentOutputIndex.length) {\n      throw new Error(\n          `Got currentValueRowId=${currentValueRowId}, which is not less than ${\n              parentOutputIndex.length}`);\n    }\n\n    let currentOutputIndex = parentOutputIndex[currentValueRowId];\n    result.push(currentOutputIndex);\n    for (let i = 1; i < indexSize; ++i) {\n      const nextValueRowId = valueRowIds[i];\n      if (nextValueRowId === currentValueRowId) {\n        if (currentOutputIndex >= 0) {\n          ++currentOutputColumn;\n          if (currentOutputColumn < outputSize) {\n            currentOutputIndex += outputIndexMultiplier;\n          } else {\n            currentOutputIndex = -1;\n          }\n        }\n      } else {\n        currentOutputColumn = 0;\n        currentValueRowId = nextValueRowId;\n\n        if (nextValueRowId >= parentOutputIndex.length) {\n          throw new Error(\n              `Got nextValueRowId=${nextValueRowId} which is not less than ${\n                  parentOutputIndex.length}`);\n        }\n\n        currentOutputIndex = parentOutputIndex[nextValueRowId];\n      }\n      result.push(currentOutputIndex);\n    }\n\n    if (result.length !== valueRowIds.length) {\n      throw new Error('Invalid row ids.');\n    }\n\n    return result;\n  }\n\n  private calculateOutputIndex(\n      dimension: number, parentOutputIndex: number[],\n      outputIndexMultiplier: number, outputSize: number) {\n    const rowPartitionTensor = this.getRowPartitionTensor(dimension);\n    const partitionType = this.getRowPartitionTypeByDimension(dimension);\n    switch (partitionType) {\n      case RowPartitionType.VALUE_ROWIDS:\n        return this.calculateOutputIndexValueRowID(\n            rowPartitionTensor, parentOutputIndex, outputIndexMultiplier,\n            outputSize);\n      case RowPartitionType.ROW_SPLITS:\n        if (rowPartitionTensor.length - 1 > parentOutputIndex.length) {\n          throw new Error(`Row partition size is greater than output size: ${\n              rowPartitionTensor.length - 1} > ${parentOutputIndex.length}`);\n        }\n        return this.calculateOutputIndexRowSplit(\n            rowPartitionTensor, parentOutputIndex, outputIndexMultiplier,\n            outputSize);\n      default:\n        throw new Error(\n            `Unsupported partition type: ${RowPartitionType[partitionType]}`);\n    }\n  }\n\n  private getFirstDimensionSize() {\n    const firstPartitionTensor = this.rowPartitionValues[0];\n    if (this.rowPartitionTypes.length === 0) {\n      throw new Error('No row_partition_types given.');\n    }\n    const firstPartitionType = this.rowPartitionTypes[0];\n    switch (firstPartitionType) {\n      case RowPartitionType.FIRST_DIM_SIZE:\n        return firstPartitionTensor[0];\n      case RowPartitionType.VALUE_ROWIDS:\n        throw new Error('Cannot handle VALUE_ROWIDS in first dimension.');\n      case RowPartitionType.ROW_SPLITS:\n        return this.rowPartitionValuesShapes[0][0] - 1;\n      default:\n        throw new Error(\n            `Cannot handle type ${RowPartitionType[firstPartitionType]}`);\n    }\n  }\n\n  compute(): [number[], TypedArray] {\n    const firstPartitionTensor = this.rowPartitionValues[0];\n    if (firstPartitionTensor.length <= 0) {\n      throw new Error(\n          'Invalid first partition input. ' +\n          'Tensor requires at least one element.');\n    }\n    const firstDimension = this.getFirstDimensionSize();\n    const outputSize = this.calculateOutputSize(firstDimension);\n    const multiplier: number[] = new Array(this.raggedRank + 1);\n\n    multiplier[multiplier.length - 1] = 1;\n    for (let i = multiplier.length - 2; i >= 0; --i) {\n      multiplier[i] = multiplier[i + 1] * outputSize[i + 1];\n    }\n    // Full size of the tensor.\n    const outputShape: number[] = makeShape(outputSize, false);\n    const outputTensor =\n        util.getArrayFromDType(\n            this.valuesDType, util.sizeFromShape(outputShape)) as TypedArray;\n\n    const fullSize = multiplier[0] * outputSize[0];\n    if (fullSize > 0) {\n      let outputIndex = this.calculateFirstParentOutputIndex(\n          firstDimension, multiplier[0], outputSize[0]);\n      for (let i = 1; i <= this.raggedRank; ++i) {\n        const newOutputIndex = this.calculateOutputIndex(\n            i - 1, outputIndex, multiplier[i], outputSize[i]);\n        outputIndex = newOutputIndex;\n      }\n\n      this.setOutput(this.raggedRank, outputIndex, outputTensor, outputShape);\n    }\n\n    return [outputShape, outputTensor];\n  }\n  setOutput(\n      raggedRank: number, outputIndex: number[], outputTensor: TypedArray,\n      outputShape: number[]) {\n    if (outputTensor.length === 0) {\n      return;\n    }\n\n    const valuesBase = this.values;\n    const outputBase = outputTensor;\n\n    let elementShape = outputShape.slice();\n    elementShape = elementShape.slice(raggedRank + 1);\n    const valueElementSize = util.sizeFromShape(elementShape);\n    const outputIndexSize = outputIndex.length;\n\n    // Broadcast the default value to value_element_size.  (We can skip this\n    // if defaultValueTensor.size == 1, since we use fill when that's true.)\n    let defaultValue = this.defaultValue;\n    if (defaultValue.length !== valueElementSize && defaultValue.length !== 1) {\n      const srcShape = this.defaultValueShape;\n      tidy(() => {\n        const defaultValueTensor = reshape(defaultValue, srcShape);\n        const bCastDefault = broadcastTo(defaultValueTensor, elementShape);\n        defaultValue = bCastDefault.dataSync();\n      });\n    }\n\n    // Loop through the outputIndex array, finding contiguous regions that\n    // should be copied.  Once we find the end of a contiguous region, copy it\n    // and add any necessary padding (with defaultValue).\n    let srcStart = 0;  // Start of contiguous region (in values)\n    let dstStart = 0;  // Destination for contiguous region (in output)\n    let dstEnd = 0;    // Destination for contiguous region (in output)\n    for (let srcI = 0; srcI <= outputIndexSize; ++srcI) {\n      // dstI is the destination where the value at srcI should be copied.\n      let dstI = srcI < outputIndexSize ? outputIndex[srcI] : -1;\n\n      // If we're still in a contiguous region, then update dstEnd go to the\n      // next srcI.\n      if (dstI === dstEnd) {\n        ++dstEnd;\n        continue;\n      }\n\n      // We found the end of contiguous region.  This can be because we found\n      // a gap (dstI > dstEnd), or a source value that shouldn't be copied\n      // because it's out-of-bounds (dstI == -1), or the end of the tensor\n      // (dstI === -1).\n      if (dstStart < dstEnd) {\n        // Copy the contiguous region.\n        const src = valuesBase.subarray(srcStart * valueElementSize);\n        const dst = outputBase.subarray(dstStart * valueElementSize);\n        const nVals = (dstEnd - dstStart) * valueElementSize;\n        copyArray(dst, src, nVals);\n      }\n\n      // Add any necessary padding (w/ defaultValue).\n      if (srcI >= outputIndexSize) {\n        // We reached the end of values: pad to the end of output.\n        const outputSize = outputTensor.length;\n        dstI = Math.floor(outputSize / valueElementSize);\n      }\n      if (dstI > dstEnd) {\n        if (this.defaultValue.length === 1) {\n          outputBase\n              .subarray(dstEnd * valueElementSize, dstI * valueElementSize)\n              .fill(this.defaultValue[0]);\n          dstEnd = dstI;\n        } else {\n          while (dstI > dstEnd) {\n            const dst = outputBase.slice(dstEnd * valueElementSize);\n            copyArray(dst, defaultValue, valueElementSize);\n            ++dstEnd;\n          }\n        }\n      }\n\n      // Update indices.\n      if (dstI < 0) {\n        // srcI should be skipped -- leave it out of the contiguous region.\n        srcStart = srcI + 1;\n        dstStart = dstEnd;\n      } else {\n        // srcI should be copied -- include it in the contiguous region.\n        srcStart = srcI;\n        dstStart = dstEnd;\n        dstEnd = dstStart + 1;\n      }\n    }\n  }\n}\n\nfunction copyArray(dst: TypedArray, src: TypedArray, size: number) {\n  for (let i = 0; i < size; i++) {\n    dst[i] = src[i];\n  }\n}\n\nfunction makeShape(shape: number[]|TypedArray, isPartial: boolean) {\n  const out: number[] = [];\n  for (let dim of shape) {\n    if (dim < 0) {\n      if (!isPartial) {\n        throw new Error(`Dimension ${dim} must be >= 0`);\n      }\n      if (dim < -1) {\n        throw new Error(`Dimension ${dim} must be >= -1`);\n      }\n      dim = -1;\n    }\n    out.push(dim);\n  }\n\n  return out;\n}\n\nexport function raggedTensorToTensorImpl(\n    shape: TypedArray, shapesShape: number[], values: TypedArray,\n    valuesShape: number[], valuesDType: DataType, defaultValue: TypedArray,\n    defaultValueShape: number[], rowPartitionValues: TypedArray[],\n    rowPartitionValuesShapes: number[][],\n    rowPartitionTypes: string[]): [number[], TypedArray] {\n  return new RaggedTensorToTensorOp(\n             shape, shapesShape, values, valuesShape, valuesDType, defaultValue,\n             defaultValueShape, rowPartitionValues, rowPartitionValuesShapes,\n             rowPartitionTypes)\n      .compute();\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataTypeMap, util} from '@tensorflow/tfjs-core';\n\nexport function rangeImpl(\n    start: number, stop: number, step: number,\n    dtype: 'float32'|'int32'): DataTypeMap['float32' | 'int32'] {\n  const sameStartStop = start === stop;\n  const increasingRangeNegativeStep = start < stop && step < 0;\n  const decreasingRangePositiveStep = stop < start && step > 1;\n\n  if (sameStartStop || increasingRangeNegativeStep ||\n      decreasingRangePositiveStep) {\n    return util.makeZerosTypedArray(0, dtype);\n  }\n\n  const numElements = Math.abs(Math.ceil((stop - start) / step));\n  const values = util.makeZerosTypedArray(numElements, dtype);\n\n  if (stop < start && step === 1) {\n    // Auto adjust the step's sign if it hasn't been set\n    // (or was set to 1)\n    step = -1;\n  }\n\n  values[0] = start;\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n  return values;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));\nexport const rsqrt = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);\n\nexport const rsqrtConfig: KernelConfig = {\n  kernelName: Rsqrt,\n  backendName: 'cpu',\n  kernelFunc: rsqrt,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {buffer, Rank, ShapeMap, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\ninterface DefaultValueTypeMap {\n  bool: boolean;\n  int32: number;\n  float32: number;\n  string: string;\n}\n\nexport function\nscatterImpl<R extends Rank, D extends 'float32'|'int32'|'bool'|'string'>(\n    indices: TensorBuffer<R, 'int32'>, updates: TensorBuffer<R, D>,\n    shape: number[], outputSize: number, sliceSize: number, numUpdates: number,\n    sliceRank: number, strides: number[], defaultValue: DefaultValueTypeMap[D],\n    sumDupeIndices: boolean): TensorBuffer<R, D> {\n  const flattenShape = [outputSize / sliceSize, sliceSize];\n\n  const indicesData = indices.values as TypedArray;\n  const updatesData = updates.values;\n\n  if (outputSize === 0) {\n    return buffer(shape as ShapeMap[R], updates.dtype);\n  }\n\n  const outBuf = buffer(flattenShape, updates.dtype);\n  if (typeof defaultValue === 'string') {\n    (outBuf.values as string[]).fill(defaultValue);\n  } else if (typeof defaultValue === 'number') {\n    (outBuf.values as TypedArray).fill(defaultValue);\n  } else if (typeof defaultValue === 'boolean') {\n    (outBuf.values as TypedArray).fill(+defaultValue);\n  }\n\n  for (let i = 0; i < numUpdates; i++) {\n    const index = [];\n    let flattenIndex = 0;\n    for (let j = 0; j < sliceRank; j++) {\n      const dim = indicesData[i * sliceRank + j];\n      index.push(dim);\n      flattenIndex += dim * strides[j];\n    }\n\n    if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n      throw new Error(`Invalid indices: ${index} does not index into ${shape}`);\n    }\n\n    for (let k = 0; k < sliceSize; k++) {\n      if (sumDupeIndices) {\n        (outBuf.values as TypedArray)[flattenIndex * sliceSize + k] +=\n            (updatesData as TypedArray)[i * sliceSize + k];\n      } else {\n        outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n            updatesData[0] :\n            updatesData[i * sliceSize + k];\n      }\n    }\n  }\n\n  return outBuf as TensorBuffer<R, D>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sigmoid} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sigmoidImpl =\n    createSimpleUnaryImpl((xi) => 1 / (1 + Math.exp(-xi)));\nexport const sigmoid =\n    unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: Sigmoid,\n  backendName: 'cpu',\n  kernelFunc: sigmoid,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BackendValues, buffer, DataType, KernelConfig, KernelFunc, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function sliceImpl(\n    vals: BackendValues, begin: number[], size: number[], shape: number[],\n    dtype: DataType): BackendValues {\n  const isContinous = slice_util.isSliceContinous(shape, begin, size);\n  const length = util.sizeFromShape(size);\n  const xStrides = util.computeStrides(shape);\n\n  if (isContinous) {\n    const flatOffset = slice_util.computeFlatOffset(begin, xStrides);\n\n    if (dtype === 'string') {\n      return (vals as Uint8Array[]).slice(flatOffset, flatOffset + length);\n    }\n\n    return (vals as TypedArray).subarray(flatOffset, flatOffset + length);\n  }\n\n  const decodedData = dtype === 'string' ?\n      backend_util.fromUint8ToStringArray(vals as Uint8Array[]) :\n      vals as TypedArray;\n\n  const inBuf = buffer(shape, dtype, decodedData);\n  const outBuf = buffer(size, dtype);\n  for (let i = 0; i < outBuf.size; ++i) {\n    const outLoc = outBuf.indexToLoc(i);\n    const inLoc = outLoc.map((idx: number, j) => idx + begin[j]);\n    outBuf.set(inBuf.get(...inLoc), ...outLoc);\n  }\n\n  if (dtype === 'string') {\n    return backend_util.fromStringArrayToUint8(outBuf.values as string[]);\n  }\n  return outBuf.values as TypedArray;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendCPU, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  assertNotComplex(x, 'slice');\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  const vals = backend.data.get(x.dataId).values;\n  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);\n  return backend.makeTensorInfo($size, x.dtype, outVals);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'cpu',\n  kernelFunc: slice as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseFillEmptyRowsImpl(\n    indices: TypedArray, indicesShape: number[], indicesDType: DataType,\n    values: TypedArray, valuesDType: DataType, denseShape: TypedArray,\n    defaultValue: number):\n    [TypedArray, number[], TypedArray, boolean[], number[]] {\n  const indicesCount = indicesShape[0];\n  const denseRows = denseShape[0];\n\n  const emptyRowIndicator: boolean[] = new Array(denseRows);\n  const reverseIndexMap: number[] = new Array(indicesCount);\n\n  const rank = indicesShape[1];\n\n  if (denseRows === 0) {\n    if (indicesCount !== 0) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsIndicesDenseShapeMismatch(\n              indicesCount));\n    }\n    const outputIndices = util.getArrayFromDType(indicesDType, 0) as TypedArray;\n    const outputValues = util.getArrayFromDType(valuesDType, 0) as TypedArray;\n    return [\n      outputIndices, [0, rank], outputValues, emptyRowIndicator, reverseIndexMap\n    ];\n  }\n\n  let rowsAreOrdered = true;\n  let lastIndicesRow = 0;\n  const csrOffset: number[] = new Array(denseRows).fill(0);\n\n  for (let i = 0; i < indicesCount; ++i) {\n    // indices is a 2d tensor with shape of [N, rank]\n    const row = indices[i * rank];\n    if (row < 0) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsNegativeIndexErrorMessage(i, row));\n    }\n    if (row >= denseRows) {\n      throw new Error(\n          backend_util.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(\n              i, row, denseRows));\n    }\n    ++csrOffset[row];\n    rowsAreOrdered = rowsAreOrdered && (row >= lastIndicesRow);\n    lastIndicesRow = row;\n  }\n\n  let allRowsFull = true;\n  for (let row = 0; row < denseRows; ++row) {\n    // csrOffset here describes the number of elements in this dense row\n    const rowEmpty = (csrOffset[row] === 0);\n    emptyRowIndicator[row] = rowEmpty;\n    allRowsFull = allRowsFull && !rowEmpty;\n    // In filled version, each row has at least one element.\n    csrOffset[row] = Math.max(csrOffset[row], 1);\n    // Update csrOffset to represent the number of elements up to and\n    // including denseRows + 1:\n    //  csrOffset[0] == #{elements of row 0}\n    //  csrOffset[1] == #{elements of row 1} + #{elements of row 0}\n    //  ..\n    //  csrOffset[i] == starting index for elements in row i + 1.\n    if (row > 0) {\n      csrOffset[row] += csrOffset[row - 1];\n    }\n  }\n\n  if (allRowsFull && rowsAreOrdered) {\n    const outputIndices: TypedArray = indices;\n    const outputValues: TypedArray = values;\n    for (let i = 0; i < indicesCount; ++i) {\n      reverseIndexMap[i] = i;\n    }\n    return [\n      outputIndices, [indicesCount, rank], outputValues, emptyRowIndicator,\n      reverseIndexMap\n    ];\n  } else {\n    const fullIndicesCount = csrOffset[denseRows - 1];\n    const outputIndices =\n        util.getArrayFromDType(indicesDType, fullIndicesCount * rank) as\n        TypedArray;\n    const outputValues =\n        util.getArrayFromDType(valuesDType, fullIndicesCount) as TypedArray;\n    const filledCount: number[] = new Array(denseRows).fill(0);\n\n    // Fill in values for rows that are not missing\n    for (let i = 0; i < indicesCount; ++i) {\n      // indices is a 2d tensor with shape of [N, rank]\n      const row = indices[i * rank];\n      const offset = filledCount[row];\n      const outputI = ((row === 0) ? 0 : csrOffset[row - 1]) + offset;\n      filledCount[row]++;  // Increment the filled count for this row.\n      for (let j = 0; j < rank; ++j) {\n        // indices and outputIndices are 2d tensors with shape of [N, rank]\n        outputIndices[outputI * rank + j] = indices[i * rank + j];\n      }\n      outputValues[outputI] = values[i];\n      // We'll need this reverse index map to backprop correctly.\n      reverseIndexMap[i] = outputI;\n    }\n\n    // Fill in values for rows that are missing\n    for (let row = 0; row < denseRows; ++row) {\n      const rowCount = filledCount[row];\n      if (rowCount === 0) {  // We haven't filled this row\n        const startingIndex = (row === 0) ? 0 : csrOffset[row - 1];\n        // Remaining index values were set to zero already.\n        // Just need to set the row index in the right location.\n        // outputIndices is a 2d tensor with shape of [N, rank]\n        outputIndices[startingIndex * rank + 0] = row;\n        for (let col = 1; col < rank; ++col) {\n          outputIndices[startingIndex * rank + col] = 0;\n        }\n        outputValues[startingIndex] = defaultValue;\n      }\n    }\n    return [\n      outputIndices, [fullIndicesCount, rank], outputValues, emptyRowIndicator,\n      reverseIndexMap\n    ];\n  }\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseReshapeImpl(\n    inputIndices: TypedArray, inputIndicesShape: number[], inputDType: DataType,\n    inputShape: number[],\n    targetShape: number[]): [TypedArray, number[], number[]] {\n  const denseSize = util.sizeFromShape(inputShape);\n  const nnz = inputIndicesShape[0];\n  const outputRank = targetShape.length;\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  const outputShape: number[] = [];\n  let product = 1;\n  let unknownIndex = -1;\n  for (let d = 0; d < outputRank; ++d) {\n    const size = targetShape[d];\n    if (size === -1) {\n      if (unknownIndex !== -1) {\n        throw new Error(\n            backend_util\n                .getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(\n                    unknownIndex, d));\n      }\n      unknownIndex = d;\n      outputShape.push(1);\n    } else {\n      if (size < 0) {\n        throw new Error(\n            backend_util.getSparseReshapeNegativeOutputDimErrorMessage(\n                d, size));\n      }\n      product *= size;\n      outputShape.push(size);\n    }\n  }\n  if (unknownIndex !== -1) {\n    if (product <= 0) {\n      throw new Error(\n          backend_util.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());\n    }\n    const missing = Math.trunc(denseSize / product);\n    if (product * missing !== denseSize) {\n      throw new Error(\n          backend_util.getSparseReshapeInputOutputMultipleErrorMessage(\n              inputShape, outputShape));\n    }\n\n    outputShape[unknownIndex] = missing;\n  }\n  const outputSize = util.sizeFromShape(outputShape);\n  if (outputSize !== denseSize) {\n    throw new Error(\n        backend_util.getSparseReshapeInputOutputMismatchErrorMessage(\n            inputShape, outputShape));\n  }\n\n  const inputRank = inputShape.length;\n  const inputStrides: number[] = [];\n  if (inputRank > 0) {\n    inputStrides[inputRank - 1] = 1;\n    for (let d = inputRank - 2; d >= 0; --d) {\n      inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];\n    }\n  }\n\n  const outputStrides: number[] = [];\n  if (outputRank > 0) {\n    outputStrides[outputRank - 1] = 1;\n    for (let d = outputRank - 2; d >= 0; --d) {\n      outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];\n    }\n  }\n\n  const newIndices =\n      util.getArrayFromDType(inputDType, nnz * outputRank) as TypedArray;\n  for (let i = 0; i < nnz; ++i) {\n    let id = 0;\n    for (let j = 0; j < inputRank; ++j) {\n      // inputIndices is a 2d tensor with shape of [nnz, inputRank]\n      id += inputIndices[i * inputRank + j] * inputStrides[j];\n    }\n    for (let j = 0; j < outputRank; ++j) {\n      // newIndices is a 2d tensor with shape of [nnz, outputRank]\n      newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);\n      id %= outputStrides[j];\n    }\n  }\n  return [newIndices, [nnz, outputRank], outputShape];\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function sparseSegmentReductionImpl(\n    input: TypedArray, inputShape: number[], inputDType: DataType,\n    indices: TypedArray, segmentIds: TypedArray, isMean = false,\n    defaultValue = 0): [TypedArray, number[]] {\n  const numIndices = indices.length;\n\n  // Flatten the array to two dimensions\n  const inputFlat: number[] = [inputShape[0], input.length / inputShape[0]];\n  const numCol = inputFlat[1];\n  // Note that the current implementation assumes that segmentIds values are\n  // sorted.\n  const lastSegmentIdPlusOne =\n      numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;\n  const outputRows = lastSegmentIdPlusOne;\n\n  if (outputRows < 0) {\n    throw new Error(\n        backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());\n  }\n\n  const outputShape = inputShape.slice();\n  outputShape[0] = outputRows;\n\n  const outputLength =\n      outputShape.reduce((product, value) => product * value, 1);\n  // Output array is initialized with the value 0 by default.\n  const output = util.getArrayFromDType(inputDType, outputLength) as TypedArray;\n\n  // Note that we do not initialize the output buffer with a default value, so\n  // we need to explicitly set missing indices to the default value.\n  if (numIndices === 0) {\n    if (outputRows > 0) {\n      output.fill(defaultValue);\n    }\n    return [output, outputShape];\n  }\n\n  if (outputRows <= 0) {\n    throw new Error(\n        backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());\n  }\n\n  let start = 0, end = 1;\n  // Index from which the output is not initialized.\n  let uninitializedIndex = 0;\n  let outIndex = segmentIds[start];\n\n  while (true) {\n    // We initialize nextIndex to 0 to avoid may be uninitialized warning\n    let nextIndex = 0;\n    if (end < numIndices) {\n      nextIndex = segmentIds[end];\n      if (outIndex === nextIndex) {\n        ++end;\n        continue;\n      }\n      // We have a new segment here.  Verify that the segment ids are growing.\n      if (outIndex >= nextIndex) {\n        throw new Error(backend_util\n            .getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());\n      }\n    }\n\n    if (outIndex < 0 || outIndex >= outputRows) {\n      throw new Error(\n          backend_util.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(\n              outIndex, outputRows));\n    }\n\n    // If there is a gap between two indices, we need to set that gap to the\n    // default value.\n    if (outIndex > uninitializedIndex) {\n      output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);\n    }\n\n    for (let i = start; i < end; ++i) {\n      const index = indices[i];\n      if (index < 0 || index >= inputFlat[0]) {\n        throw new Error(\n            backend_util.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(\n                i, indices[i], inputFlat[0]));\n      }\n      for (let j = 0; j < numCol; j++) {\n        output[outIndex * numCol + j] += input[index * numCol + j];\n      }\n    }\n\n    if (isMean) {\n      for (let j = 0; j < numCol; j++) {\n        output[outIndex * numCol + j] /= end - start;\n      }\n    }\n\n    start = end;\n    ++end;\n    uninitializedIndex = outIndex + 1;\n    outIndex = nextIndex;\n    if (end > numIndices) {\n      break;\n    }\n  }\n\n  // Fill the gap at the end with the default value.\n  if (uninitializedIndex < outputRows) {\n    output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);\n  }\n\n  return [output, outputShape];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sqrtImpl = createSimpleUnaryImpl((xi) => Math.sqrt(xi));\nexport const sqrt = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));\n\nexport const sqrtConfig: KernelConfig = {\n  kernelName: Sqrt,\n  backendName: 'cpu',\n  kernelFunc: sqrt,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const squaredDifferenceImpl =\n    createSimpleBinaryKernelImpl(((a: number, b: number) => {\n      const diff = a - b;\n      return diff * diff;\n    }));\nexport const squaredDifference =\n    binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);\n\nexport const squaredDifferenceConfig: KernelConfig = {\n  kernelName: SquaredDifference,\n  backendName: 'cpu',\n  kernelFunc: squaredDifference\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\nexport function stridedSliceImpl<R extends Rank>(\n    outShape: number[], xBuf: TensorBuffer<R>, strides: number[],\n    begin: number[]): TensorBuffer<R> {\n  const outBuf = buffer(outShape, xBuf.dtype);\n\n  for (let i = 0; i < outBuf.size; i++) {\n    const loc = outBuf.indexToLoc(i);\n\n    const newLoc: number[] = new Array(loc.length);\n    for (let j = 0; j < newLoc.length; j++) {\n      newLoc[j] = loc[j] * strides[j] + begin[j];\n    }\n    outBuf.set(xBuf.get(...newLoc), ...loc);\n  }\n\n  return outBuf as TensorBuffer<R>;\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\n\n/**\n * The StringNGramsOp class creates ngrams from ragged string data.\n * The constructor contains all attributes related to the operation such as\n * padding widths and strings, and the compute function can be used to\n * compute the ngrams for different ragged tensor inputs.\n */\nclass StringNGramsOp {\n  private separator: Uint8Array;\n  private nGramWidths: number[];\n  private padWidth: number;\n  private leftPad: Uint8Array;\n  private rightPad: Uint8Array;\n  private preserveShort: boolean;\n\n  constructor(\n      separator: string, nGramWidths: number[], leftPad: string,\n      rightPad: string, padWidth: number, preserveShortSequences: boolean) {\n    this.separator = util.encodeString(separator);\n    this.nGramWidths = nGramWidths;\n    this.leftPad = util.encodeString(leftPad);\n    this.rightPad = util.encodeString(rightPad);\n    this.padWidth = padWidth;\n    this.preserveShort = preserveShortSequences;\n  }\n\n  private getPadWidth(nGramWidth: number) {\n    // Ngrams can be padded with either a fixed pad width or a dynamic pad\n    // width depending on the 'padWidth' arg, but in no case should the padding\n    // ever be wider than 'nGramWidth' - 1.\n    return Math.min(\n        this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);\n  }\n\n  private getNumNGrams(length: number, nGramWidth: number) {\n    const padWidth = this.getPadWidth(nGramWidth);\n    return Math.max(0, ((length + 2 * padWidth) - nGramWidth) + 1);\n  }\n\n  private createNGrams(\n      data: Uint8Array[], splitIndex: number, output: Uint8Array[],\n      outputStartIndex: number, numNGrams: number, nGramWidth: number) {\n    for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {\n      const padWidth = this.getPadWidth(nGramWidth);\n      const leftPadding = Math.max(0, padWidth - nGramIndex);\n      const rightPadding =\n          Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));\n      const numTokens = nGramWidth - (leftPadding + rightPadding);\n      const dataStartIndex =\n          splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);\n\n      // Calculate the total expected size of the nGram so we can reserve the\n      // correct amount of space in the string.\n      let nGramSize = 0;\n      // Size of the left padding.\n      nGramSize += leftPadding * this.leftPad.length;\n      // Size of the tokens.\n      for (let n = 0; n < numTokens; ++n) {\n        nGramSize += data[dataStartIndex + n].length;\n      }\n      // Size of the right padding.\n      nGramSize += rightPadding * this.rightPad.length;\n      // Size of the separators.\n      const numSeparators = leftPadding + rightPadding + numTokens - 1;\n      nGramSize += numSeparators * this.separator.length;\n\n      // Build the nGram.\n      output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);\n      const nGram = output[outputStartIndex + nGramIndex];\n\n      let nextNGramIndex = 0;\n      const appendToNGram = (str: Uint8Array) =>\n          str.forEach((value) => nGram[nextNGramIndex++] = value);\n\n      for (let n = 0; n < leftPadding; ++n) {\n        appendToNGram(this.leftPad);\n        appendToNGram(this.separator);\n      }\n      // Only output first numTokens - 1 pairs of data and separator\n      for (let n = 0; n < numTokens - 1; ++n) {\n        appendToNGram(data[dataStartIndex + n]);\n        appendToNGram(this.separator);\n      }\n      // Handle case when there are no tokens or no right padding as these\n      // can result in consecutive separators.\n      if (numTokens > 0) {\n        // If we have tokens, then output last and then pair each separator\n        // with the right padding that follows, to ensure nGram ends either with\n        // the token or with the right pad.\n        appendToNGram(data[dataStartIndex + numTokens - 1]);\n        for (let n = 0; n < rightPadding; ++n) {\n          appendToNGram(this.separator);\n          appendToNGram(this.rightPad);\n        }\n      } else {\n        // If we don't have tokens, then the last item inserted into the nGram\n        // has been the separator from the left padding loop above. Hence,\n        // output right pad and separator and make sure to finish with a\n        // padding, not a separator.\n        for (let n = 0; n < rightPadding - 1; ++n) {\n          appendToNGram(this.rightPad);\n          appendToNGram(this.separator);\n        }\n        appendToNGram(this.rightPad);\n      }\n    }\n  }\n\n  // Data and splits together form the definition of the ragged tensor,\n  // where data is 1 dimensional and contains the values of the tensor\n  // and splits denotes the indices at which each row starts.\n  public compute(data: Uint8Array[], splits: Int32Array):\n      [Uint8Array[], Int32Array] {\n    // Validate that the splits are valid indices into data, only if there are\n    // splits specified.\n    const inputDataSize = data.length;\n    const splitsSize = splits.length;\n    if (splitsSize > 0) {\n      let prevSplit = splits[0];\n      if (prevSplit !== 0) {\n        throw new Error(`First split value must be 0, got ${prevSplit}`);\n      }\n      for (let i = 1; i < splitsSize; ++i) {\n        let validSplits = splits[i] >= prevSplit;\n        validSplits = validSplits && (splits[i] <= inputDataSize);\n        if (!validSplits) {\n          throw new Error(`Invalid split value ${splits[i]}, must be in [${\n              prevSplit}, ${inputDataSize}]`);\n        }\n        prevSplit = splits[i];\n      }\n      if (prevSplit !== inputDataSize) {\n        throw new Error(`Last split value must be data size. Expected ${\n            inputDataSize}, got ${prevSplit}`);\n      }\n    }\n\n    const numBatchItems = splitsSize - 1;\n    const nGramsSplits = util.getArrayFromDType('int32', splitsSize);\n    // If there is no data or size, return an empty ragged tensor.\n    if (inputDataSize === 0 || splitsSize === 0) {\n      const empty: Uint8Array[] = new Array(inputDataSize);\n      for (let i = 0; i <= numBatchItems; ++i) {\n        nGramsSplits[i] = 0;\n      }\n      return [empty, nGramsSplits];\n    }\n\n    nGramsSplits[0] = 0;\n    for (let i = 1; i <= numBatchItems; ++i) {\n      const length = splits[i] - splits[i - 1];\n      let numNGrams = 0;\n      this.nGramWidths.forEach((nGramWidth) => {\n        numNGrams += this.getNumNGrams(length, nGramWidth);\n      });\n      if (this.preserveShort && length > 0 && numNGrams === 0) {\n        numNGrams = 1;\n      }\n      nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;\n    }\n\n    const nGrams: Uint8Array[] = new Array(nGramsSplits[numBatchItems]);\n\n    for (let i = 0; i < numBatchItems; ++i) {\n      const splitIndex = splits[i];\n      let outputStartIdx = nGramsSplits[i];\n      this.nGramWidths.forEach((nGramWidth) => {\n        const length = splits[i + 1] - splits[i];\n        const numNGrams = this.getNumNGrams(length, nGramWidth);\n        this.createNGrams(\n            data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n        outputStartIdx += numNGrams;\n      });\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (nGramSplitsdata). If no ngrams were generated, then they will\n      // be equal (since we increment outputStartIdx by numNGrams every\n      // time we create a set of ngrams.)\n      if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {\n        const dataLength = splits[i + 1] - splits[i];\n        // One legitimate reason to not have any ngrams when this.preserveShort\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (dataLength === 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one nGram.\n        const nGramWidth = dataLength + 2 * this.padWidth;\n        const numNGrams = 1;\n        this.createNGrams(\n            data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);\n      }\n    }\n    return [nGrams, nGramsSplits];\n  }\n}\n\nexport function stringNGramsImpl(\n    data: Uint8Array[], dataSplits: Int32Array, separator: string,\n    nGramWidths: number[], leftPad: string, rightPad: string, padWidth: number,\n    preserveShortSequences: boolean): [Uint8Array[], Int32Array] {\n  return new StringNGramsOp(\n             separator, nGramWidths, leftPad, rightPad, padWidth,\n             preserveShortSequences)\n      .compute(data, dataSplits);\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nfunction split(\n    str: Uint8Array, delimiters: Uint8Array, skipEmpty: boolean,\n    result: Uint8Array[]): void {\n  if (!str.length) {\n    return;\n  }\n  // When the delimiter is empty, the input is split into individual characters.\n  if (delimiters.length === 0) {\n    for (let i = 0; i < str.length; ++i) {\n      result.push(str.subarray(i, i + 1));\n    }\n    return;\n  }\n  // When there is one delimiter, the input is split only at that delimiter.\n  if (delimiters.length === 1) {\n    const delimiter = delimiters[0];\n    let f = str.indexOf(delimiter);\n    while (f !== -1) {\n      const token = str.subarray(0, f);\n      if (!skipEmpty || token.length !== 0) {\n        result.push(token);\n      }\n      str = str.subarray(f + 1);\n      f = str.indexOf(delimiter);\n    }\n    if (!skipEmpty || str.length !== 0) {\n      result.push(str);\n    }\n    return;\n  }\n  // When there are multiple delimiters, the input is split at every instance\n  // one of the delimiters appears.\n  let tokenStart = 0;\n  for (let i = 0; i < str.length + 1; i++) {\n    if ((i === str.length) || (delimiters.indexOf(str[i]) !== -1)) {\n      const token = str.subarray(tokenStart, i);\n      if (!skipEmpty || token.length !== 0) {\n        result.push(token);\n      }\n      tokenStart = i + 1;\n    }\n  }\n}\n\nexport function stringSplitImpl(\n    input: Uint8Array[], delimiter: Uint8Array,\n    skipEmpty: boolean): [TypedArray, Uint8Array[], [number, number]] {\n  const batchSize = input.length;\n\n  // Empty delimiter means split the input character by character.\n  const tokens: Uint8Array[] = [];\n\n  let outputSize = 0;\n  let maxNumEntries = 0;\n  const numIndices: number[] = new Array(batchSize);\n  for (let i = 0; i < batchSize; ++i) {\n    const prevTokensLength = tokens.length;\n    split(input[i], delimiter, skipEmpty, tokens);\n    const nEntries = tokens.length - prevTokensLength;\n    numIndices[i] = nEntries;\n    outputSize += nEntries;\n    maxNumEntries = Math.max(maxNumEntries, nEntries);\n  }\n\n  const indices = util.getArrayFromDType('int32', outputSize * 2) as TypedArray;\n  const values: Uint8Array[] = new Array(outputSize);\n  const shape: [number, number] = [batchSize, maxNumEntries];\n\n  let c = 0;\n  for (let i = 0; i < batchSize; ++i) {\n    for (let j = 0; j < numIndices[i]; ++j) {\n      // indices is a 2d tensor with shape of [outputSize, 2]\n      indices[c * 2] = i;\n      indices[c * 2 + 1] = j;\n      values[c] = tokens[c];\n      ++c;\n    }\n  }\n\n  return [indices, values, shape];\n}\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function stringToHashBucketFastImpl(\n    input: Uint8Array[], numBuckets: number): TypedArray {\n  const output = util.getArrayFromDType('int32', input.length) as TypedArray;\n\n  for (let i = 0; i < input.length; ++i) {\n    output[i] =\n        util.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();\n  }\n\n  return output;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/binary_utils';\n\nexport const subImpl = createSimpleBinaryKernelImpl(\n    ((aValue: number, bValue: number) => aValue - bValue));\nexport const subComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal - bReal, imag: aImag - bImag};\n    }));\nexport const sub = binaryKernelFunc(Sub, subImpl, subComplexImpl);\n\nexport const subConfig: KernelConfig = {\n  kernelName: Sub,\n  backendName: 'cpu',\n  kernelFunc: sub\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, DataType, Rank, TensorBuffer} from '@tensorflow/tfjs-core';\n\n/**\n * An implementation of the tile kernel shared between webgl and cpu for string\n * tensors only.\n */\n\nexport function tileImpl<R extends Rank>(\n    xBuf: TensorBuffer<R, DataType>,\n    reps: number[]): TensorBuffer<R, DataType> {\n  const newShape: number[] = new Array(xBuf.rank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = xBuf.shape[i] * reps[i];\n  }\n  const result = buffer(newShape, xBuf.dtype);\n  for (let i = 0; i < result.values.length; ++i) {\n    const newLoc = result.indexToLoc(i);\n\n    const originalLoc: number[] = new Array(xBuf.rank);\n    for (let j = 0; j < originalLoc.length; j++) {\n      originalLoc[j] = newLoc[j] % xBuf.shape[j];\n    }\n\n    const originalIndex = xBuf.locToIndex(originalLoc);\n\n    result.values[i] = xBuf.values[originalIndex];\n  }\n  return result as TensorBuffer<R, DataType>;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/** An implementation of the TopK kernel shared between webgl and cpu. */\n\nimport {buffer, NumericDataType, Rank, ShapeMap, Tensor, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\ntype Pair = {\n  value: number,\n  index: number\n};\n\nconst comparePair = (a: Pair, b: Pair) => {\n  const valueDiff = b.value - a.value;\n  return valueDiff === 0 ? a.index - b.index : valueDiff;\n};\n\n/**\n * Partitions array where all elements smaller than the (k+1) smallest element\n * are found to the left of it, and all larger to the right of it.\n * Based on the Floyd-Rivest Algorithm, ref:\n * https://en.wikipedia.org/wiki/Floyd%E2%80%93Rivest_algorithm\n * @param array: Array to partition\n * @param left: Left index for the interval\n * @param right: Right index for the interval\n * @param k: Desired index value, where array[k] is the (k+1)th smallest element\n *           when left = 0\n */\nfunction select(array: Pair[], k: number, left = 0, right = array.length - 1) {\n  while (right > left) {\n    // Use select recursively to sample a smaller set of size s\n    // the arbitrary constants 600 and 0.5 are used in the original\n    // version to minimize execution time.\n    if (right - left > 600) {\n      const n = right - left + 1;\n      const i = k - left + 1;\n      const z = Math.log(n);\n      const s = 0.5 * Math.exp(2 * z / 3);\n      const sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * Math.sign(i - n / 2);\n      const newLeft = Math.max(left, Math.floor(k - i * s / n + sd));\n      const newRight = Math.min(right, Math.floor(k + (n - i) * s / n + sd));\n      select(array, k, newLeft, newRight);\n    }\n    // partition the elements between left and right around t\n    const t = array[k];\n    let i = left;\n    let j = right;\n\n    util.swap(array, left, k);\n\n    if (comparePair(array[right], t) > 0) {\n      util.swap(array, left, right);\n    }\n    while (i < j) {\n      util.swap(array, i, j);\n      i++;\n      j--;\n      while (comparePair(array[i], t) < 0) {\n        i = i + 1;\n      }\n      while (comparePair(array[j], t) > 0) {\n        j = j - 1;\n      }\n    }\n    if (comparePair(array[left], t) === 0) {\n      util.swap(array, left, j);\n    } else {\n      j = j + 1;\n      util.swap(array, j, right);\n    }\n    // Adjust left and right towards the boundaries of the subset\n    // containing the (k - left + 1)th smallest element.\n    if (j <= k) {\n      left = j + 1;\n    }\n    if (k <= j) {\n      right = j - 1;\n    }\n  }\n}\n\nexport function topKImpl<T extends Tensor, R extends Rank>(\n    x: TypedArray, xShape: number[], xDtype: NumericDataType, k: number,\n    sorted: boolean):\n    [TensorBuffer<R, NumericDataType>, TensorBuffer<R, 'int32'>] {\n  // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n  const lastDim = xShape[xShape.length - 1];\n  const [batch, size] = [x.length / lastDim, lastDim];\n  const allTopKVals = util.getTypedArrayFromDType(xDtype, batch * k);\n  const allTopKIndices = util.getTypedArrayFromDType('int32', batch * k);\n\n  for (let b = 0; b < batch; b++) {\n    const offset = b * size;\n    const vals = x.subarray(offset, offset + size);\n\n    let valAndInd: Pair[] = new Array(vals.length);\n    vals.forEach(\n        (value: number, index: number) => valAndInd[index] = {value, index});\n\n    if (k < valAndInd.length) {\n      select(valAndInd, k);\n      valAndInd = valAndInd.slice(0, k);\n    }\n\n    if (sorted) {\n      valAndInd.sort(comparePair);\n    }\n    \n    const outOffset = b * k;\n    const topKVals = allTopKVals.subarray(outOffset, outOffset + k);\n    const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);\n    for (let i = 0; i < k; i++) {\n      topKVals[i] = valAndInd[i].value;\n      topKIndices[i] = valAndInd[i].index;\n    }\n  }\n  // Reshape back to the original input shape, except that the last\n  // dimension is k.\n  const outputShape = xShape.slice();\n  outputShape[outputShape.length - 1] = k;\n\n  return [\n    buffer(outputShape as ShapeMap[R], xDtype, allTopKVals),\n    buffer(outputShape as ShapeMap[R], 'int32', allTopKIndices)\n  ];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendValues, DataType, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function uniqueImpl(\n    values: BackendValues, axis: number, shape: number[], dtype: DataType): {\n  outputValues: BackendValues,\n  outputShape: number[],\n  indices: BackendValues\n} {\n  // Normalize and validate axis.\n  const $axis = util.parseAxisParam(axis, shape)[0];\n\n  // Calculate the new shape that is suitable for extracting data along the\n  // given axis.\n  //\n  // The rank is 3.\n  // The size of the 1st dimension is the size of all the axes < the given axis.\n  // The size of the 2nd dimension is the same as the size of the given axis.\n  // The size of the 3rd dimension is the size of all the axes > the given axis.\n  //\n  // For example, for a 4D tensor with shape=[2, 3, 5, 4] and axis=2, the\n  // newShape would be: [2*3, 5, 4].\n  //\n  // Note that this is not the final output shape. This will be the shape for an\n  // intermediate TensorBuffer (see inputBuffer below) to allow us to extract\n  // values along the given axis. To demonstrate how it works, consider the\n  // following example:\n  //\n  // Input: a 3D tensor, with shape [1, 2, 3]\n  // [\n  //   [\n  //      [1,2,3],\n  //      [4,5,6]\n  //   ]\n  // ]\n  // Axis: 2 (the last axis).\n  // Along axis 2, we expect to extract 3 tensors: [1,4], [2,5], [3,6].\n  //\n  // For this example, newShape would be: [2, 3, 1], where 2 is calculated from\n  // 1*2. The re-shaped data would look like:\n  //\n  // [\n  //   [\n  //     [1], [2], [3]\n  //   ],\n  //   [\n  //     [4], [5], [6]\n  //   ]\n  // ]\n  //\n  // Then, we can construct a 3-level nested loop by the following dimension\n  // order to extract the values along the axis (dimension1):\n  // i: dimension1       // 0,1,2 (newShape[1])\n  //   m: dimension0     // 0,1   (newShape[0])\n  //     n: dimension2   // 0     (newShape[2])\n  //\n  //                       m, i, n\n  //                      ---------\n  // Iteration 0: data at [0, 0, 0] => \"1\"\n  // Iteration 1: data at [1, 0, 0] => \"4\"\n  // We got [1,4].\n  // Iteration 2: data at [0, 1, 0] => \"2\"\n  // Iteration 3: data at [1, 1, 0] => \"5\"\n  // We got [2,5].\n  // Iteration 4: data at [0, 2, 0] => \"3\"\n  // Iteration 5: data at [1, 2, 0] => \"6\"\n  // We got [3,6].\n  const newShape = [1, shape[0], 1];\n  for (let i = 0; i < $axis; i++) {\n    newShape[0] *= shape[i];\n  }\n  newShape[1] = shape[$axis];\n  for (let i = $axis + 1; i < shape.length; i++) {\n    newShape[2] *= shape[i];\n  }\n\n  // A map from unique elements (their string representations) to their values\n  // in \"indices\" (below).\n  const uniqueElements: {[key: string]: number} = {};\n  // The indices of each unique element in the original tensor along the given\n  // axis. It is 1D and has the same size as the given axis.\n  const indices = new Int32Array(shape[$axis]);\n  // Create a buffer so we can easily extract value at a given location.\n  const inputBuffer = new TensorBuffer(newShape, dtype, values as TypedArray);\n  // The indices along the given axis that have unique elements. This is a\n  // de-duped version of \"indices\" above.\n  const uniqueIndices: number[] = [];\n  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;\n  for (let i = 0; i < shape[$axis]; i++) {\n    // Extract values along the axis.\n    let element: string;\n    if (is1DTensor) {\n      // Fast path for 1D tensor input.\n      element = values[i].toString();\n    } else {\n      const axisValues = [];\n      for (let m = 0; m < newShape[0]; m++) {\n        for (let n = 0; n < newShape[2]; n++) {\n          axisValues.push(inputBuffer.get(m, i, n));\n        }\n      }\n      element = axisValues.join(',');\n    }\n\n    // Dedup and update various indices.\n    if (uniqueElements[element] !== undefined) {\n      indices[i] = uniqueElements[element];\n    } else {\n      const uniqueIndex = Object.keys(uniqueElements).length;\n      uniqueElements[element] = uniqueIndex;\n      indices[i] = uniqueIndex;\n      uniqueIndices.push(i);\n    }\n  }\n\n  // Now we know where each of the unique elements are located along the axis\n  // (uniqueIndices). Extract them from input buffer and store them in the\n  // output buffer.\n  const outputTmpShape = newShape.slice();\n  outputTmpShape[1] = Object.keys(uniqueElements).length;\n  const outputBuffer = new TensorBuffer(outputTmpShape, dtype);\n  uniqueIndices.forEach((uniqueElementIndex, i) => {\n    for (let m = 0; m < newShape[0]; m++) {\n      for (let n = 0; n < newShape[2]; n++) {\n        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);\n      }\n    }\n  });\n\n  // The output shape can be calculated from the input shape with the size of\n  // the given axis replaced by the number of unique elements along that axis.\n  const outputShape = shape.slice();\n  outputShape[$axis] = outputTmpShape[1];\n\n  return {\n    outputValues: outputBuffer.values as BackendValues,\n    outputShape,\n    indices,\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/*\n * base.ts contains all the exports from tfjs-backend-cpu\n * without auto-kernel registration\n */\nimport {registerBackend} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from './backend_cpu';\nimport * as shared from './shared';\n\nexport {MathBackendCPU} from './backend_cpu';\nexport {version as version_cpu} from './version';\nexport {shared};\n\n// Side effects for default initialization of MathBackendCPU\nregisterBackend('cpu', () => new MathBackendCPU(), 1 /* priority */);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Elu, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const elu =\n    unaryKernelFunc(Elu, (xi) => xi >= 0 ? xi : (Math.exp(xi) - 1));\n\nexport const eluConfig: KernelConfig = {\n  kernelName: Elu,\n  backendName: 'cpu',\n  kernelFunc: elu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LeakyRelu, LeakyReluAttrs, LeakyReluInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function leakyRelu(args: {\n  inputs: LeakyReluInputs,\n  backend: MathBackendCPU,\n  attrs: LeakyReluAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {alpha} = attrs;\n\n  assertNotComplex([x], 'leakyRelu');\n\n  const xSize = util.sizeFromShape(x.shape);\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const outVals = util.getTypedArrayFromDType('float32', xSize);\n\n  for (let i = 0; i < xVals.length; i++) {\n    outVals[i] = xVals[i] < 0 ? alpha * xVals[i] : xVals[i];\n  }\n\n  return backend.makeTensorInfo(x.shape, 'float32', outVals);\n}\n\nexport const leakyReluConfig: KernelConfig = {\n  kernelName: LeakyRelu,\n  backendName: 'cpu',\n  kernelFunc: leakyRelu as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Prelu, PreluInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\n\nconst preluImpl = createSimpleBinaryKernelImpl(\n    (xValue: number, aValue: number) => xValue < 0 ? aValue * xValue : xValue);\n\nexport function prelu(args: {inputs: PreluInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x, alpha} = inputs;\n\n  assertNotComplex([x, alpha], 'prelu');\n\n  const aVals = backend.data.get(x.dataId).values as TypedArray;\n  const bVals = backend.data.get(alpha.dataId).values as TypedArray;\n\n  const [resultData, resultShape] =\n      preluImpl(x.shape, alpha.shape, aVals, bVals, 'float32');\n\n  return backend.makeTensorInfo(resultShape, 'float32', resultData);\n}\n\nexport const preluConfig: KernelConfig = {\n  kernelName: Prelu,\n  backendName: 'cpu',\n  kernelFunc: prelu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const relu = unaryKernelFunc(Relu, (xi) => Math.max(0, xi));\n\nexport const reluConfig: KernelConfig = {\n  kernelName: Relu,\n  backendName: 'cpu',\n  kernelFunc: relu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu6} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const relu6 =\n    unaryKernelFunc(Relu6, (xi) => Math.min(Math.max(0, xi), 6));\n\nexport const relu6Config: KernelConfig = {\n  kernelName: Relu6,\n  backendName: 'cpu',\n  kernelFunc: relu6,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {elu} from '../kernels/Elu';\nimport {identity} from '../kernels/Identity';\nimport {leakyRelu} from '../kernels/LeakyRelu';\nimport {prelu} from '../kernels/Prelu';\nimport {relu} from '../kernels/Relu';\nimport {relu6} from '../kernels/Relu6';\nimport {sigmoid} from '../kernels/Sigmoid';\n\nexport function applyActivation(\n    backend: MathBackendCPU, x: TensorInfo, activation: backend_util.Activation,\n    preluActivationWeights?: TensorInfo, leakyreluAlpha?: number): TensorInfo {\n  if (activation === 'linear') {\n    return identity({inputs: {x}, backend});\n  } else if (activation === 'relu') {\n    return relu({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'elu') {\n    return elu({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'relu6') {\n    return relu6({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'prelu') {\n    return prelu({inputs: {x, alpha: preluActivationWeights}, backend});\n  } else if (activation === 'leakyrelu') {\n    return leakyRelu({inputs: {x}, backend, attrs: {alpha: leakyreluAlpha}});\n  } else if (activation === 'sigmoid') {\n    return sigmoid({inputs: {x}, backend}) as TensorInfo;\n  }\n  throw new Error(\n      `Activation ${activation} has not been implemented for the CPU backend.`);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reshape, ReshapeAttrs, ReshapeInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function reshape(\n    args:\n        {inputs: ReshapeInputs, backend: MathBackendCPU, attrs: ReshapeAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {shape} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const $shape = util.inferFromImplicitShape(shape, xSize);\n  const $xSize = util.sizeFromShape($shape);\n\n  util.assert(\n      xSize === $xSize,\n      () => `The new shape (${$shape}) has ${$xSize} elements and the old ` +\n          `shape (${x.shape}) has ${xSize} elements. The new shape and old ` +\n          `shape must have the same number of elements.`);\n\n  backend.incRef(x.dataId);\n\n  const xData = backend.data.get(x.dataId);\n\n  if (xData.complexTensorInfos != null) {\n    const real = xData.complexTensorInfos.real;\n    const imag = xData.complexTensorInfos.imag;\n\n    real.shape = $shape;\n    imag.shape = $shape;\n  }\n\n  return {dataId: x.dataId, shape: $shape, dtype: x.dtype};\n}\n\nexport const reshapeConfig: KernelConfig = {\n  kernelName: Reshape,\n  backendName: 'cpu',\n  kernelFunc: reshape as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, broadcast_util, buffer, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {reshape} from './Reshape';\n\nexport function batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  attrs: BatchMatMulAttrs,\n  backend: MathBackendCPU\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  assertNotComplex([a, b], 'matMul');\n\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(\n      a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] :\n                                [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] :\n                                [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n\n  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n\n  const a3dValues = backend.data.get(a3d.dataId).values as TypedArray;\n  const b3dValues = backend.data.get(b3d.dataId).values as TypedArray;\n\n  const a3dStrides = util.computeStrides(a3d.shape);\n  const b3dStrides = util.computeStrides(b3d.shape);\n\n  const [aBatch, aOuterStep, aInnerStep] = transposeA ?\n      [a3dStrides[0], 1, a3dStrides[1]] :\n      [a3dStrides[0], a3dStrides[1], 1];\n  const [bInnerStep, bOuterStep, bBatch] = transposeB ?\n      [1, b3dStrides[1], b3dStrides[0]] :\n      [b3dStrides[1], 1, b3dStrides[0]];\n\n  const size = leftDim * rightDim;\n  const result = buffer([batchDim, leftDim, rightDim], a3d.dtype);\n\n  const resVals = result.values as TypedArray;\n  const blockSize = backend.blockSize;\n\n  for (let bi = 0; bi < batchDim; bi++) {\n    for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n      for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n        for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n          // for when blockSize doesn't evenly divide the input\n          const iBlock = Math.min(i0 + blockSize, leftDim);\n          const jBlock = Math.min(j0 + blockSize, rightDim);\n          const kBlock = Math.min(k0 + blockSize, sharedDim);\n\n          for (let i = i0; i < iBlock; i++) {\n            for (let j = j0; j < jBlock; j++) {\n              let sum = 0.0;\n\n              for (let k = k0; k < kBlock; k++) {\n                const batchOffsetA = Math.min(bi, batchDimA - 1) * aBatch;\n                const batchOffsetB = Math.min(bi, batchDimB - 1) * bBatch;\n                const aVal =\n                    a3dValues[batchOffsetA + i * aOuterStep + k * aInnerStep];\n                const bVal =\n                    b3dValues[k * bInnerStep + j * bOuterStep + batchOffsetB];\n                sum += aVal * bVal;\n              }\n              resVals[bi * size + (i * rightDim + j)] += sum;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  backend.disposeIntermediateTensorInfo(a3d);\n  backend.disposeIntermediateTensorInfo(b3d);\n\n  // set correct shape on output.\n  return backend.makeTensorInfo(\n      outShape, result.dtype, result.values as TypedArray);\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'cpu',\n  kernelFunc: batchMatMul as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\n\nimport {add} from './Add';\nimport {batchMatMul} from './BatchMatMul';\n\nexport function _fusedMatMul(args: {\n  inputs: _FusedMatMulInputs,\n  attrs: _FusedMatMulAttrs,\n  backend: MathBackendCPU\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b, bias, preluActivationWeights} = inputs;\n  const {transposeA, transposeB, activation, leakyreluAlpha} = attrs;\n\n  let current;\n  let addRes;\n  let activationRes;\n\n  const intermediates: TensorInfo[] = [];\n\n  const matMulRes =\n      batchMatMul({inputs: {a, b}, attrs: {transposeA, transposeB}, backend});\n  current = matMulRes;\n\n  if (bias) {\n    addRes = add({inputs: {a: current, b: bias}, backend}) as TensorInfo;\n    intermediates.push(current);\n    current = addRes;\n  }\n  if (activation) {\n    activationRes = applyActivation(\n        backend, current, activation, preluActivationWeights, leakyreluAlpha);\n    intermediates.push(current);\n    current = activationRes;\n  }\n\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return current;\n}\n\nexport const _fusedMatMulConfig: KernelConfig = {\n  kernelName: _FusedMatMul,\n  backendName: 'cpu',\n  kernelFunc: _fusedMatMul as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acos = unaryKernelFunc(Acos, (xi) => Math.acos(xi));\n\nexport const acosConfig: KernelConfig = {\n  kernelName: Acos,\n  backendName: 'cpu',\n  kernelFunc: acos,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acosh = unaryKernelFunc(Acosh, (xi) => Math.acosh(xi));\n\nexport const acoshConfig: KernelConfig = {\n  kernelName: Acosh,\n  backendName: 'cpu',\n  kernelFunc: acosh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AddN, AddNInputs, buffer, KernelConfig, KernelFunc, Tensor, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function addN(args: {inputs: AddNInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const tensors = inputs as Tensor[];\n\n  assertNotComplex(inputs, 'addN');\n\n  const vals =\n      tensors.map(t => backend.data.get(t.dataId).values as TypedArray);\n  const outBuf = buffer(tensors[0].shape, tensors[0].dtype as 'float32');\n  const outVals = outBuf.values;\n  for (let i = 0; i < tensors.length; i++) {\n    const currVals = vals[i];\n    for (let j = 0; j < outVals.length; j++) {\n      outVals[j] += currVals[j];\n    }\n  }\n\n  return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\n\nexport const addNConfig: KernelConfig = {\n  kernelName: AddN,\n  backendName: 'cpu',\n  kernelFunc: addN as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {All, AllAttrs, AllInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function all(\n    args: {inputs: AllInputs, backend: MathBackendCPU, attrs: AllAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'all');\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    axes = backend_util.getInnerMostAxes(axes.length, x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('all', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = util.makeZerosTypedArray(util.sizeFromShape(outShape), $x.dtype);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let all = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      all = all && value;\n    }\n    vals[i] = all;\n  }\n\n  if (permutedAxes != null) {\n    backend.disposeIntermediateTensorInfo($x);\n  }\n\n  const result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n\n  if (keepDims) {\n    const expandedShape = backend_util.expandShapeToKeepDim(outShape, origAxes);\n    const reshapedResult =\n        reshape({inputs: {x: result}, backend, attrs: {shape: expandedShape}});\n\n    backend.disposeIntermediateTensorInfo(result);\n\n    return reshapedResult;\n  }\n\n  return result;\n}\n\nexport const allConfig: KernelConfig = {\n  kernelName: All,\n  backendName: 'cpu',\n  kernelFunc: all as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Any, AnyAttrs, AnyInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function any(\n    args: {inputs: AnyInputs, backend: MathBackendCPU, attrs: AnyAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'any');\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    axes = backend_util.getInnerMostAxes(axes.length, x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('any', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = util.makeZerosTypedArray(util.sizeFromShape(outShape), $x.dtype);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let anyVal = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      anyVal = anyVal || value;\n    }\n    vals[i] = anyVal;\n  }\n\n  if (permutedAxes != null) {\n    backend.disposeIntermediateTensorInfo($x);\n  }\n\n  const result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n\n  if (keepDims) {\n    const expandedShape = backend_util.expandShapeToKeepDim(outShape, origAxes);\n    const reshapedResult =\n        reshape({inputs: {x: result}, backend, attrs: {shape: expandedShape}});\n\n    backend.disposeIntermediateTensorInfo(result);\n\n    return reshapedResult;\n  }\n\n  return result;\n}\n\nexport const anyConfig: KernelConfig = {\n  kernelName: Any,\n  backendName: 'cpu',\n  kernelFunc: any as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMax, ArgMaxAttrs, ArgMaxInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function argMax(\n    args: {inputs: ArgMaxInputs, backend: MathBackendCPU, attrs: ArgMaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  assertNotComplex(x, 'argMax');\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  axes = [axes[0]];\n  backend_util.assertAxesAreInnerMostDims('argMax', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n\n  const outSize = util.sizeFromShape(outShape);\n  const vals = util.makeZerosTypedArray(outSize, 'int32');\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    let maxIndex = 0;\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value > max) {\n        max = value;\n        maxIndex = j;\n      }\n    }\n    vals[i] = maxIndex;\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(outShape, 'int32', vals);\n}\n\nexport const argMaxConfig: KernelConfig = {\n  kernelName: ArgMax,\n  backendName: 'cpu',\n  kernelFunc: argMax as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ArgMin, ArgMinAttrs, ArgMinInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function argMin(\n    args: {inputs: ArgMinInputs, backend: MathBackendCPU, attrs: ArgMinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis} = attrs;\n\n  assertNotComplex(x, 'argMin');\n\n  let axes = util.parseAxisParam(axis, x.shape);\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  const intermediateTensorInfos = [];\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    intermediateTensorInfos.push($x);\n    axes = backend_util.getInnerMostAxes(axes.length, $x.shape.length);\n  }\n\n  axes = [axes[0]];\n  backend_util.assertAxesAreInnerMostDims('argMin', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n\n  const outSize = util.sizeFromShape(outShape);\n  const vals = util.makeZerosTypedArray(outSize, 'int32');\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let min = aVals[offset];\n    let minIndex = 0;\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value < min) {\n        min = value;\n        minIndex = j;\n      }\n    }\n    vals[i] = minIndex;\n  }\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return backend.makeTensorInfo(outShape, 'int32', vals);\n}\n\nexport const argMinConfig: KernelConfig = {\n  kernelName: ArgMin,\n  backendName: 'cpu',\n  kernelFunc: argMin as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asin, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asin = unaryKernelFunc(Asin, (xi) => Math.asin(xi));\n\nexport const asinConfig: KernelConfig = {\n  kernelName: Asin,\n  backendName: 'cpu',\n  kernelFunc: asin,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asinh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asinh = unaryKernelFunc(Asinh, (xi) => Math.asinh(xi));\n\nexport const asinhConfig: KernelConfig = {\n  kernelName: Asinh,\n  backendName: 'cpu',\n  kernelFunc: asinh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atan = unaryKernelFunc(Atan, (xi) => Math.atan(xi));\n\nexport const atanConfig: KernelConfig = {\n  kernelName: Atan,\n  backendName: 'cpu',\n  kernelFunc: atan,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan2, KernelConfig} from '@tensorflow/tfjs-core';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const atan2Impl = createSimpleBinaryKernelImpl(\n    (aValue, bValue) => Math.atan2(aValue as number, bValue as number));\n\nexport const atan2 = binaryKernelFunc(Atan2, atan2Impl);\n\nexport const atan2Config: KernelConfig = {\n  kernelName: Atan2,\n  backendName: 'cpu',\n  kernelFunc: atan2,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atanh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atanh = unaryKernelFunc(Atanh, (xi) => Math.atanh(xi));\n\nexport const atanhConfig: KernelConfig = {\n  kernelName: Atanh,\n  backendName: 'cpu',\n  kernelFunc: atanh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function pool(\n    xValues: TypedArray, xShape: number[], dtype: DataType, strides: number[],\n    convInfo: backend_util.Conv2DInfo,\n    poolType: 'max'|'avg'): TensorBuffer<Rank, DataType> {\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const initialValue =\n      (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n\n  const output = buffer(convInfo.outShape, dtype);\n  const outputVals = output.values;\n\n  const outputBatchStrides =\n      convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];\n  const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];\n  const outputColStrides = convInfo.outShape[3];\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const outputBatchOffset = b * outputBatchStrides;\n    const inputBatchOffset = b * strides[0];\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        const outputRowOffset = outputBatchOffset + yR * outputRowStrides;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          const xCMin = Math.max(0, xCCorner);\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let minMaxValue = initialValue;\n          let avgValue = 0;\n          let count = 0;\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const xROffset = inputBatchOffset + xR * strides[1];\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const xCOffset = xROffset + xC * strides[2];\n              const pixel = xValues[xCOffset + d];\n              if ((poolType === 'max' && pixel > minMaxValue)) {\n                minMaxValue = pixel;\n              } else if (poolType === 'avg') {\n                avgValue += pixel;\n                count++;\n              }\n            }\n            if (isNaN(minMaxValue)) {\n              break;\n            }\n          }\n          const outputOffset = outputRowOffset + yC * outputColStrides + d;\n          outputVals[outputOffset] =\n              poolType === 'avg' ? avgValue / count : minMaxValue;\n        }\n      }\n    }\n  }\n  return output;\n}\n\nexport function maxPoolPositions(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    convInfo: backend_util.Conv2DInfo, flattenPositions = false,\n    includeBatchInIndex = false): TensorBuffer<Rank, 'int32'> {\n  const maxPositions = buffer(convInfo.outShape, 'int32');\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const xBuf = buffer(xShape, dtype, xValues);\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        let xRMin = xRCorner;\n        while (xRMin < 0) {\n          xRMin += dilationHeight;\n        }\n        // const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          let xCMin = xCCorner;\n          while (xCMin < 0) {\n            xCMin += dilationWidth;\n          }\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let maxValue = Number.NEGATIVE_INFINITY;\n          let maxPosition = -1;\n\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const wR = xR - xRCorner;\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const wC = xC - xCCorner;\n              const pixel = xBuf.get(b, xR, xC, d);\n              if (pixel > maxValue) {\n                maxValue = pixel as number;\n                if (flattenPositions) {\n                  maxPosition = includeBatchInIndex ?\n                      ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) *\n                              convInfo.inChannels +\n                          d :\n                      (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;\n                } else {\n                  maxPosition = wR * effectiveFilterWidth + wC;\n                }\n              }\n            }\n          }\n          maxPositions.set(maxPosition, b, yR, yC, d);\n        }\n      }\n    }\n  }\n  return maxPositions;\n}\n\nexport function pool3d(\n    xValues: TypedArray, xShape: number[], dtype: DataType, strides: number[],\n    convInfo: backend_util.Conv3DInfo,\n    poolType: 'max'|'avg'): TensorBuffer<Rank, DataType> {\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = convInfo.padInfo.front;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const initialValue =\n      (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n\n  const output = buffer(convInfo.outShape, dtype);\n  const outputVals = output.values;\n\n  const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] *\n      convInfo.outShape[3] * convInfo.outShape[4];\n  const outputDepthStrides =\n      convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];\n  const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];\n  const outputColStrides = convInfo.outShape[4];\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    const outputBatchOffset = batch * outputBatchStrides;\n    const inputBatchOffset = batch * strides[0];\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n        const xDepthCorner = yDepth * strideDepth - padFront;\n        let xDepthMin = xDepthCorner;\n        while (xDepthMin < 0) {\n          xDepthMin += dilationDepth;\n        }\n        const xDepthMax =\n            Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n        const outputDepthOffset =\n            outputBatchOffset + yDepth * outputDepthStrides;\n        for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n          const xRowCorner = yRow * strideHeight - padTop;\n          let xRowMin = xRowCorner;\n          while (xRowMin < 0) {\n            xRowMin += dilationHeight;\n          }\n          const xRowMax =\n              Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n          const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;\n          for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n            const xColCorner = yCol * strideWidth - padLeft;\n            let xColMin = xColCorner;\n            while (xColMin < 0) {\n              xColMin += dilationWidth;\n            }\n            const xColMax =\n                Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n            // Shader code begins\n            const outputColOffset = outputRowOffset + yCol * outputColStrides;\n            let minMaxValue = initialValue;\n            let avgValue = 0;\n            let count = 0;\n            for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                 xDepth += dilationDepth) {\n              const xDepthOffset = inputBatchOffset + xDepth * strides[1];\n              for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {\n                const xRowOffset = xDepthOffset + xRow * strides[2];\n                for (let xCol = xColMin; xCol < xColMax;\n                     xCol += dilationWidth) {\n                  const xColOffset = xRowOffset + xCol * strides[3];\n                  const pixel = xValues[xColOffset + channel];\n                  if ((poolType === 'max' && pixel > minMaxValue)) {\n                    minMaxValue = pixel;\n                  } else if (poolType === 'avg') {\n                    avgValue += pixel;\n                    count++;\n                  }\n                  if (isNaN(minMaxValue)) {\n                    break;\n                  }\n                }\n                if (isNaN(minMaxValue)) {\n                  break;\n                }\n              }\n              if (isNaN(minMaxValue)) {\n                break;\n              }\n            }\n            const outputOffset = outputColOffset + channel;\n            outputVals[outputOffset] =\n                poolType === 'avg' ? avgValue / count : minMaxValue;\n          }\n        }\n      }\n    }\n  }\n\n  return output;\n}\n\nexport function maxPool3dPositions(\n    xBuf: TensorBuffer<Rank, DataType>,\n    convInfo: backend_util.Conv3DInfo): TensorBuffer<Rank, DataType> {\n  const maxPositions = buffer(convInfo.outShape, 'int32');\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = convInfo.padInfo.front;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n        const xDepthCorner = yDepth * strideDepth - padFront;\n        let xDepthMin = xDepthCorner;\n        while (xDepthMin < 0) {\n          xDepthMin += dilationDepth;\n        }\n        const xDepthMax =\n            Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n        for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n          const xRowCorner = yRow * strideHeight - padTop;\n          let xRowMin = xRowCorner;\n          while (xRowMin < 0) {\n            xRowMin += dilationHeight;\n          }\n          const xRowMax =\n              Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n          for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n            const xColCorner = yCol * strideWidth - padLeft;\n            let xColMin = xColCorner;\n            while (xColMin < 0) {\n              xColMin += dilationWidth;\n            }\n            const xColMax =\n                Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n\n            // Shader code begins\n            let maxValue = Number.NEGATIVE_INFINITY;\n            let maxPosition = -1;\n\n            for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                 xDepth += dilationDepth) {\n              const wDepth = xDepth - xDepthCorner;\n              for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {\n                const wRow = xRow - xRowCorner;\n                for (let xCol = xColMin; xCol < xColMax;\n                     xCol += dilationWidth) {\n                  const wCol = xCol - xColCorner;\n                  const pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);\n                  if (pixel >= maxValue) {\n                    maxValue = pixel as number;\n                    maxPosition =\n                        wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                        wRow * effectiveFilterHeight + wCol;\n                  }\n                }\n              }\n            }\n\n            maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);\n          }\n        }\n      }\n    }\n  }\n\n  return maxPositions;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPool, AvgPoolAttrs, AvgPoolInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function avgPool(\n    args:\n        {inputs: AvgPoolInputs, backend: MathBackendCPU, attrs: AvgPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'avgPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in avgPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'avg');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const avgPoolConfig: KernelConfig = {\n  kernelName: AvgPool,\n  backendName: 'cpu',\n  kernelFunc: avgPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPool3D, AvgPool3DAttrs, AvgPool3DInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool3d} from '../utils/pool_utils';\n\nexport function avgPool3D(args: {\n  inputs: AvgPool3DInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPool3DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode, dataFormat} = attrs;\n\n  assertNotComplex(x, 'avgPool3d');\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode, dataFormat);\n\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const outBuf = pool3d(\n      xValues, x.shape, x.dtype, util.computeStrides(x.shape), convInfo, 'avg');\n\n  return backend.makeTensorInfo(outBuf.shape, 'float32', outBuf.values);\n}\n\nexport const avgPool3DConfig: KernelConfig = {\n  kernelName: AvgPool3D,\n  backendName: 'cpu',\n  kernelFunc: avgPool3D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {AvgPool3DGrad, AvgPool3DGradAttrs, AvgPool3DGradInputs, backend_util, buffer, KernelConfig, KernelFunc, Rank, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function avgPool3DGrad(args: {\n  inputs: AvgPool3DGradInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPool3DGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  assertNotComplex([dy, input], 'avgPool3DGrad');\n\n  const convInfo = backend_util.computePool3DInfo(\n      input.shape as [number, number, number, number, number], filterSize,\n      strides, 1 /* dilations */, pad, dimRoundingMode);\n\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterDepth = convInfo.filterDepth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx = buffer(input.shape, 'float32');\n\n  const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);\n\n  const dyBuf = backend.bufferSync<Rank, 'float32'>(dy);\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n        for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n          for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n            // Shader code begins.\n            const dyDepthCorner = dxDepth - padFront;\n            const dyRowCorner = dxRow - padTop;\n            const dyColCorner = dxCol - padLeft;\n            let dotProd = 0;\n            for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                 wDepth += dilationDepth) {\n              const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n              if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                  Math.floor(dyDepth) !== dyDepth) {\n                continue;\n              }\n              for (let wRow = 0; wRow < effectiveFilterHeight;\n                   wRow += dilationHeight) {\n                const dyRow = (dyRowCorner + wRow) / strideHeight;\n                if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                    Math.floor(dyRow) !== dyRow) {\n                  continue;\n                }\n                for (let wCol = 0; wCol < effectiveFilterWidth;\n                     wCol += dilationWidth) {\n                  const dyCol = (dyColCorner + wCol) / strideWidth;\n                  if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                      Math.floor(dyCol) !== dyCol) {\n                    continue;\n                  }\n\n                  const pixel =\n                      dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                  dotProd += pixel;\n                }\n              }\n            }\n            dx.set(\n                dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol, channel);\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const avgPool3DGradConfig: KernelConfig = {\n  kernelName: AvgPool3DGrad,\n  backendName: 'cpu',\n  kernelFunc: avgPool3DGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPoolGrad, AvgPoolGradAttrs, AvgPoolGradInputs, backend_util, buffer, KernelConfig, KernelFunc, Rank, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function avgPoolGrad(args: {\n  inputs: AvgPoolGradInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPoolGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  assertNotComplex([dy, input], 'avgPoolGrad');\n  const {filterSize, strides, pad} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const avgMultiplier = 1 / (filterHeight * filterWidth);\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel;\n            }\n          }\n          dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const avgPoolGradConfig: KernelConfig = {\n  kernelName: AvgPoolGrad,\n  backendName: 'cpu',\n  kernelFunc: avgPoolGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function batchNorm(args: {\n  inputs: FusedBatchNormInputs,\n  backend: MathBackendCPU,\n  attrs: FusedBatchNormAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, scale, offset, mean, variance} = inputs;\n\n  util.assert(\n      mean.shape.length === variance.shape.length,\n      () => 'Batch normalization gradient requires mean and variance to have ' +\n          'equal ranks.');\n  util.assert(\n      offset == null || mean.shape.length === offset.shape.length,\n      () => 'Batch normalization gradient requires mean and offset to have ' +\n          'equal ranks.');\n  util.assert(\n      scale == null || mean.shape.length === scale.shape.length,\n      () => 'Batch normalization gradient requires mean and scale to have ' +\n          'equal ranks.');\n\n  assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n\n  let {varianceEpsilon} = attrs;\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const mVals = backend.data.get(mean.dataId).values as TypedArray;\n  const varVals = backend.data.get(variance.dataId).values as TypedArray;\n  const sVals = scale ? backend.data.get(scale.dataId).values as TypedArray :\n                        new Float32Array([1]);\n  const offVals = offset ?\n      backend.data.get(offset.dataId).values as TypedArray :\n      new Float32Array([0]);\n  const outVals = new Float32Array(xVals.length);\n\n  const offValsLength = offVals.length;\n  const sValsLength = sVals.length;\n  const varValsLength = varVals.length;\n  const mValsLength = mVals.length;\n\n  let offi = 0;\n  let mi = 0;\n  let si = 0;\n  let vi = 0;\n  for (let i = 0; i < xVals.length; ++i) {\n    outVals[i] = offVals[offi++] +\n        (xVals[i] - mVals[mi++]) * sVals[si++] /\n            Math.sqrt(varVals[vi++] + varianceEpsilon);\n    if (offi >= offValsLength) {\n      offi = 0;\n    }\n    if (mi >= mValsLength) {\n      mi = 0;\n    }\n    if (si >= sValsLength) {\n      si = 0;\n    }\n    if (vi >= varValsLength) {\n      vi = 0;\n    }\n  }\n  return backend.makeTensorInfo(x.shape, x.dtype, outVals);\n}\n\nexport const batchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'cpu',\n  kernelFunc: batchNorm as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BatchToSpaceND, BatchToSpaceNDAttrs, BatchToSpaceNDInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {transpose} from './Transpose';\n\nexport function batchToSpaceND(args: {\n  inputs: BatchToSpaceNDInputs,\n  backend: MathBackendCPU,\n  attrs: BatchToSpaceNDAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, crops} = attrs;\n\n  assertNotComplex([x], 'batchToSpaceND');\n\n  const prod = blockShape.reduce((a, b) => a * b);\n\n  const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n  const permuted = backend_util.getPermuted(reshaped.length, blockShape.length);\n  const reshapedPermuted =\n      backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n  const sliceBeginCoords =\n      backend_util.getSliceBeginCoords(crops, blockShape.length);\n  const sliceSize =\n      backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n  const xReshaped = reshape({inputs: {x}, backend, attrs: {shape: reshaped}});\n  const xTransposed =\n      transpose({inputs: {x: xReshaped}, backend, attrs: {perm: permuted}});\n  const xTransposedReshaped = reshape(\n      {inputs: {x: xTransposed}, backend, attrs: {shape: reshapedPermuted}});\n  const result = slice({\n    inputs: {x: xTransposedReshaped},\n    backend,\n    attrs: {begin: sliceBeginCoords, size: sliceSize}\n  });\n\n  backend.disposeIntermediateTensorInfo(xReshaped);\n  backend.disposeIntermediateTensorInfo(xTransposed);\n  backend.disposeIntermediateTensorInfo(xTransposedReshaped);\n\n  return result;\n}\n\nexport const batchToSpaceNDConfig: KernelConfig = {\n  kernelName: BatchToSpaceND,\n  backendName: 'cpu',\n  kernelFunc: batchToSpaceND as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Bincount, BincountAttrs, BincountInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {bincountImpl} from './Bincount_impl';\n\nexport function bincount(args: {\n  inputs: BincountInputs,\n  backend: MathBackendCPU,\n  attrs: BincountAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, weights} = inputs;\n  const {size} = attrs;\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const weightsVals = backend.data.get(weights.dataId).values as TypedArray;\n\n  const outVals =\n      bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);\n\n  return backend.makeTensorInfo([size], weights.dtype, outVals);\n}\n\nexport const bincountConfig: KernelConfig = {\n  kernelName: Bincount,\n  backendName: 'cpu',\n  kernelFunc: bincount as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BroadcastArgs, BroadcastArgsInputs, KernelConfig, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function broadcastArgs(args: {\n  inputs: BroadcastArgsInputs,\n  backend: MathBackendCPU,\n}): TensorInfo {\n  const {inputs, backend} = args;\n  const {s0, s1} = inputs;\n\n  const s0Vals = backend.data.get(s0.dataId).values as TypedArray;\n  const s1Vals = backend.data.get(s1.dataId).values as TypedArray;\n\n  const broadcastShape = backend_util.assertAndGetBroadcastShape(\n      Array.from(s0Vals), Array.from(s1Vals));\n\n  return backend.makeTensorInfo(\n      [broadcastShape.length], 'int32', Int32Array.from(broadcastShape));\n}\n\nexport const broadcastArgsConfig: KernelConfig = {\n  kernelName: BroadcastArgs,\n  backendName: 'cpu',\n  kernelFunc: broadcastArgs\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ClipByValue, ClipByValueAttrs, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const clipByValue = unaryKernelFunc(ClipByValue, (xi, attrs) => {\n  const clipAttrs = attrs as {} as ClipByValueAttrs;\n  if (xi > clipAttrs.clipValueMax) {\n    return clipAttrs.clipValueMax;\n  }\n  return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;\n});\n\nexport const clipByValueConfig: KernelConfig = {\n  kernelName: ClipByValue,\n  backendName: 'cpu',\n  kernelFunc: clipByValue,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ComplexAbs, ComplexAbsInputs, KernelConfig, KernelFunc, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const complexAbs =\n    (args: {inputs: ComplexAbsInputs, backend: MathBackendCPU}) => {\n      const {x} = args.inputs;\n      const cpuBackend = args.backend;\n      const resultValues = new Float32Array(util.sizeFromShape(x.shape));\n      const complexVals = cpuBackend.data.get(x.dataId);\n      const real = complexVals.complexTensorInfos.real;\n      const imag = complexVals.complexTensorInfos.imag;\n      const realVals = cpuBackend.data.get(real.dataId).values as Float32Array;\n      const imagVals = cpuBackend.data.get(imag.dataId).values as Float32Array;\n      for (let i = 0; i < realVals.length; i++) {\n        const real = realVals[i];\n        const imag = imagVals[i];\n        resultValues[i] = Math.hypot(real, imag);\n      }\n\n      return cpuBackend.makeOutput(resultValues, x.shape, 'float32');\n    };\n\nexport const complexAbsConfig: KernelConfig = {\n  kernelName: ComplexAbs,\n  backendName: 'cpu',\n  kernelFunc: complexAbs as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Imag, ImagInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function imag(args: {inputs: ImagInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const imag = backend.data.get(input.dataId).complexTensorInfos.imag;\n  const imagVal = backend.data.get(imag.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the imag value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(imag.shape, imag.dtype, imagVal);\n}\n\nexport const imagConfig: KernelConfig = {\n  kernelName: Imag,\n  backendName: 'cpu',\n  kernelFunc: imag as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Concat, ConcatAttrs, ConcatInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {complex} from './Complex';\nimport {concatImpl} from './Concat_impl';\nimport {identity} from './Identity';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concat(\n    args: {inputs: ConcatInputs, backend: MathBackendCPU, attrs: ConcatAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n  let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return identity({inputs: {x: $inputs[0]}, backend});\n  }\n\n  const shapes = $inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n\n  if ($inputs[0].dtype === 'complex64') {\n    const reals = $inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = $inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concat({inputs: reals, backend, attrs: {axis: $axis}});\n    const imagConcated = concat({inputs: imags, backend, attrs: {axis: $axis}});\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n\n    return result;\n  }\n\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const inputs2D = $inputs.map(t => {\n    const innerSize = util.sizeFromShape(t.shape.slice($axis));\n    const shape = [-1, innerSize];\n    return reshape({inputs: {x: t}, backend, attrs: {shape}});\n  });\n\n  const inputsValShapes = inputs2D.map(t => {\n    return {vals: backend.data.get(t.dataId).values, shape: t.shape};\n  });\n\n  // Concats 2d tensors along axis=1.\n  outShape =\n      backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n  const simplyConcat = inputs2D[0].shape[0] === 1;\n  const outVals =\n      concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);\n\n  const finalOutShape =\n      backend_util.computeOutShape($inputs.map(t => t.shape), $axis);\n\n  const outInfo =\n      backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);\n\n  inputs2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return outInfo;\n}\n\nexport const concatConfig: KernelConfig = {\n  kernelName: Concat,\n  backendName: 'cpu',\n  kernelFunc: concat as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2D, Conv2DAttrs, Conv2DInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2D(\n    args: {inputs: Conv2DInputs, backend: MathBackendCPU, attrs: Conv2DAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode} = attrs;\n\n  assertNotComplex([x, filter], 'conv2d');\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const padLeft = convInfo.padInfo.left;\n  const padTop = convInfo.padInfo.top;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const xBatchStride = xStrides[0];\n  const xRowStride = isChannelsLast ? xStrides[1] : xStrides[2];\n  const xColStride = isChannelsLast ? xStrides[2] : 1;\n  const xChannelStride = isChannelsLast ? 1 : xStrides[1];\n  const yBatchStride = y.strides[0];\n  const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];\n  const yColStride = isChannelsLast ? y.strides[2] : 1;\n  const yChannelStride = isChannelsLast ? 1 : y.strides[1];\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xBatchStride;\n    const yOffset1 = b * yBatchStride;\n    for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n      const yOffset2 = yOffset1 + yR * yRowStride;\n      const xRCorner = yR * convInfo.strideHeight - padTop;\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const xR = xRCorner + wR * dilationHeight;\n        if (xR < 0 || xR >= convInfo.inHeight) {\n          continue;\n        }\n        const wOffset1 = wR * filterStrides[0];\n        const xOffset2 = xOffset1 + xR * xRowStride;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const yOffset3 = yOffset2 + yC * yColStride;\n          const xCCorner = yC * convInfo.strideWidth - padLeft;\n          for (let wC = 0; wC < filterWidth; ++wC) {\n            const xC = xCCorner + wC * dilationWidth;\n            if (xC < 0 || xC >= convInfo.inWidth) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wC * filterStrides[1];\n            const xOffset3 = xOffset2 + xC * xColStride;\n            let wOffset3 = wOffset2;\n            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n              const xVal = xVals[xOffset3 + d1 * xChannelStride];\n              for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                yVals[yOffset3 + d2 * yChannelStride] +=\n                    xVal * wVals[wOffset3 + d2];\n              }\n              wOffset3 += convInfo.outChannels;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, yVals);\n}\n\nexport const conv2DConfig: KernelConfig = {\n  kernelName: Conv2D,\n  backendName: 'cpu',\n  kernelFunc: conv2D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropFilter, Conv2DBackpropFilterAttrs, Conv2DBackpropFilterInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2DBackpropFilter(args: {\n  inputs: Conv2DBackpropFilterInputs,\n  backend: MathBackendCPU,\n  attrs: Conv2DBackpropFilterAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, dataFormat, dimRoundingMode, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'conv2dBackpropFilter');\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad, dimRoundingMode, false /* depthwise */,\n      $dataFormat);\n\n  const {strideHeight, strideWidth, filterHeight, filterWidth} = convInfo;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const dW = new TensorBuffer(convInfo.filterShape, 'float32');\n\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const dyVals = backend.data.get(dy.dataId).values as TypedArray;\n\n  const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);\n  const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);\n\n  for (let wR = 0; wR < filterHeight; ++wR) {\n    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n    const yRMax = Math.min(\n        convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n    for (let wC = 0; wC < filterWidth; ++wC) {\n      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n      const yCMax = Math.min(\n          convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n      for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n          let dotProd = 0;\n          for (let b = 0; b < convInfo.batchSize; ++b) {\n            for (let yR = yRMin; yR < yRMax; ++yR) {\n              const xR = wR + yR * strideHeight - topPad;\n              for (let yC = yCMin; yC < yCMax; ++yC) {\n                const xC = wC + yC * strideWidth - leftPad;\n                if (isChannelsLast) {\n                  dotProd += (xBuf.get(b, xR, xC, d1) as number) *\n                      (dyBuf.get(b, yR, yC, d2) as number);\n                } else {\n                  dotProd += (xBuf.get(b, d1, xR, xC) as number) *\n                      (dyBuf.get(b, d2, yR, yC) as number);\n                }\n              }\n            }\n          }\n          dW.set(dotProd, wR, wC, d1, d2);\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);\n}\n\nexport const conv2DBackpropFilterConfig: KernelConfig = {\n  kernelName: Conv2DBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: conv2DBackpropFilter as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropInput, Conv2DBackpropInputAttrs, Conv2DBackpropInputInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2DBackpropInput(args: {\n  inputs: Conv2DBackpropInputInputs,\n  backend: MathBackendCPU,\n  attrs: Conv2DBackpropInputAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {inputShape, strides, pad, dataFormat, dimRoundingMode} = attrs;\n\n  assertNotComplex([dy, filter], 'conv2dBackpropInput');\n\n  const filterStrides = util.computeStrides(filter.shape);\n  const dyStrides = util.computeStrides(dy.shape);\n\n  let $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      1 /* dilations */, pad, dimRoundingMode, false, $dataFormat);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2] = filterStrides;\n  const {\n    batchSize,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inHeight,\n    inWidth,\n    outChannels,\n    outHeight,\n    outWidth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  $dataFormat = convInfo.dataFormat;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n  const isChannelsLast = $dataFormat === 'channelsLast';\n  const xBatchStride = dx.strides[0];\n  const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];\n  const xColStride = isChannelsLast ? dx.strides[2] : 1;\n  const xChannelStride = isChannelsLast ? 1 : dx.strides[1];\n  const yBatchStride = dyStrides[0];\n  const yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];\n  const yColStride = isChannelsLast ? dyStrides[2] : 1;\n  const yChannelStride = isChannelsLast ? 1 : dyStrides[1];\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      for (let xR = 0; xR < inHeight; ++xR) {\n        const xRCorner = xR - topPad;\n        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n        const yRMax =\n            Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n        for (let xC = 0; xC < inWidth; ++xC) {\n          const xCCorner = xC - leftPad;\n          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n          const yCMax =\n              Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n          let dotProd = 0;\n          for (let yR = xRMin; yR < yRMax; ++yR) {\n            const wR = yR * strideHeight - xRCorner;\n\n            for (let yC = xCMin; yC < yCMax; ++yC) {\n              const wC = yC * strideWidth - xCCorner;\n              const dyOffset =\n                  yBatchStride * b + yRowStride * yR + yColStride * yC;\n              const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                  fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n              for (let d2 = 0; d2 < outChannels; ++d2) {\n                const pixel = dyValues[dyOffset + yChannelStride * d2];\n                const weight = fltValues[fltOffset + d2];\n                dotProd += pixel * weight;\n              }\n            }\n          }\n          const dxOffset = xBatchStride * b + xRowStride * xR +\n              xColStride * xC + xChannelStride * d1;\n          dxValues[dxOffset] = dotProd;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const conv2DBackpropInputConfig: KernelConfig = {\n  kernelName: Conv2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: conv2DBackpropInput as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3D, Conv3DAttrs, Conv3DInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3D(\n    args: {inputs: Conv3DInputs, backend: MathBackendCPU, attrs: Conv3DAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  assertNotComplex([x, filter], 'conv3d');\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number],\n      filter.shape as [number, number, number, number, number], strides,\n      dilations, pad);\n\n  const {\n    filterDepth,\n    filterHeight,\n    filterWidth,\n    dilationDepth,\n    dilationHeight,\n    dilationWidth,\n    padInfo\n  } = convInfo;\n  const padFront = padInfo.front;\n  const padLeft = padInfo.left;\n  const padTop = padInfo.top;\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xStrides[0];\n    const yOffset1 = b * y.strides[0];\n    for (let yF = 0; yF < convInfo.outDepth; ++yF) {\n      const yOffset2 = yOffset1 + yF * y.strides[1];\n      const xFCorner = yF * convInfo.strideDepth - padFront;\n      for (let wF = 0; wF < filterDepth; ++wF) {\n        const xF = xFCorner + wF * dilationDepth;\n        if (xF < 0 || xF >= convInfo.inDepth) {\n          continue;\n        }\n        const wOffset1 = wF * filterStrides[0];\n        const xOffset2 = xOffset1 + xF * xStrides[1];\n\n        for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n          const yOffset3 = yOffset2 + yR * y.strides[2];\n          const xRCorner = yR * convInfo.strideHeight - padTop;\n          for (let wR = 0; wR < filterHeight; ++wR) {\n            const xR = xRCorner + wR * dilationHeight;\n            if (xR < 0 || xR >= convInfo.inHeight) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wR * filterStrides[1];\n            const xOffset3 = xOffset2 + xR * xStrides[2];\n            for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n              const yOffset4 = yOffset3 + yC * convInfo.outChannels;\n              const xCCorner = yC * convInfo.strideWidth - padLeft;\n              for (let wC = 0; wC < filterWidth; ++wC) {\n                const xC = xCCorner + wC * dilationWidth;\n                if (xC < 0 || xC >= convInfo.inWidth) {\n                  continue;\n                }\n                const wOffset3 = wOffset2 + wC * filterStrides[2];\n                const xOffset4 = xOffset3 + xC * convInfo.inChannels;\n                let wOffset4 = wOffset3;\n                for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                  const xVal = xVals[xOffset4 + d1];\n                  for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                    yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];\n                  }\n                  wOffset4 += convInfo.outChannels;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, y.values);\n}\n\nexport const conv3DConfig: KernelConfig = {\n  kernelName: Conv3D,\n  backendName: 'cpu',\n  kernelFunc: conv3D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropFilterV2, Conv3DBackpropFilterV2Attrs, Conv3DBackpropFilterV2Inputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3DBackpropFilterV2(args: {\n  inputs: Conv3DBackpropFilterV2Inputs,\n  backend: MathBackendCPU,\n  attrs: Conv3DBackpropFilterV2Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'conv3dBackpropFilterV2');\n\n  const xStrides = util.computeStrides(x.shape);\n  const dyStrides = util.computeStrides(dy.shape);\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad);\n\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterDepth = convInfo.filterDepth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n\n  const dw = new TensorBuffer(convInfo.filterShape, 'float32');\n  const dwValues = dw.values;\n  const [dwS0, dwS1, dwS2, dwS3] = dw.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const [xS0, xS1, xS2, xS3] = xStrides;\n\n  const frontPad = convInfo.padInfo.front;\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n\n  for (let wF = 0; wF < filterDepth; ++wF) {\n    const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));\n    const yFMax = Math.min(\n        convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);\n    const wOffset1 = wF * dwS0;\n\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n      const wOffset2 = wR * dwS1 + wOffset1;\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n        const wOffset3 = wC * dwS2 + wOffset2;\n\n        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n          const wOffset4 = d1 * dwS3 + wOffset3;\n\n          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n            let dotProd = 0;\n            for (let b = 0; b < convInfo.batchSize; ++b) {\n              const xOffset1 = b * xS0;\n              const yOffset1 = b * dyS0;\n\n              for (let yF = yFMin; yF < yFMax; ++yF) {\n                const xF = wF + yF * strideDepth - frontPad;\n                const xOffset2 = xF * xS1 + xOffset1;\n                const yOffset2 = yF * dyS1 + yOffset1;\n\n                for (let yR = yRMin; yR < yRMax; ++yR) {\n                  const xR = wR + yR * strideHeight - topPad;\n                  const xOffset3 = xR * xS2 + xOffset2;\n                  const yOffset3 = yR * dyS2 + yOffset2;\n\n                  for (let yC = yCMin; yC < yCMax; ++yC) {\n                    const xC = wC + yC * strideWidth - leftPad;\n                    const xOffset4 = xC * xS3 + xOffset3;\n                    const yOffset4 = yC * dyS3 + yOffset3;\n\n                    dotProd += xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];\n                  }\n                }\n              }\n            }\n            dwValues[wOffset4 + d2] = dotProd;\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dw.shape, dw.dtype, dw.values);\n}\n\nexport const conv3DBackpropFilterV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropFilterV2,\n  backendName: 'cpu',\n  kernelFunc: conv3DBackpropFilterV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropInputV2, Conv3DBackpropInputV2Attrs, Conv3DBackpropInputV2Inputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3DBackpropInputV2(args: {\n  inputs: Conv3DBackpropInputV2Inputs,\n  backend: MathBackendCPU,\n  attrs: Conv3DBackpropInputV2Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {pad, strides, inputShape} = attrs;\n\n  assertNotComplex([dy], 'conv3dBackpropInputV2');\n\n  const dyStrides = util.computeStrides(dy.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const convInfo = backend_util.computeConv3DInfo(\n      inputShape, filter.shape as [number, number, number, number, number],\n      strides, 1 /* dilations */, pad);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const [dxS0, dxS1, dxS2, dxS3] = dx.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2, fltS3] = filterStrides;\n  const {\n    batchSize,\n    filterDepth,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inDepth,\n    inHeight,\n    inWidth,\n    outChannels,\n    outDepth,\n    outHeight,\n    outWidth,\n    strideDepth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  const frontPad = filterDepth - 1 - convInfo.padInfo.front;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      // Frames of depth\n      for (let xF = 0; xF < inDepth; ++xF) {\n        const xFCorner = xF - frontPad;\n        const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));\n        const yFMax =\n            Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);\n\n        // Rows as per standard 2d matrix notation\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n          // Columns as per standard 2d matrix notation\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yF = xFMin; yF < yFMax; ++yF) {\n              const wF = yF * strideDepth - xFCorner;\n\n              for (let yR = xRMin; yR < yRMax; ++yR) {\n                const wR = yR * strideHeight - xRCorner;\n\n                for (let yC = xCMin; yC < yCMax; ++yC) {\n                  const wC = yC * strideWidth - xCCorner;\n                  const dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;\n                  const fltOffset = fltS0 * (filterDepth - 1 - wF) +\n                      fltS1 * (filterHeight - 1 - wR) +\n                      fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;\n\n                  for (let d2 = 0; d2 < outChannels; ++d2) {\n                    const pixel = dyValues[dyOffset + d2];\n                    const weight = fltValues[fltOffset + d2];\n                    dotProd += pixel * weight;\n                  }\n                }\n              }\n            }\n            dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] =\n                dotProd;\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const conv3DBackpropInputV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropInputV2,\n  backendName: 'cpu',\n  kernelFunc: conv3DBackpropInputV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const cos = unaryKernelFunc(Cos, (xi) => Math.cos(xi));\n\nexport const cosConfig: KernelConfig = {\n  kernelName: Cos,\n  backendName: 'cpu',\n  kernelFunc: cos,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const cosh = unaryKernelFunc(Cosh, (xi) => Math.cosh(xi));\n\nexport const coshConfig: KernelConfig = {\n  kernelName: Cosh,\n  backendName: 'cpu',\n  kernelFunc: cosh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, CropAndResize, CropAndResizeAttrs, CropAndResizeInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function cropAndResize(args: {\n  inputs: CropAndResizeInputs,\n  backend: MathBackendCPU,\n  attrs: CropAndResizeAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {image, boxes, boxInd} = inputs;\n  const {cropSize, method, extrapolationValue} = attrs;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n  const numBoxes = boxes.shape[0];\n\n  const [cropHeight, cropWidth] = cropSize;\n  const output =\n      buffer([numBoxes, cropHeight, cropWidth, numChannels], 'float32');\n\n  const boxVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const boxIndVals = backend.data.get(boxInd.dataId).values as TypedArray;\n  const imageVals = backend.data.get(image.dataId).values as TypedArray;\n\n  const inStride =\n      util.computeStrides(image.shape);  // to calculate flat indexes into image\n  const outStride = util.computeStrides(\n      output.shape);  // to calculate flat indexes into output\n\n  // Reference implementation\n  // tslint:disable-next-line:max-line-length\n  // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op.cc\n  for (let b = 0; b < numBoxes; b++) {\n    const startInd = b * 4;\n    const y1 = boxVals[startInd];\n    const x1 = boxVals[startInd + 1];\n    const y2 = boxVals[startInd + 2];\n    const x2 = boxVals[startInd + 3];\n\n    const bInd: number = boxIndVals[b];\n    if (bInd >= batch) {\n      continue;\n    }\n\n    const heightScale =\n        (cropHeight > 1) ? (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) : 0;\n    const widthScale =\n        (cropWidth > 1) ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;\n\n    for (let y = 0; y < cropHeight; y++) {\n      const yInd: number = (cropHeight > 1) ?\n          y1 * (imageHeight - 1) + y * (heightScale) :\n          0.5 * (y1 + y2) * (imageHeight - 1);\n\n      if (yInd < 0 || yInd > imageHeight - 1) {\n        for (let x = 0; x < cropWidth; x++) {\n          for (let c = 0; c < numChannels; c++) {\n            const ind =\n                c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n            output.values[ind] = extrapolationValue;\n          }\n        }\n        continue;\n      }\n\n      if (method === 'bilinear') {\n        const topInd = Math.floor(yInd);\n        const bottomInd = Math.ceil(yInd);\n        const yLerp = yInd - topInd;\n\n        for (let x = 0; x < cropWidth; x++) {\n          const xInd = (cropWidth > 1) ?\n              x1 * (imageWidth - 1) + x * widthScale :\n              0.5 * (x1 + x2) * (imageWidth - 1);\n\n          if (xInd < 0 || xInd > imageWidth - 1) {\n            for (let c = 0; c < numChannels; c++) {\n              const ind =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = extrapolationValue;\n            }\n            continue;\n          }\n\n          const leftInd = Math.floor(xInd);\n          const rightInd = Math.ceil(xInd);\n          const xLerp = xInd - leftInd;\n\n          for (let c = 0; c < numChannels; c++) {\n            let ind = c + leftInd * inStride[2] + topInd * inStride[1] +\n                bInd * inStride[0];\n            const topLeft = imageVals[ind];\n\n            ind = c + rightInd * inStride[2] + topInd * inStride[1] +\n                bInd * inStride[0];\n            const topRight = imageVals[ind];\n\n            ind = c + leftInd * inStride[2] + bottomInd * inStride[1] +\n                bInd * inStride[0];\n            const bottomLeft = imageVals[ind];\n\n            ind = c + rightInd * inStride[2] + bottomInd * inStride[1] +\n                bInd * inStride[0];\n            const bottomRight = imageVals[ind];\n\n            const top = topLeft + (topRight - topLeft) * xLerp;\n            const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;\n\n            ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n            output.values[ind] = top + ((bottom - top) * yLerp);\n          }\n        }\n      } else {  // method == \"nearest\"\n        for (let x = 0; x < cropWidth; ++x) {\n          const xInd = (cropWidth > 1) ?\n              x1 * (imageWidth - 1) + x * widthScale :\n              0.5 * (x1 + x2) * (imageWidth - 1);\n\n          if (xInd < 0 || xInd > imageWidth - 1) {\n            for (let c = 0; c < numChannels; c++) {\n              const ind =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = extrapolationValue;\n            }\n            continue;\n          }\n\n          const closestX = Math.round(xInd);\n          const closestY = Math.round(yInd);\n          for (let c = 0; c < numChannels; c++) {\n            const inInd = c + closestX * inStride[2] + closestY * inStride[1] +\n                bInd * inStride[0];\n            const outInd =\n                c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n            output.values[outInd] = imageVals[inInd];\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(output.shape, output.dtype, output.values);\n}\n\nexport const cropAndResizeConfig: KernelConfig = {\n  kernelName: CropAndResize,\n  backendName: 'cpu',\n  kernelFunc: cropAndResize as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Cumprod, CumprodAttrs, CumprodInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function cumprod(\n    args: {inputs: CumprodInputs, backend: MathBackendCPU,\n           attrs: CumprodAttrs}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n\n  assertNotComplex(x, 'cumprod');\n\n  const permutation = backend_util.getAxesPermutation([axis], x.shape.length);\n  let $x = x;\n  if (permutation != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, x.shape.length)[0];\n\n  if (permutedAxis !== $x.shape.length - 1) {\n    throw new Error(\n        `backend.cumprod in CPU expects an inner-most ` +\n        `axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);\n  }\n\n  const resultDtype = upcastType($x.dtype, 'int32');\n  const vals = util.makeOnesTypedArray(\n                   util.sizeFromShape($x.shape), resultDtype) as TypedArray;\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  const finalDim = $x.shape[$x.shape.length - 1];\n  const indexAdjuster = reverse ?\n      (i: number, j: number) => i + finalDim - j - 1 :\n      (i: number, j: number) => i + j;\n  for (let i = 0; i < aVals.length; i += finalDim) {\n    for (let j = 0; j < finalDim; j++) {\n      const idx = indexAdjuster(i, j);\n      if (j === 0) {\n        vals[idx] = exclusive ? 1 : aVals[idx];\n      } else {\n        const prevIdx = indexAdjuster(i, j - 1);\n        vals[idx] = exclusive ? aVals[prevIdx] * vals[prevIdx] :\n                                aVals[idx] * vals[prevIdx];\n      }\n    }\n  }\n\n  const result = backend.makeTensorInfo($x.shape, resultDtype, vals);\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo($x);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n\nexport const cumprodConfig: KernelConfig = {\n  kernelName: Cumprod,\n  backendName: 'cpu',\n  kernelFunc: cumprod as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Cumsum, CumsumAttrs, CumsumInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {transpose} from './Transpose';\n\nexport function cumsum(\n    args: {inputs: CumsumInputs, backend: MathBackendCPU, attrs: CumsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, exclusive, reverse} = attrs;\n\n  assertNotComplex(x, 'cumsum');\n\n  const permutation = backend_util.getAxesPermutation([axis], x.shape.length);\n  let $x = x;\n  if (permutation != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, x.shape.length)[0];\n\n  if (permutedAxis !== $x.shape.length - 1) {\n    throw new Error(\n        `backend.cumsum in CPU expects an inner-most ` +\n        `axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);\n  }\n\n  const resultDtype = upcastType($x.dtype, 'int32');\n  const vals = util.makeZerosTypedArray(\n                   util.sizeFromShape($x.shape), resultDtype) as TypedArray;\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  const finalDim = $x.shape[$x.shape.length - 1];\n  const indexAdjuster = reverse ?\n      (i: number, j: number) => i + finalDim - j - 1 :\n      (i: number, j: number) => i + j;\n  for (let i = 0; i < aVals.length; i += finalDim) {\n    for (let j = 0; j < finalDim; j++) {\n      const idx = indexAdjuster(i, j);\n      if (j === 0) {\n        vals[idx] = exclusive ? 0 : aVals[idx];\n      } else {\n        const prevIdx = indexAdjuster(i, j - 1);\n        vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                                aVals[idx] + vals[prevIdx];\n      }\n    }\n  }\n\n  const result = backend.makeTensorInfo($x.shape, resultDtype, vals);\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeIntermediateTensorInfo(result);\n    backend.disposeIntermediateTensorInfo($x);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n\nexport const cumsumConfig: KernelConfig = {\n  kernelName: Cumsum,\n  backendName: 'cpu',\n  kernelFunc: cumsum as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DenseBincount, DenseBincountAttrs, DenseBincountInputs, KernelConfig, KernelFunc, Rank, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {bincountImpl, bincountReduceImpl} from './Bincount_impl';\n\nexport function denseBincount(args: {\n  inputs: DenseBincountInputs,\n  backend: MathBackendCPU,\n  attrs: DenseBincountAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, weights} = inputs;\n  const {size, binaryOutput} = attrs;\n\n  if (x.shape.length === 1) {\n    const xVals = backend.data.get(x.dataId).values as TypedArray;\n    const weightsVals = backend.data.get(weights.dataId).values as TypedArray;\n\n    const outVals =\n        bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);\n\n    return backend.makeTensorInfo([size], weights.dtype, outVals);\n  } else if (x.shape.length === 2) {\n    const xBuf = backend.bufferSync<Rank, 'float32'>(x);\n    const weightsBuf = backend.bufferSync<Rank, 'float32'>(weights);\n\n    const outBuf = bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput);\n\n    return backend.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);\n  }\n\n  throw new Error(\n      `Error in denseBincount: input must be at most rank 2, but got rank` +\n      `${x.shape.length}.`);\n}\n\nexport const denseBincountConfig: KernelConfig = {\n  kernelName: DenseBincount,\n  backendName: 'cpu',\n  kernelFunc: denseBincount as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DepthToSpace, DepthToSpaceAttrs, DepthToSpaceInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function depthToSpace(args: {\n  inputs: DepthToSpaceInputs,\n  backend: MathBackendCPU,\n  attrs: DepthToSpaceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockSize, dataFormat} = attrs;\n\n  util.assert(\n      dataFormat === 'NHWC',\n      () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${\n          dataFormat}`);\n\n  const batchSize = x.shape[0];\n  const inputHeight = x.shape[1];\n  const inputWidth = x.shape[2];\n  const inputDepth = x.shape[3];\n\n  const outputHeight = inputHeight * blockSize;\n  const outputWidth = inputWidth * blockSize;\n  const outputDepth = inputDepth / (blockSize * blockSize);\n\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const result =\n      new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);\n\n  let outputIdx = 0;\n  for (let b = 0; b < batchSize; ++b) {\n    for (let h = 0; h < outputHeight; ++h) {\n      const inH = Math.floor(h / blockSize);\n      const offsetH = (h % blockSize);\n      for (let w = 0; w < outputWidth; ++w) {\n        const inW = Math.floor(w / blockSize);\n        const offsetW = (w % blockSize);\n        const offsetD = (offsetH * blockSize + offsetW) * outputDepth;\n        for (let d = 0; d < outputDepth; ++d) {\n          const inD = d + offsetD;\n          const inputIdx =\n              inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));\n          result[outputIdx++] = xValues[inputIdx];\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batchSize, outputHeight, outputWidth, outputDepth], x.dtype, result);\n}\n\nexport const depthToSpaceConfig: KernelConfig = {\n  kernelName: DepthToSpace,\n  backendName: 'cpu',\n  kernelFunc: depthToSpace as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNative, DepthwiseConv2dNativeAttrs, DepthwiseConv2dNativeInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNative(args: {\n  inputs: DepthwiseConv2dNativeInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations, dimRoundingMode} = attrs;\n\n  assertNotComplex([x, filter], 'depthwiseConv2DNative');\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  let $dilations = dilations;\n  if ($dilations == null) {\n    $dilations = [1, 1];\n  }\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, $dilations),\n      () => 'Error in depthwiseConv2d: Either strides or dilations must be ' +\n          `1. Got strides ${strides} and dilations '${$dilations}'`);\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, $dilations,\n      pad, dimRoundingMode, true /* depthwise */);\n\n  const {filterHeight, filterWidth, dilationHeight, dilationWidth, padInfo} =\n      convInfo;\n  const padLeft = padInfo.left;\n  const padTop = padInfo.top;\n  const chMul = convInfo.outChannels / convInfo.inChannels;\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xStrides[0];\n    const yOffset1 = b * y.strides[0];\n    for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n      const yOffset2 = yOffset1 + yR * y.strides[1];\n      const xRCorner = yR * convInfo.strideHeight - padTop;\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const xR = xRCorner + wR * dilationHeight;\n        if (xR < 0 || xR >= convInfo.inHeight) {\n          continue;\n        }\n        const wOffset1 = wR * filterStrides[0];\n        const xOffset2 = xOffset1 + xR * xStrides[1];\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const yOffset3 = yOffset2 + yC * y.strides[2];\n          const xCCorner = yC * convInfo.strideWidth - padLeft;\n          for (let wC = 0; wC < filterWidth; ++wC) {\n            const xC = xCCorner + wC * dilationWidth;\n            if (xC < 0 || xC >= convInfo.inWidth) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wC * filterStrides[1];\n            const xOffset3 = xOffset2 + xC * convInfo.inChannels;\n            let yOffset4 = yOffset3;\n            let wOffset3 = wOffset2;\n            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n              const xVal = xVals[xOffset3 + d1];\n              for (let q = 0; q < chMul; ++q) {\n                yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];\n              }\n              yOffset4 += chMul;\n              wOffset3 += chMul;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, y.values);\n}\n\nexport const depthwiseConv2dNativeConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNative,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNative as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropFilterAttrs, DepthwiseConv2dNativeBackpropFilterInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNativeBackpropFilter(args: {\n  inputs: DepthwiseConv2dNativeBackpropFilterInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeBackpropFilterAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'depthwiseConv2dNativeBackpropFilter');\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const {strideHeight, strideWidth, filterHeight, filterWidth} = convInfo;\n\n  const dW = new TensorBuffer(convInfo.filterShape, 'float32');\n\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n  const chMul = convInfo.outChannels / convInfo.inChannels;\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);\n  const dyVals = backend.data.get(dy.dataId).values as TypedArray;\n  const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);\n  for (let wR = 0; wR < filterHeight; ++wR) {\n    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n    const yRMax = Math.min(\n        convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n    for (let wC = 0; wC < filterWidth; ++wC) {\n      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n      const yCMax = Math.min(\n          convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n      for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n        const d1 = Math.trunc(d2 / chMul);\n        const dm = d2 % chMul;\n\n        let dotProd = 0;\n        for (let b = 0; b < convInfo.batchSize; ++b) {\n          for (let yR = yRMin; yR < yRMax; ++yR) {\n            const xR = wR + yR * strideHeight - topPad;\n            for (let yC = yCMin; yC < yCMax; ++yC) {\n              const xC = wC + yC * strideWidth - leftPad;\n              dotProd += (xBuf.get(b, xR, xC, d1) as number) *\n                  (dyBuf.get(b, yR, yC, d2) as number);\n            }\n          }\n        }\n        dW.set(dotProd, wR, wC, d1, dm);\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);\n}\n\nexport const depthwiseConv2dNativeBackpropFilterConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNativeBackpropFilter as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropInput, DepthwiseConv2dNativeBackpropInputAttrs, DepthwiseConv2dNativeBackpropInputInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNativeBackpropInput(args: {\n  inputs: DepthwiseConv2dNativeBackpropInputInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeBackpropInputAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, inputShape} = attrs;\n\n  assertNotComplex([dy, filter], 'depthwiseConv2DNativeBackpropInput');\n\n  const dyStrides = util.computeStrides(dy.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const [dxS0, dxS1, dxS2] = dx.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2] = dyStrides;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2] = filterStrides;\n  const {\n    batchSize,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inHeight,\n    inWidth,\n    outChannels,\n    outHeight,\n    outWidth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n  const chMul = outChannels / inChannels;\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      for (let xR = 0; xR < inHeight; ++xR) {\n        const xRCorner = xR - topPad;\n        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n        const yRMax =\n            Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n        for (let xC = 0; xC < inWidth; ++xC) {\n          const xCCorner = xC - leftPad;\n          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n          const yCMax =\n              Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n          let dotProd = 0;\n          for (let yR = xRMin; yR < yRMax; ++yR) {\n            const wR = yR * strideHeight - xRCorner;\n\n            for (let yC = xCMin; yC < yCMax; ++yC) {\n              const wC = yC * strideWidth - xCCorner;\n              const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n              const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                  fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n              for (let dm = 0; dm < chMul; ++dm) {\n                const d2 = d1 * chMul + dm;\n                const pixel = dyValues[dyOffset + d2];\n                const weight = fltValues[fltOffset + dm];\n                dotProd += pixel * weight;\n              }\n            }\n          }\n          dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const depthwiseConv2dNativeBackpropInputConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNativeBackpropInput as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {buffer, Diag, DiagInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function diag(args: {inputs: DiagInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  const xSize = util.sizeFromShape(x.shape);\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const outBuf = buffer([xSize, xSize], x.dtype);\n  const vals = outBuf.values;\n  for (let i = 0; i < xVals.length; i++) {\n    vals[i * xSize + i] = xVals[i];\n  }\n\n  const outShape = [...x.shape, ...x.shape];\n\n  return backend.makeTensorInfo(outShape, outBuf.dtype, outBuf.values);\n}\n\nexport const diagConfig: KernelConfig = {\n  kernelName: Diag,\n  backendName: 'cpu',\n  kernelFunc: diag as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2D, Dilation2DAttrs, Dilation2DInputs, KernelConfig, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2DConfig: KernelConfig = {\n  kernelName: Dilation2D,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter} = inputs as Dilation2DInputs;\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xRank = x.shape.length;\n\n    const filterVals = cpuBackend.data.get(filter.dataId).values as TypedArray;\n    const filterRank = filter.shape.length;\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    const outSize = util.sizeFromShape(outShape);\n    const outRank = outShape.length;\n    const outputVals = util.getArrayFromDType(x.dtype, outSize);\n\n    // Upsampling the input by fill in `dilation size - 1` values between each\n    // input value.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const xIndex = util.locToIndex(\n                        [b, hIn, wIn, d], xRank, util.computeStrides(x.shape));\n                    const filterIndex = util.locToIndex(\n                        [h, w, d], filterRank,\n                        util.computeStrides(filter.shape));\n                    const val = xVals[xIndex] + filterVals[filterIndex];\n                    if (val > curVal) {\n                      curVal = val;\n                    }\n                  }\n                }\n              }\n            }\n            const outputIndex = util.locToIndex(\n                [b, hOut, wOut, d], outRank, util.computeStrides(outShape));\n            outputVals[outputIndex] = curVal;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(outputVals, x.dtype), outShape, x.dtype);\n\n    return {dataId, shape: outShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropFilter, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2DBackpropFilterConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropFilter}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed filter gradients has the same dimensions as the filter:\n    // [filterHeight, filterWidth, depth]\n    const gradients = util.makeZerosNestedTypedArray(\n                          filter.shape, filter.dtype) as number[][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hMax = 0;\n            let wMax = 0;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hMax = h;\n                      wMax = w;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);\n\n    return {dataId, shape: filter.shape, dtype: filter.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropInput, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2DBackpropInputConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropInput}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed gradients has the same dimensions as the input:\n    // [batch, inputHeight, inputCols, inChannel]\n    const gradients =\n        util.makeZerosNestedTypedArray(x.shape, x.dtype) as number[][][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hInMax = (hBeg < 0) ? 0 : hBeg;\n            let wInMax = (wBeg < 0) ? 0 : wBeg;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hInMax = hIn;\n                      wInMax = wIn;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Sum, SumAttrs, SumInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {zeros} from '../utils/zeros_impl';\nimport {cast} from './Cast';\nimport {identity} from './Identity';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function sum(\n    args: {inputs: SumInputs, backend: MathBackendCPU, attrs: SumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'sum');\n\n  let $x;\n  if (x.dtype === 'bool') {\n    $x = cast({inputs: {x}, backend, attrs: {dtype: 'int32'}});\n  } else {\n    $x = identity({inputs: {x}, backend});\n  }\n\n  const xRank = $x.shape.length;\n  const axes = util.parseAxisParam(axis, $x.shape);\n  const permutation = backend_util.getAxesPermutation(axes, xRank);\n\n  let reductionAxes = axes;\n  let permutedX = $x;\n  if (permutation != null) {\n    permutedX =\n        transpose({inputs: {x: $x}, backend, attrs: {perm: permutation}});\n    reductionAxes = backend_util.getInnerMostAxes(reductionAxes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims(\n      'sum', reductionAxes, permutedX.shape.length);\n\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(permutedX.shape, reductionAxes);\n  const resultDtype = backend_util.upcastType(permutedX.dtype, 'int32');\n  let result = zeros(backend, outShape, resultDtype);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = backend.data.get(result.dataId).values as TypedArray;\n\n  const aVals = backend.data.get(permutedX.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let sum = 0;\n    for (let j = 0; j < reduceSize; ++j) {\n      sum += aVals[offset + j];\n    }\n    vals[i] = sum;\n  }\n\n  if (keepDims) {\n    const newShape = backend_util.expandShapeToKeepDim(result.shape, axes);\n    const oldResult = result;\n    result = reshape({inputs: {x: result}, backend, attrs: {shape: newShape}});\n    backend.disposeIntermediateTensorInfo(oldResult);\n  }\n\n  backend.disposeIntermediateTensorInfo($x);\n\n  if (permutation != null) {\n    backend.disposeIntermediateTensorInfo(permutedX);\n  }\n\n  return result;\n}\n\nexport const sumConfig: KernelConfig = {\n  kernelName: Sum,\n  backendName: 'cpu',\n  kernelFunc: sum as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Einsum, EinsumAttrs, EinsumInputs, KernelConfig, KernelFunc, Tensor, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {multiply} from './Multiply';\nimport {reshape} from './Reshape';\nimport {sum} from './Sum';\nimport {transpose} from './Transpose';\n\nexport function einsum(\n    args: {inputs: EinsumInputs, backend: MathBackendCPU, attrs: EinsumAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {equation} = attrs;\n  const tensors = inputs as Tensor[];\n\n  const {allDims, summedDims, idDims} =\n      backend_util.decodeEinsumEquation(equation, tensors.length);\n  backend_util.checkEinsumDimSizes(allDims.length, idDims, tensors);\n  const {path, steps} = backend_util.getEinsumComputePath(summedDims, idDims);\n\n  const nSteps = steps.length;\n  let out: TensorInfo|null = null;\n  let numDimsRemaining = allDims.length;\n  const tensorsToDispose: TensorInfo[] = [];\n  for (let i = 0; i < nSteps; ++i) {\n    for (const idTerm of steps[i]) {\n      const {permutationIndices: perm, expandDims: dimsToExpand} =\n          backend_util.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);\n      let x: TensorInfo;\n      if (backend_util.isIdentityPermutation(perm)) {\n        x = tensors[idTerm];\n      } else {\n        x = transpose({inputs: {x: tensors[idTerm]}, backend, attrs: {perm}});\n        tensorsToDispose.push(x);\n      }\n      const targetShape: number[] = x.shape.slice();\n      for (let k = 0; k < dimsToExpand.length; ++k) {\n        targetShape.splice(dimsToExpand[k], 0, 1);\n      }\n\n      if (!util.arraysEqual(x.shape, targetShape)) {\n        x = reshape({inputs: {x}, backend, attrs: {shape: targetShape}});\n        tensorsToDispose.push(x);\n      }\n      if (out === null) {\n        out = x;\n      } else {\n        // tslint:disable-next-line: no-unnecessary-type-assertion\n        out = multiply({inputs: {a: x, b: out}, backend}) as TensorInfo;\n        tensorsToDispose.push(out);\n      }\n    }\n    if (i < nSteps - 1) {\n      if (path[i] >= 0) {\n        out = sum({\n          inputs: {x: out},\n          backend,\n          attrs: {\n            axis: path[i] - (allDims.length - numDimsRemaining),\n            keepDims: false\n          }\n        });\n        tensorsToDispose.push(out);\n      }\n      numDimsRemaining--;\n    }\n  }\n\n  // Clean up intermediate tensors.\n  for (const tensorInfo of tensorsToDispose) {\n    if (tensorInfo === out) {\n      continue;\n    }\n    backend.disposeIntermediateTensorInfo(tensorInfo);\n  }\n\n  return out;\n}\n\nexport const einsumConfig: KernelConfig = {\n  kernelName: Einsum,\n  backendName: 'cpu',\n  kernelFunc: einsum as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {EluGrad, EluGradInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function eluGrad(args: {inputs: EluGradInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {dy, y} = inputs;\n\n  assertNotComplex([dy, y], 'eluGrad');\n\n  const resultValues = new Float32Array(util.sizeFromShape(y.shape));\n  const values = backend.data.get(y.dataId).values as TypedArray;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  for (let i = 0; i < values.length; ++i) {\n    const v = values[i];\n    if (v >= 1) {\n      resultValues[i] = dyValues[i];\n    } else {\n      resultValues[i] = dyValues[i] * (v + 1);\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, 'float32', resultValues);\n}\n\nexport const eluGradConfig: KernelConfig = {\n  kernelName: EluGrad,\n  backendName: 'cpu',\n  kernelFunc: eluGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Erf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst p = backend_util.ERF_P;\nconst a1 = backend_util.ERF_A1;\nconst a2 = backend_util.ERF_A2;\nconst a3 = backend_util.ERF_A3;\nconst a4 = backend_util.ERF_A4;\nconst a5 = backend_util.ERF_A5;\n\nexport const erf = unaryKernelFunc(\n    Erf,\n    (xi) => {\n      const sign = Math.sign(xi);\n      const v = Math.abs(xi);\n      const t = 1.0 / (1.0 + p * v);\n      return sign *\n          (1.0 -\n           (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t *\n               Math.exp(-v * v));\n    },\n);\n\nexport const erfConfig: KernelConfig = {\n  kernelName: Erf,\n  backendName: 'cpu',\n  kernelFunc: erf,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ExpandDims, ExpandDimsAttrs, ExpandDimsInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {reshape} from './Reshape';\n\nexport function expandDims(args: {\n  inputs: ExpandDimsInputs,\n  backend: MathBackendCPU,\n  attrs: ExpandDimsAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {input} = inputs;\n  const {dim} = attrs;\n\n  const inputRank = input.shape.length;\n  const newShape = input.shape.slice();\n  let $dim = dim;\n  if (dim < 0) {\n    // Negative value is counted from the tail of rank.\n    util.assert(\n        -(inputRank + 1) <= dim,\n        () => `Axis must be in the interval [${- (inputRank + 1)}, ${\n            inputRank}]`);\n    $dim = inputRank + dim + 1;\n  }\n  newShape.splice($dim, 0, 1);\n\n  return reshape({inputs: {x: input}, backend, attrs: {shape: newShape}});\n}\n\nexport const expandDimsConfig: KernelConfig = {\n  kernelName: ExpandDims,\n  backendName: 'cpu',\n  kernelFunc: expandDims as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, RealDiv} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const realDivImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a / b);\nexport const div = binaryKernelFunc(RealDiv, realDivImpl);\n\nexport const realDivConfig: KernelConfig = {\n  kernelName: RealDiv,\n  backendName: 'cpu',\n  kernelFunc: div\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Tensor, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {add} from '../kernels/Add';\nimport {complex} from '../kernels/Complex';\nimport {concat} from '../kernels/Concat';\nimport {identity} from '../kernels/Identity';\nimport {imag} from '../kernels/Imag';\nimport {multiply} from '../kernels/Multiply';\nimport {real} from '../kernels/Real';\nimport {realDivConfig} from '../kernels/RealDiv';\nimport {slice} from '../kernels/Slice';\nimport {sub} from '../kernels/Sub';\n\n/**\n * Calculate FFT of inner most elements of batch tensor.\n */\nexport function fftBatch(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): TensorInfo {\n  const inputShape = input.shape;\n  const batch = inputShape[0];\n  const innerDim = inputShape[1];\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const real2D = inputVals.complexTensorInfos.real;\n  const imag2D = inputVals.complexTensorInfos.imag;\n\n  // Collects real and imaginary values separately.\n  const resultShape = [batch, innerDim];\n  const resultSize = util.sizeFromShape(resultShape);\n  const resultReal = util.getTypedArrayFromDType('float32', resultSize);\n  const resultImag = util.getTypedArrayFromDType('float32', resultSize);\n\n  for (let b = 0; b < batch; b++) {\n    // TODO: Support slice ops for complex type.\n    const r = slice({\n      inputs: {x: real2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n    const i = slice({\n      inputs: {x: imag2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n\n    const input = complex({inputs: {real: r, imag: i}, backend: cpuBackend});\n\n    // Run FFT by batch element.\n    const {real, imag} = fftImpl(input, inverse, cpuBackend);\n    const res = backend_util.mergeRealAndImagArrays(real, imag);\n\n    for (let d = 0; d < innerDim; d++) {\n      const c = backend_util.getComplexWithIndex(res, d);\n      resultReal[b * innerDim + d] = c.real;\n      resultImag[b * innerDim + d] = c.imag;\n    }\n\n    cpuBackend.disposeIntermediateTensorInfo(r);\n    cpuBackend.disposeIntermediateTensorInfo(i);\n    cpuBackend.disposeIntermediateTensorInfo(input);\n  }\n\n  const $realInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultReal);\n  const $imagInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultImag);\n\n  const result = complex(\n      {inputs: {real: $realInfo, imag: $imagInfo}, backend: cpuBackend});\n\n  cpuBackend.disposeIntermediateTensorInfo($realInfo);\n  cpuBackend.disposeIntermediateTensorInfo($imagInfo);\n\n  return result;\n}\n\nexport function fftImpl(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  const inputSize = util.sizeFromShape(input.shape);\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const realVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values as\n      Float32Array;\n\n  const imagVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values as\n      Float32Array;\n\n  if (isExponentOf2(inputSize)) {\n    const result =\n        fftRadix2(realVals, imagVals, inputSize, inverse, cpuBackend);\n\n    const resultShape = [input.shape[0], input.shape[1]];\n\n    if (inverse) {\n      const realInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.real);\n      const imagInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.imag);\n\n      const sizeInfo: TensorInfo = cpuBackend.makeTensorInfo(\n          [], 'float32',\n          util.createScalarValue(inputSize as {} as 'float32', 'float32'));\n      const sizeInfoCopy =\n          identity({inputs: {x: sizeInfo}, backend: cpuBackend});\n\n      const divRealInfo =\n          realDivConfig.kernelFunc(\n              {inputs: {a: realInfo, b: sizeInfo}, backend: cpuBackend}) as\n          TensorInfo;\n      const divImagInfo =\n          realDivConfig.kernelFunc(\n              {inputs: {a: imagInfo, b: sizeInfoCopy}, backend: cpuBackend}) as\n          TensorInfo;\n\n      const divRealVals =\n          cpuBackend.data.get(divRealInfo.dataId).values as Float32Array;\n      const divImagVals =\n          cpuBackend.data.get(divImagInfo.dataId).values as Float32Array;\n\n      cpuBackend.disposeIntermediateTensorInfo(realInfo);\n      cpuBackend.disposeIntermediateTensorInfo(imagInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);\n      cpuBackend.disposeIntermediateTensorInfo(divRealInfo);\n      cpuBackend.disposeIntermediateTensorInfo(divImagInfo);\n\n      return {real: divRealVals, imag: divImagVals};\n    }\n\n    return result;\n  } else {\n    const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n    const rawOutput =\n        fourierTransformByMatmul(data, inputSize, inverse) as Float32Array;\n\n    return backend_util.splitRealAndImagArrays(rawOutput);\n  }\n}\n\nfunction isExponentOf2(size: number): boolean {\n  return (size & size - 1) === 0;\n}\n\n// FFT using Cooley-Tukey algorithm on radix 2 dimensional input.\nfunction fftRadix2(\n    realVals: Float32Array, imagVals: Float32Array, size: number,\n    inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  if (size === 1) {\n    return {real: realVals, imag: imagVals};\n  }\n\n  const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n  const half = size / 2;\n\n  const evenComplex = backend_util.complexWithEvenIndex(data);\n\n  const evenRealVals = evenComplex.real;\n  const evenImagVals = evenComplex.imag;\n\n  const evenShape = [evenRealVals.length];\n\n  const evenRealInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenRealVals);\n  const evenImagInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenImagVals);\n\n  const evenTensorInfo = complex(\n      {inputs: {real: evenRealInfo, imag: evenImagInfo}, backend: cpuBackend});\n\n  const oddComplex = backend_util.complexWithOddIndex(data);\n\n  const oddRealVals = oddComplex.real;\n  const oddImagVals = oddComplex.imag;\n\n  const oddShape = [oddRealVals.length];\n\n  const oddRealInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddRealVals);\n  const oddImagInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddImagVals);\n\n  const oddTensorInfo = complex(\n      {inputs: {real: oddRealInfo, imag: oddImagInfo}, backend: cpuBackend});\n\n  // Recursive call for half part of original input.\n  const $evenComplex =\n      fftRadix2(evenRealVals, evenImagVals, half, inverse, cpuBackend);\n\n  const $evenRealVals = $evenComplex.real;\n  const $evenImagVals = $evenComplex.imag;\n\n  const $evenShape = [$evenRealVals.length];\n\n  const $evenRealInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenRealVals);\n  const $evenImagInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenImagVals);\n\n  const $evenTensorInfo = complex({\n    inputs: {real: $evenRealInfo, imag: $evenImagInfo},\n    backend: cpuBackend\n  });\n\n  const $oddComplex =\n      fftRadix2(oddRealVals, oddImagVals, half, inverse, cpuBackend);\n\n  const $oddRealVals = $oddComplex.real;\n  const $oddImagVals = $oddComplex.imag;\n\n  const $oddShape = [$oddRealVals.length];\n\n  const $oddRealInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddRealVals);\n  const $oddImagInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddImagVals);\n\n  const $oddTensorInfo = complex(\n      {inputs: {real: $oddRealInfo, imag: $oddImagInfo}, backend: cpuBackend});\n\n  const e = backend_util.exponents(size, inverse);\n  const eShape = [e.real.length];\n\n  const eRealInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.real);\n  const eImagInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.imag);\n\n  const complexInfo = complex(\n      {inputs: {real: eRealInfo, imag: eImagInfo}, backend: cpuBackend});\n\n  const exponentInfo =\n      multiply(\n          {inputs: {a: complexInfo, b: $oddTensorInfo}, backend: cpuBackend}) as\n      TensorInfo;\n\n  const addPart = add({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n  const subPart = sub({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n\n  const addPartReal = real({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartReal = real({inputs: {input: subPart}, backend: cpuBackend});\n\n  const addPartImag = imag({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartImag = imag({inputs: {input: subPart}, backend: cpuBackend});\n\n  const $real = concat({\n    inputs: [addPartReal as Tensor, subPartReal as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n  const $imag = concat({\n    inputs: [addPartImag as Tensor, subPartImag as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n\n  const $realVals = cpuBackend.data.get($real.dataId).values as Float32Array;\n  const $imagVals = cpuBackend.data.get($imag.dataId).values as Float32Array;\n\n  cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(complexInfo);\n  cpuBackend.disposeIntermediateTensorInfo(exponentInfo);\n  cpuBackend.disposeIntermediateTensorInfo(addPart);\n  cpuBackend.disposeIntermediateTensorInfo(subPart);\n  cpuBackend.disposeIntermediateTensorInfo(addPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(addPartImag);\n  cpuBackend.disposeIntermediateTensorInfo(subPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(subPartImag);\n  cpuBackend.disposeIntermediateTensorInfo($real);\n  cpuBackend.disposeIntermediateTensorInfo($imag);\n\n  return {real: $realVals, imag: $imagVals};\n}\n\n// Calculate fourier transform by multplying sinusoid matrix.\nfunction fourierTransformByMatmul(\n    data: TypedArray, size: number, inverse: boolean): TypedArray {\n  const ret = new Float32Array(size * 2);\n  // TODO: Use matmul instead once it supports complex64 type.\n  for (let r = 0; r < size; r++) {\n    let real = 0.0;\n    let imag = 0.0;\n    for (let c = 0; c < size; c++) {\n      const e = backend_util.exponent(r * c, size, inverse);\n      const term = backend_util.getComplexWithIndex(data as Float32Array, c);\n      real += term.real * e.real - term.imag * e.imag;\n      imag += term.real * e.imag + term.imag * e.real;\n    }\n    if (inverse) {\n      real /= size;\n      imag /= size;\n    }\n    backend_util.assignToTypedArray(ret, real, imag, r);\n  }\n  return ret;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FFT, FFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function fft(args: {inputs: FFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, false, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const fftConfig: KernelConfig = {\n  kernelName: FFT,\n  backendName: 'cpu',\n  kernelFunc: fft as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, DataValues, Fill, FillAttrs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function fill(args: {backend: MathBackendCPU, attrs: FillAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {shape, value, dtype} = attrs;\n\n  const $dtype = dtype || util.inferDtype(value);\n  const values = util.getArrayFromDType($dtype, util.sizeFromShape(shape));\n  fillValues(values, value, $dtype);\n\n  return backend.makeTensorInfo(shape, $dtype, values);\n}\n\nexport const fillConfig: KernelConfig = {\n  kernelName: Fill,\n  backendName: 'cpu',\n  kernelFunc: fill as {} as KernelFunc\n};\n\nfunction fillValues(\n    values: DataValues, value: string|number, dtype: DataType): void {\n  if (dtype === 'string') {\n    (values as string[]).fill(value as string);\n  } else {\n    (values as TypedArray).fill(value as number);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {FlipLeftRight, FlipLeftRightInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const flipLeftRightConfig: KernelConfig = {\n  kernelName: FlipLeftRight,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as FlipLeftRightInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coordX = Math.round(imageWidth - col - 1);\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n\n            let outputValue = imageVals[outIdx];\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth) {\n              // set the output to the image value at the coordinate position.\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n            output[outIdx] = outputValue;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FloorDiv, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const floorDivImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => Math.floor(a / b));\nexport const floorDiv =\n    binaryKernelFunc(FloorDiv, floorDivImpl, null /* complexImpl */, 'int32');\n\nexport const floorDivConfig: KernelConfig = {\n  kernelName: FloorDiv,\n  backendName: 'cpu',\n  kernelFunc: floorDiv\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\nimport {add} from './Add';\nimport {conv2D} from './Conv2D';\nimport {reshape} from './Reshape';\n\nexport function fusedConv2D(args: {\n  inputs: FusedConv2DInputs,\n  backend: MathBackendCPU,\n  attrs: FusedConv2DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  let result = conv2D({\n    inputs: {x, filter},\n    backend,\n    attrs: {strides, pad, dataFormat, dilations, dimRoundingMode}\n  });\n\n  if (bias) {\n    const resultOld = result;\n    // For NCHW format, if bias is a 1-D tensor, it is supposed to be aligned\n    // to the channel of the conv2d's result; if the bias is a scalar, the\n    // bias_add is computed as if the bias was broadcasted to the shape of the\n    // conv2d's result.\n    if (dataFormat === 'NCHW' && bias.shape.length === 1 &&\n        bias.shape[0] !== 1) {\n      const reshapedBias = reshape(\n          {inputs: {x: bias}, backend, attrs: {shape: [bias.shape[0], 1, 1]}});\n      result =\n          add({inputs: {a: result, b: reshapedBias}, backend}) as TensorInfo;\n      backend.disposeIntermediateTensorInfo(reshapedBias);\n    } else {\n      // This condition handles NHWC and NCHW (scalar case). The only other case\n      // for NCHW (1D case) is handled above.\n      result = add({inputs: {a: result, b: bias}, backend}) as TensorInfo;\n    }\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  if (activation) {\n    const resultOld = result;\n    // For NCHW format, if PReLu activation weights is a 1-D tensor, it is\n    // supposed to be aligned with the channel of the conv2d's result. For other\n    // cases, whether NCHW or NHWC data format, the conv2d result is\n    // already aligned with the activation weights.\n    if (dataFormat === 'NCHW' && activation === 'prelu' &&\n        preluActivationWeights.shape.length === 1 &&\n        preluActivationWeights.shape[0] !== 1) {\n      const reshapedAlpha = reshape({\n        inputs: {x: preluActivationWeights},\n        backend,\n        attrs: {shape: [preluActivationWeights.shape[0], 1, 1]}\n      });\n      result = applyActivation(\n          backend, result, activation, reshapedAlpha, leakyreluAlpha);\n      backend.disposeIntermediateTensorInfo(reshapedAlpha);\n    } else {\n      result = applyActivation(\n          backend, result, activation, preluActivationWeights, leakyreluAlpha);\n    }\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  return result;\n}\n\nexport const fusedConv2DConfig: KernelConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'cpu',\n  kernelFunc: fusedConv2D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedDepthwiseConv2D, FusedDepthwiseConv2DAttrs, FusedDepthwiseConv2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\nimport {add} from './Add';\nimport {depthwiseConv2dNative} from './DepthwiseConv2dNative';\n\nexport function fusedDepthwiseConv2D(args: {\n  inputs: FusedDepthwiseConv2DInputs,\n  backend: MathBackendCPU,\n  attrs: FusedDepthwiseConv2DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n\n  let result = depthwiseConv2dNative({\n    inputs: {x, filter},\n    backend,\n    attrs: {strides, pad, dataFormat, dilations, dimRoundingMode}\n  });\n\n  if (bias) {\n    const oldResult = result;\n    result = add({inputs: {a: result, b: bias}, backend}) as TensorInfo;\n    backend.disposeIntermediateTensorInfo(oldResult);\n  }\n  if (activation) {\n    const oldResult = result;\n    result = applyActivation(\n        backend, result, activation, preluActivationWeights, leakyreluAlpha);\n    backend.disposeIntermediateTensorInfo(oldResult);\n  }\n\n  return result;\n}\n\nexport const fusedDepthwiseConv2DConfig: KernelConfig = {\n  kernelName: FusedDepthwiseConv2D,\n  backendName: 'cpu',\n  kernelFunc: fusedDepthwiseConv2D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, GatherNd, GatherNdInputs, KernelConfig, KernelFunc, Rank, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {gatherNdImpl} from './GatherNd_Impl';\n\nexport function gatherNd(\n    args: {inputs: GatherNdInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {params, indices} = inputs;\n\n  const paramsSize = util.sizeFromShape(params.shape);\n\n  const indicesShape = indices.shape;\n  const sliceRank = indicesShape[indicesShape.length - 1];\n\n  const [resultShape, numSlices, sliceSize, strides] =\n      backend_util.prepareAndValidate(params, indices);\n  if (numSlices === 0) {\n    return backend.makeTensorInfo(resultShape, params.dtype, []);\n  }\n\n  const indicesData = backend.data.get(indices.dataId).values as TypedArray;\n  const paramsBuf = backend.bufferSync<Rank, 'float32'>(params);\n  const outBuf = gatherNdImpl(\n      indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize,\n      strides, params.shape, paramsSize);\n\n  return backend.makeTensorInfo(resultShape, params.dtype, outBuf.values);\n}\n\nexport const gatherNdConfig: KernelConfig = {\n  kernelName: GatherNd,\n  backendName: 'cpu',\n  kernelFunc: gatherNd as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, GatherV2, GatherV2Attrs, GatherV2Inputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {gatherV2Impl} from './GatherV2_impl';\nimport {reshape} from './Reshape';\n\nexport function gatherV2(args: {\n  inputs: GatherV2Inputs,\n  backend: MathBackendCPU,\n  attrs: GatherV2Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, indices} = inputs;\n  const {axis, batchDims} = attrs;\n\n  assertNotComplex([x, indices], 'gatherV2');\n\n  // Throw error when any index is out of bound.\n  const parsedAxis = util.parseAxisParam(axis, x.shape)[0];\n  const indicesVals = backend.data.get(indices.dataId).values as TypedArray;\n  const axisDim = x.shape[parsedAxis];\n  for (let i = 0; i < indicesVals.length; ++i) {\n    const index = indicesVals[i];\n    util.assert(\n        index <= axisDim - 1 && index >= 0,\n        () =>\n            `GatherV2: the index value ${index} is not in [0, ${axisDim - 1}]`);\n  }\n\n  let $batchDims = batchDims;\n\n  if (batchDims == null) {\n    $batchDims = 0;\n  }\n\n  const indicesSize = util.sizeFromShape(indices.shape);\n\n  const shapeInfo = backend_util.segment_util.collectGatherOpShapeInfo(\n      x, indices, parsedAxis, $batchDims);\n\n  const flattenX = reshape({\n    inputs: {x},\n    backend,\n    attrs: {\n      shape: [\n        shapeInfo.batchSize, shapeInfo.outerSize, shapeInfo.dimSize,\n        shapeInfo.sliceSize\n      ]\n    }\n  });\n\n  const flattenIndex = reshape({\n    inputs: {x: indices},\n    backend,\n    attrs: {shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize]}\n  });\n\n  const flattenOutputShape = [\n    shapeInfo.batchSize, shapeInfo.outerSize, indicesSize / shapeInfo.batchSize,\n    shapeInfo.sliceSize\n  ];\n\n  const indicesBuf = backend.bufferSync(flattenIndex);\n  const xBuf = backend.bufferSync(flattenX);\n  const outBuf = gatherV2Impl(xBuf, indicesBuf, flattenOutputShape);\n\n  backend.disposeIntermediateTensorInfo(flattenX);\n  backend.disposeIntermediateTensorInfo(flattenIndex);\n\n  return backend.makeTensorInfo(\n      shapeInfo.outputShape, outBuf.dtype, outBuf.values);\n}\n\nexport const gatherV2Config: KernelConfig = {\n  kernelName: GatherV2,\n  backendName: 'cpu',\n  kernelFunc: gatherV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IFFT, IFFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function ifft(args: {inputs: IFFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, true, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const ifftConfig: KernelConfig = {\n  kernelName: IFFT,\n  backendName: 'cpu',\n  kernelFunc: ifft as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsFinite, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isFinite =\n    unaryKernelFunc(IsFinite, (xi) => Number.isFinite(xi) ? 1 : 0, 'bool');\n\nexport const isFiniteConfig: KernelConfig = {\n  kernelName: IsFinite,\n  backendName: 'cpu',\n  kernelFunc: isFinite,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsInf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isInf =\n    unaryKernelFunc(IsInf, (xi) => Math.abs(xi) === Infinity ? 1 : 0, 'bool');\n\nexport const isInfConfig: KernelConfig = {\n  kernelName: IsInf,\n  backendName: 'cpu',\n  kernelFunc: isInf,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsNan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isNaN =\n    unaryKernelFunc(IsNan, (xi) => Number.isNaN(xi) ? 1 : 0, 'bool');\n\nexport const isNaNConfig: KernelConfig = {\n  kernelName: IsNan,\n  backendName: 'cpu',\n  kernelFunc: isNaN,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LinSpace, LinSpaceAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {linSpaceImpl} from './LinSpace_impl';\n\nexport function linSpace(args: {backend: MathBackendCPU, attrs: LinSpaceAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {start, stop, num} = attrs;\n\n  const outVals = linSpaceImpl(start, stop, num);\n\n  return backend.makeTensorInfo([outVals.length], 'float32', outVals);\n}\n\nexport const linSpaceConfig: KernelConfig = {\n  kernelName: LinSpace,\n  backendName: 'cpu',\n  kernelFunc: linSpace as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log1p} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const log1p = unaryKernelFunc(Log1p, (xi) => Math.log1p(xi));\n\nexport const log1pConfig: KernelConfig = {\n  kernelName: Log1p,\n  backendName: 'cpu',\n  kernelFunc: log1p,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalAnd} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const logicalAndImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a && b);\nexport const logicalAnd = binaryKernelFunc(\n    LogicalAnd, logicalAndImpl, null /* complexImpl */, 'bool');\n\nexport const logicalAndConfig: KernelConfig = {\n  kernelName: LogicalAnd,\n  backendName: 'cpu',\n  kernelFunc: logicalAnd\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalNot} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const logicalNot =\n    unaryKernelFunc(LogicalNot, (xi) => xi ? 0 : 1, 'bool');\n\nexport const logicalNotConfig: KernelConfig = {\n  kernelName: LogicalNot,\n  backendName: 'cpu',\n  kernelFunc: logicalNot,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalOr} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const logicalOrImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a || b);\nexport const logicalOr =\n    binaryKernelFunc(LogicalOr, logicalOrImpl, null /* complexImpl */, 'bool');\n\nexport const logicalOrConfig: KernelConfig = {\n  kernelName: LogicalOr,\n  backendName: 'cpu',\n  kernelFunc: logicalOr\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRN, LRNAttrs, LRNInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function lRN(\n    args: {inputs: LRNInputs, backend: MathBackendCPU, attrs: LRNAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  assertNotComplex(x, 'LRN');\n\n  const channels = x.shape[3];\n  const maxD = channels - 1;\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const size = util.sizeFromShape(x.shape);\n  const result = new Float32Array(size);\n\n  function sumAcrossChannels(offset: number) {\n    const currentChannel = offset % channels;\n    let beginSumOffset =\n        offset - currentChannel + Math.max(0, currentChannel - depthRadius);\n    const endSumOffset =\n        offset - currentChannel + Math.min(currentChannel + depthRadius, maxD);\n\n    let sum = 0.0;\n    for (; beginSumOffset <= endSumOffset; beginSumOffset++) {\n      const z = xValues[beginSumOffset];\n      sum += z * z;\n    }\n    return sum;\n  }\n\n  for (let offset = 0; offset < size; offset++) {\n    const sum = sumAcrossChannels(offset);\n    const val = xValues[offset] * Math.pow(bias + alpha * sum, -beta);\n    result[offset] = val;\n  }\n\n  return backend.makeTensorInfo(x.shape, x.dtype, result);\n}\n\n// tslint:disable-next-line: variable-name\nexport const LRNConfig: KernelConfig = {\n  kernelName: LRN,\n  backendName: 'cpu',\n  kernelFunc: lRN as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRNGrad, LRNGradAttrs, LRNGradInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function lRNGrad(\n    args:\n        {inputs: LRNGradInputs, backend: MathBackendCPU, attrs: LRNGradAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, y, dy} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  assertNotComplex(dy, 'LRNGrad');\n\n  const dySize = util.sizeFromShape(dy.shape);\n\n  const channels = dy.shape[3];\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const yValues = backend.data.get(y.dataId).values as TypedArray;\n  const result = new Float32Array(dySize);\n  const size = dySize;\n\n  for (let offset = 0; offset < size; offset++) {\n    const currentChannel = offset % channels;\n    const depthBegin =\n        (offset - currentChannel) + Math.max(0, currentChannel - depthRadius);\n    const depthEnd = (offset - currentChannel) +\n        Math.min(channels, currentChannel + depthRadius + 1);\n\n    let norm = 0;\n    for (let k = depthBegin; k < depthEnd; k++) {\n      norm += Math.pow(xValues[k], 2);\n    }\n    norm = alpha * norm + bias;\n\n    for (let k = depthBegin; k < depthEnd; k++) {\n      let dyi = -2 * alpha * beta * xValues[k] * yValues[offset] / norm;\n      if (offset === k) {\n        dyi += Math.pow(norm, -beta);\n      }\n      dyi *= dyValues[offset];\n      result[k] += dyi;\n    }\n  }\n\n  return backend.makeTensorInfo(dy.shape, x.dtype, result);\n}\n\n// tslint:disable-next-line: variable-name\nexport const LRNGradConfig: KernelConfig = {\n  kernelName: LRNGrad,\n  backendName: 'cpu',\n  kernelFunc: lRNGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig} from '@tensorflow/tfjs-core';\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl} from './Transpose_impl';\n\nexport function max(\n    args: {inputs: MaxInputs, backend: MathBackendCPU, attrs: MaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reductionIndices, keepDims} = attrs;\n  const cpuBackend = backend;\n  let xShape = x.shape;\n  const xRank = xShape.length;\n\n  const origAxes = util.parseAxisParam(reductionIndices, xShape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  let xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n  if (permutedAxes != null) {\n    const newShape: number[] = new Array(xRank);\n    for (let i = 0; i < newShape.length; i++) {\n      newShape[i] = xShape[permutedAxes[i]];\n    }\n\n    xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n\n    xShape = newShape;\n  }\n\n  assertNotComplex(x, 'max');\n  backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n  const [maxOutShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(xShape, axes);\n\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n  const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n\n  let outShape = maxOutShape;\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n    outShape = newShape;\n  }\n\n  return {dataId, shape: outShape, dtype: x.dtype};\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: max as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, KernelConfig, KernelFunc, MaxPool, MaxPoolAttrs, MaxPoolInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function maxPool(\n    args:\n        {inputs: MaxPoolInputs, backend: MathBackendCPU, attrs: MaxPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'maxPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'max');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const maxPoolConfig: KernelConfig = {\n  kernelName: MaxPool,\n  backendName: 'cpu',\n  kernelFunc: maxPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, MaxPool3D, MaxPool3DAttrs, MaxPool3DInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool3d} from '../utils/pool_utils';\n\nexport function maxPool3D(args: {\n  inputs: MaxPool3DInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPool3DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode, dataFormat} = attrs;\n\n  assertNotComplex(x, 'maxPool3d');\n\n  const convInfo = backend_util.computePool3DInfo(\n      x.shape as [number, number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode, dataFormat);\n\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const outBuf = pool3d(\n      xValues, x.shape, x.dtype, util.computeStrides(x.shape), convInfo, 'max');\n\n  return backend.makeTensorInfo(outBuf.shape, 'float32', outBuf.values);\n}\n\nexport const maxPool3DConfig: KernelConfig = {\n  kernelName: MaxPool3D,\n  backendName: 'cpu',\n  kernelFunc: maxPool3D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, KernelConfig, KernelFunc, MaxPool3DGrad, MaxPool3DGradAttrs, MaxPool3DGradInputs, Rank, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {maxPool3dPositions} from '../utils/pool_utils';\n\nexport function maxPool3DGrad(args: {\n  inputs: MaxPool3DGradInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPool3DGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  assertNotComplex([dy, input], 'maxPool3DGrad');\n\n  const convInfo = backend_util.computePool3DInfo(\n      input.shape as [number, number, number, number, number], filterSize,\n      strides, 1 /* dilations */, pad, dimRoundingMode);\n\n  const inputBuf = backend.bufferSync(input);\n  const maxPosBuf = maxPool3dPositions(inputBuf, convInfo);\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationDepth = convInfo.dilationDepth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx = buffer(input.shape, 'float32');\n\n  const dyBuf = backend.bufferSync<Rank, 'float32'>(dy);\n\n  for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n    for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n      for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n        for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n          for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n            // Shader code begins\n            const dyDepthCorner = dxDepth - padFront;\n            const dyRowCorner = dxRow - padTop;\n            const dyColCorner = dxCol - padLeft;\n            let dotProd = 0;\n            for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                 wDepth += dilationDepth) {\n              const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n              if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                  Math.floor(dyDepth) !== dyDepth) {\n                continue;\n              }\n              for (let wRow = 0; wRow < effectiveFilterHeight;\n                   wRow += dilationHeight) {\n                const dyRow = (dyRowCorner + wRow) / strideHeight;\n                if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                    Math.floor(dyRow) !== dyRow) {\n                  continue;\n                }\n                for (let wCol = 0; wCol < effectiveFilterWidth;\n                     wCol += dilationWidth) {\n                  const dyCol = (dyColCorner + wCol) / strideWidth;\n                  if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                      Math.floor(dyCol) !== dyCol) {\n                    continue;\n                  }\n\n                  const maxPos = effectiveFilterDepth * effectiveFilterHeight *\n                          effectiveFilterWidth -\n                      1 -\n                      (maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel) as\n                       number);\n                  const curPos =\n                      wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                      wRow * effectiveFilterWidth + wCol;\n\n                  const mask = maxPos === curPos ? 1 : 0;\n                  if (mask === 0) {\n                    continue;\n                  }\n\n                  const pixel =\n                      dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                  dotProd += pixel * mask;\n                }\n              }\n            }\n            dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const maxPool3DGradConfig: KernelConfig = {\n  kernelName: MaxPool3DGrad,\n  backendName: 'cpu',\n  kernelFunc: maxPool3DGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, buffer, KernelConfig, KernelFunc, MaxPoolGrad, MaxPoolGradAttrs, MaxPoolGradInputs, Rank, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {maxPoolPositions} from '../utils/pool_utils';\n\nexport function maxPoolGrad(args: {\n  inputs: MaxPoolGradInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPoolGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input, output} = inputs;\n  const x = input;\n  assertNotComplex([input, output], 'maxPoolGrad');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode);\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const maxPosBuf = buffer(\n      convInfo.outShape, x.dtype,\n      maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n              const maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 -\n                  (maxPosBuf.get(b, dyR, dyC, d) as number);\n              const curPos = wR * effectiveFilterWidth + wC;\n\n              const mask = maxPos === curPos ? 1 : 0;\n              if (mask === 0) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel * mask;\n            }\n          }\n          dx.set(dotProd, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const maxPoolGradConfig: KernelConfig = {\n  kernelName: MaxPoolGrad,\n  backendName: 'cpu',\n  kernelFunc: maxPoolGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxPoolWithArgmaxImpl} from './MaxPoolWithArgmax_impl';\n\nexport const maxPoolWithArgmaxConfig: KernelConfig = {\n  kernelName: MaxPoolWithArgmax,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxPoolWithArgmaxInputs;\n    const {filterSize, strides, pad, includeBatchInIndex} =\n        attrs as {} as MaxPoolWithArgmaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'MaxPoolWithArgmax');\n\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const convInfo = backend_util.computePool2DInfo(\n        x.shape as [number, number, number, number], filterSize, strides,\n        [1, 1], pad);\n    const [pooled, indexes] = maxPoolWithArgmaxImpl(\n        values, x.shape, x.dtype, includeBatchInIndex, convInfo);\n\n    const pooledDataId =\n        cpuBackend.write(pooled as Float32Array, convInfo.outShape, x.dtype);\n    const indexesDataId =\n        cpuBackend.write(indexes as Int32Array, convInfo.outShape, x.dtype);\n    return [\n      {dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype},\n      {dataId: indexesDataId, shape: convInfo.outShape, dtype: 'int32'}\n    ];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {maxPoolPositions, pool} from '../utils/pool_utils';\nexport function maxPoolWithArgmaxImpl(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    includeBatchInIndex: boolean, convInfo: backend_util.Conv2DInfo) {\n  const strides = util.computeStrides(xShape);\n  const maxPools = pool(xValues, xShape, dtype, strides, convInfo, 'max');\n  const maxPositions = maxPoolPositions(\n      xValues, xShape, dtype, convInfo, true, includeBatchInIndex);\n\n  return [maxPools.values, maxPositions.values];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Mean, MeanAttrs, MeanInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {cast} from './Cast';\nimport {div} from './RealDiv';\nimport {sum} from './Sum';\n\nexport function mean(\n    args: {inputs: MeanInputs, backend: MathBackendCPU, attrs: MeanAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  const axes = util.parseAxisParam(axis, x.shape);\n  const shapes = backend_util.computeOutAndReduceShapes(x.shape, axes);\n  const reduceShape = shapes[1];\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const toDispose = [];\n  const reduceSizeScalar =\n      backend.makeTensorInfo([], 'float32', new Float32Array([reduceSize]));\n  toDispose.push(reduceSizeScalar);\n\n  const $x = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n  toDispose.push($x);\n\n  const res =\n      div({inputs: {a: $x, b: reduceSizeScalar}, backend}) as TensorInfo;\n  toDispose.push(res);\n\n  const result = sum({inputs: {x: res}, backend, attrs: {axis, keepDims}});\n\n  toDispose.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return result;\n}\n\nexport const meanConfig: KernelConfig = {\n  kernelName: Mean,\n  backendName: 'cpu',\n  kernelFunc: mean as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Min, MinAttrs, MinInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function min(\n    args: {inputs: MinInputs, backend: MathBackendCPU, attrs: MinAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {axis, keepDims} = attrs;\n\n  assertNotComplex(x, 'min');\n\n  const origAxes = util.parseAxisParam(axis, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, x.shape.length);\n  let $x = x;\n  if (permutedAxes != null) {\n    $x = transpose({inputs: {x}, backend, attrs: {perm: permutedAxes}});\n    axes = backend_util.getInnerMostAxes(axes.length, x.shape.length);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('min', axes, $x.shape.length);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes($x.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const vals = util.makeZerosTypedArray(util.sizeFromShape(outShape), $x.dtype);\n\n  const aVals = backend.data.get($x.dataId).values as TypedArray;\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let min = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (Number.isNaN(value) ||\n          value < min) {  // comparison with NaN always return false\n        min = value;\n      }\n    }\n    vals[i] = min;\n  }\n\n  if (permutedAxes != null) {\n    backend.disposeIntermediateTensorInfo($x);\n  }\n\n  const result = backend.makeTensorInfo(outShape, $x.dtype, vals);\n\n  if (keepDims) {\n    const expandedShape = backend_util.expandShapeToKeepDim(outShape, origAxes);\n    const reshapedResult =\n        reshape({inputs: {x: result}, backend, attrs: {shape: expandedShape}});\n\n    backend.disposeIntermediateTensorInfo(result);\n\n    return reshapedResult;\n  }\n\n  return result;\n}\n\nexport const minConfig: KernelConfig = {\n  kernelName: Min,\n  backendName: 'cpu',\n  kernelFunc: min as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, MirrorPad, MirrorPadAttrs, MirrorPadInputs, NumericDataType, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function mirrorPad(args: {\n  inputs: MirrorPadInputs,\n  backend: MathBackendCPU,\n  attrs: MirrorPadAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {paddings, mode} = attrs;\n\n  assertNotComplex(x, 'mirrorPad');\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  const start = paddings.map(p => p[0]);\n  const end = paddings.map((p, i) => p[0] + x.shape[i]);\n  const offset = mode === 'reflect' ? 0 : 1;\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xRank = x.shape.length;\n  const xStrides = util.computeStrides(x.shape);\n\n  const resultSize = util.sizeFromShape(outShape);\n  const resultRank = outShape.length;\n  const resultStrides = util.computeStrides(outShape);\n  const resVals =\n      util.getTypedArrayFromDType(x.dtype as NumericDataType, resultSize);\n\n  for (let i = 0; i < resultSize; i++) {\n    let coords = util.indexToLoc(i, resultRank, resultStrides);\n    for (let i = 0; i < resultRank; i++) {\n      if (coords[i] < start[i]) {\n        coords[i] = start[i] * 2 - coords[i] - offset;\n      } else if (coords[i] >= end[i]) {\n        coords[i] = (end[i] - 1) * 2 - coords[i] + offset;\n      }\n    }\n    coords = coords.map((c, i) => c - start[i]);\n\n    const inIndex = util.locToIndex(coords, xRank, xStrides);\n\n    resVals[i] = xVals[inIndex];\n  }\n\n  const outId = backend.write(resVals, outShape, x.dtype);\n\n  return {dataId: outId, shape: outShape, dtype: x.dtype};\n}\n\nexport const mirrorPadConfig: KernelConfig = {\n  kernelName: MirrorPad,\n  backendName: 'cpu',\n  kernelFunc: mirrorPad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Mod} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const modImpl =\n    createSimpleBinaryKernelImpl(((aValue: number, bValue: number) => {\n      const rem = aValue % bValue;\n      if ((aValue < 0 && bValue < 0) || (aValue >= 0 && bValue >= 0)) {\n        return rem;\n      } else {\n        return (rem + bValue) % bValue;\n      }\n    }));\n\nexport const mod = binaryKernelFunc(Mod, modImpl);\n\nexport const modConfig: KernelConfig = {\n  kernelName: Mod,\n  backendName: 'cpu',\n  kernelFunc: mod\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Softmax, SoftmaxAttrs, SoftmaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {exp} from './Exp';\nimport {max} from './Max';\nimport {div} from './RealDiv';\nimport {reshape} from './Reshape';\nimport {sub} from './Sub';\nimport {sum} from './Sum';\n\nexport function softmax(\n    args:\n        {inputs: SoftmaxInputs, backend: MathBackendCPU, attrs: SoftmaxAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {dim} = attrs;\n\n  const logitsRank = logits.shape.length;\n\n  let $dim = dim;\n  if ($dim === -1) {\n    $dim = logitsRank - 1;\n  }\n  if ($dim !== logitsRank - 1) {\n    throw Error(\n        'Softmax along a non-last dimension is not yet supported. ' +\n        `Logits was rank ${logitsRank} and dim was ${$dim}`);\n  }\n\n  const axes = util.parseAxisParam([$dim], logits.shape);\n  const maxLogit = max({\n    inputs: {x: logits},\n    backend,\n    attrs: {reductionIndices: axes, keepDims: false}\n  });\n  const expandedShape = backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n\n  const maxLogitReshaped =\n      reshape({inputs: {x: maxLogit}, backend, attrs: {shape: expandedShape}});\n  const a =\n      sub({inputs: {a: logits, b: maxLogitReshaped}, backend}) as TensorInfo;\n  const b = exp({inputs: {x: a}, backend}) as TensorInfo;\n  const sumExp =\n      sum({inputs: {x: b}, backend, attrs: {axis: axes, keepDims: false}});\n  const sumReshaped =\n      reshape({inputs: {x: sumExp}, backend, attrs: {shape: expandedShape}});\n\n  const result = div({inputs: {a: b, b: sumReshaped}, backend}) as TensorInfo;\n\n  backend.disposeIntermediateTensorInfo(maxLogit);\n  backend.disposeIntermediateTensorInfo(maxLogitReshaped);\n  backend.disposeIntermediateTensorInfo(a);\n  backend.disposeIntermediateTensorInfo(b);\n  backend.disposeIntermediateTensorInfo(sumExp);\n  backend.disposeIntermediateTensorInfo(sumReshaped);\n\n  return result;\n}\n\nexport const softmaxConfig: KernelConfig = {\n  kernelName: Softmax,\n  backendName: 'cpu',\n  kernelFunc: softmax as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Multinomial, MultinomialAttrs, MultinomialInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {softmax} from './Softmax';\n\nexport function multinomial(args: {\n  inputs: MultinomialInputs,\n  backend: MathBackendCPU,\n  attrs: MultinomialAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {logits} = inputs;\n  const {numSamples, seed, normalized} = attrs;\n\n  assertNotComplex(logits, 'multinomial');\n\n  const probabilities = normalized ?\n      logits :\n      softmax({inputs: {logits}, backend, attrs: {dim: -1}});\n\n  const batchSize = probabilities.shape[0];\n  const numEvents = probabilities.shape[1];\n  const probVals = backend.data.get(probabilities.dataId).values as TypedArray;\n  const resShape = [batchSize, numSamples];\n  const resVals =\n      util.makeZerosTypedArray(util.sizeFromShape(resShape), 'int32');\n\n  for (let b = 0; b < batchSize; ++b) {\n    const offset = b * numEvents;\n    // The cdf won't include the last event. It will be implicit if no other\n    // event happened.\n    const cdf = new Float32Array(numEvents - 1);\n    cdf[0] = probVals[offset];\n    for (let event = 1; event < cdf.length; ++event) {\n      cdf[event] = cdf[event - 1] + probVals[offset + event];\n    }\n\n    const random = seedrandom.alea(seed.toString());\n    const outOffset = b * numSamples;\n    for (let sampleId = 0; sampleId < numSamples; ++sampleId) {\n      const r = random();\n\n      // Assume last event happened by default.\n      resVals[outOffset + sampleId] = cdf.length;\n\n      for (let event = 0; event < cdf.length; event++) {\n        if (r < cdf[event]) {\n          resVals[outOffset + sampleId] = event;\n          break;\n        }\n      }\n    }\n  }\n\n  if (!normalized) {\n    backend.disposeIntermediateTensorInfo(probabilities);\n  }\n\n  return backend.makeTensorInfo(resShape, 'int32', resVals);\n}\n\nexport const multinomialConfig: KernelConfig = {\n  kernelName: Multinomial,\n  backendName: 'cpu',\n  kernelFunc: multinomial as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV3, NonMaxSuppressionV3Attrs, NonMaxSuppressionV3Inputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV3Impl = kernel_impls.nonMaxSuppressionV3Impl;\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function nonMaxSuppressionV3(args: {\n  inputs: NonMaxSuppressionV3Inputs,\n  backend: MathBackendCPU,\n  attrs: NonMaxSuppressionV3Attrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold} = attrs;\n\n  assertNotComplex(boxes, 'NonMaxSuppression');\n\n  const boxesVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const scoresVals = backend.data.get(scores.dataId).values as TypedArray;\n\n  const {selectedIndices} = nonMaxSuppressionV3Impl(\n      boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n\n  return backend.makeTensorInfo(\n      [selectedIndices.length], 'int32', new Int32Array(selectedIndices));\n}\n\nexport const nonMaxSuppressionV3Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV3,\n  backendName: 'cpu',\n  kernelFunc: nonMaxSuppressionV3 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV4, NonMaxSuppressionV4Attrs, NonMaxSuppressionV4Inputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV4Impl = kernel_impls.nonMaxSuppressionV4Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function nonMaxSuppressionV4(args: {\n  inputs: NonMaxSuppressionV4Inputs,\n  backend: MathBackendCPU,\n  attrs: NonMaxSuppressionV4Attrs\n}): [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize} =\n      attrs;\n\n  assertNotComplex(boxes, 'NonMaxSuppressionPadded');\n\n  const boxesVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const scoresVals = backend.data.get(scores.dataId).values as TypedArray;\n\n  const {selectedIndices, validOutputs} = nonMaxSuppressionV4Impl(\n      boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold,\n      padToMaxOutputSize);\n\n  return [\n    backend.makeTensorInfo(\n        [selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n    backend.makeTensorInfo([], 'int32', new Int32Array([validOutputs]))\n  ];\n}\nexport const nonMaxSuppressionV4Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV4,\n  backendName: 'cpu',\n  kernelFunc: nonMaxSuppressionV4 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {kernel_impls, KernelConfig, KernelFunc, NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV5Impl = kernel_impls.nonMaxSuppressionV5Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function nonMaxSuppressionV5(args: {\n  inputs: NonMaxSuppressionV5Inputs,\n  backend: MathBackendCPU,\n  attrs: NonMaxSuppressionV5Attrs\n}): [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {boxes, scores} = inputs;\n  const {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma} = attrs;\n\n  assertNotComplex(boxes, 'NonMaxSuppressionWithScore');\n\n  const boxesVals = backend.data.get(boxes.dataId).values as TypedArray;\n  const scoresVals = backend.data.get(scores.dataId).values as TypedArray;\n\n  const maxOutputSizeVal = maxOutputSize;\n  const iouThresholdVal = iouThreshold;\n  const scoreThresholdVal = scoreThreshold;\n  const softNmsSigmaVal = softNmsSigma;\n\n  const {selectedIndices, selectedScores} = nonMaxSuppressionV5Impl(\n      boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal,\n      scoreThresholdVal, softNmsSigmaVal);\n\n  return [\n    backend.makeTensorInfo(\n        [selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n    backend.makeTensorInfo(\n        [selectedScores.length], 'float32', new Float32Array(selectedScores))\n  ];\n}\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'cpu',\n  kernelFunc: nonMaxSuppressionV5 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OneHot, OneHotAttrs, OneHotInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function oneHot(\n    args: {inputs: OneHotInputs, backend: MathBackendCPU, attrs: OneHotAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {indices} = inputs;\n  const {dtype, depth, onValue, offValue} = attrs;\n\n  assertNotComplex(indices, 'oneHot');\n\n  const indicesSize = util.sizeFromShape(indices.shape);\n\n  const res = new Float32Array(indicesSize * depth);\n  res.fill(offValue);\n  const indicesVal = backend.data.get(indices.dataId).values as TypedArray;\n\n  for (let event = 0; event < indicesSize; ++event) {\n    if (indicesVal[event] >= 0 && indicesVal[event] < depth) {\n      res[event * depth + indicesVal[event]] = onValue;\n    }\n  }\n\n  return backend.makeTensorInfo([...indices.shape, depth], dtype, res);\n}\n\nexport const oneHotConfig: KernelConfig = {\n  kernelName: OneHot,\n  backendName: 'cpu',\n  kernelFunc: oneHot as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, ZerosLike, ZerosLikeInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\n\nexport function zerosLike(\n    args: {inputs: ZerosLikeInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (x.dtype === 'string') {\n    throw new Error('zerosLike is not supported for string tensors');\n  } else if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = zerosLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n    backend.disposeIntermediateTensorInfo(r);\n    backend.disposeIntermediateTensorInfo(imagPart);\n    backend.disposeIntermediateTensorInfo(i);\n\n    return result;\n  } else {\n    return fill({backend, attrs: {shape: x.shape, value: 0, dtype: x.dtype}});\n  }\n}\n\nexport const zerosLikeConfig: KernelConfig = {\n  kernelName: ZerosLike,\n  backendName: 'cpu',\n  kernelFunc: zerosLike as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, OnesLike, OnesLikeInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {complex} from './Complex';\nimport {fill} from './Fill';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {zerosLike} from './ZerosLike';\n\nexport function onesLike(\n    args: {inputs: OnesLikeInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  if (x.dtype === 'string') {\n    throw new Error('onesLike is not supported for string tensors');\n  } else if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const r = onesLike({inputs: {x: realPart}, backend});\n    const imagPart = imag({inputs: {input: x}, backend});\n    const i = zerosLike({inputs: {x: imagPart}, backend});\n\n    const result = complex({inputs: {real: r, imag: i}, backend});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n    backend.disposeIntermediateTensorInfo(r);\n    backend.disposeIntermediateTensorInfo(imagPart);\n    backend.disposeIntermediateTensorInfo(i);\n\n    return result;\n  } else {\n    return fill({backend, attrs: {shape: x.shape, value: 1, dtype: x.dtype}});\n  }\n}\n\nexport const onesLikeConfig: KernelConfig = {\n  kernelName: OnesLike,\n  backendName: 'cpu',\n  kernelFunc: onesLike as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Pack, PackAttrs, PackInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {concat} from './Concat';\nimport {expandDims} from './ExpandDims';\n\nexport function pack(\n    args: {inputs: PackInputs, backend: MathBackendCPU, attrs: PackAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  if (inputs.length === 1) {\n    return expandDims(\n        {inputs: {input: inputs[0]}, backend, attrs: {dim: axis}});\n  }\n\n  const shape = inputs[0].shape;\n  const dtype = inputs[0].dtype;\n\n  inputs.forEach(t => {\n    util.assertShapesMatch(\n        shape, t.shape,\n        'All tensors passed to stack must have matching shapes');\n    util.assert(\n        dtype === t.dtype,\n        () => 'All tensors passed to stack must have matching dtypes');\n  });\n\n  const intermediateTensorInfos: TensorInfo[] = [];\n  const expandedTensors = inputs.map(t => {\n    const expandedT =\n        expandDims({inputs: {input: t}, backend, attrs: {dim: axis}});\n    intermediateTensorInfos.push(expandedT);\n    return expandedT;\n  });\n\n  const result = concat({inputs: expandedTensors, backend, attrs: {axis}});\n\n  intermediateTensorInfos.forEach(\n      t => backend.disposeIntermediateTensorInfo(t));\n\n  return result;\n}\n\nexport const packConfig: KernelConfig = {\n  kernelName: Pack,\n  backendName: 'cpu',\n  kernelFunc: pack as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, PadV2, PadV2Attrs, PadV2Inputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function padV2(\n    args: {inputs: PadV2Inputs, backend: MathBackendCPU, attrs: PadV2Attrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {paddings, constantValue} = attrs;\n\n  assertNotComplex(x, 'pad');\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  const start = paddings.map(p => p[0]);\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xSize = util.sizeFromShape(x.shape);\n  const xRank = x.shape.length;\n  const xStrides = util.computeStrides(x.shape);\n\n  const resultSize = util.sizeFromShape(outShape);\n  const resultRank = outShape.length;\n  const resultStrides = util.computeStrides(outShape);\n  const resVals =\n      util.getTypedArrayFromDType(x.dtype as NumericDataType, resultSize);\n\n  if (constantValue !== 0) {\n    resVals.fill(constantValue);\n  }\n\n  for (let i = 0; i < xSize; i++) {\n    const coords = util.indexToLoc(i, xRank, xStrides);\n    const outCoords = coords.map((c, i) => c + start[i]);\n    const outIndex = util.locToIndex(outCoords, resultRank, resultStrides);\n\n    resVals[outIndex] = xVals[i];\n  }\n\n  const outId = backend.write(resVals, outShape, x.dtype);\n\n  return {dataId: outId, shape: outShape, dtype: x.dtype};\n}\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'cpu',\n  kernelFunc: padV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Pow} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/binary_utils';\n\nexport const powImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => Math.pow(a, b));\nexport const pow = binaryKernelFunc(Pow, powImpl);\n\nexport const powConfig: KernelConfig = {\n  kernelName: Pow,\n  backendName: 'cpu',\n  kernelFunc: pow\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, RaggedTensorToTensor, RaggedTensorToTensorAttrs, RaggedTensorToTensorInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {raggedTensorToTensorImpl} from './RaggedTensorToTensor_impl';\n\nexport function raggedTensorToTensor(args: {\n  inputs: RaggedTensorToTensorInputs,\n  backend: MathBackendCPU,\n  attrs: RaggedTensorToTensorAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {shape, values, defaultValue, rowPartitionTensors} = inputs;\n  const {rowPartitionTypes} = attrs;\n\n  const $shape = backend.data.get(shape.dataId).values as TypedArray;\n  const $values = backend.data.get(values.dataId).values as TypedArray;\n  const $defaultValue =\n      backend.data.get(defaultValue.dataId).values as TypedArray;\n  const $rowPartitionValues = rowPartitionTensors.map(\n      t => backend.data.get(t.dataId).values as TypedArray);\n  const rowPartitionValuesShapes = rowPartitionTensors.map(t => t.shape);\n\n  const [outputShape, output] = raggedTensorToTensorImpl(\n      $shape, shape.shape, $values, values.shape, values.dtype, $defaultValue,\n      defaultValue.shape, $rowPartitionValues, rowPartitionValuesShapes,\n      rowPartitionTypes);\n  return backend.makeTensorInfo(outputShape, values.dtype, output);\n}\n\nexport const raggedTensorToTensorConfig: KernelConfig = {\n  kernelName: RaggedTensorToTensor,\n  backendName: 'cpu',\n  kernelFunc: raggedTensorToTensor as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Range, RangeAttrs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {rangeImpl} from './Range_impl';\n\nexport function range(args: {backend: MathBackendCPU, attrs: RangeAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {start, stop, dtype, step} = attrs;\n\n  const values = rangeImpl(start, stop, step, dtype);\n  return backend.makeTensorInfo([values.length], dtype, values);\n}\n\nexport const rangeConfig: KernelConfig = {\n  kernelName: Range,\n  backendName: 'cpu',\n  kernelFunc: range as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Reciprocal} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const reciprocal = unaryKernelFunc(Reciprocal, (xi) => 1 / xi);\n\nexport const reciprocalConfig: KernelConfig = {\n  kernelName: Reciprocal,\n  backendName: 'cpu',\n  kernelFunc: reciprocal,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinear, ResizeBilinearAttrs, ResizeBilinearInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeBilinear(args: {\n  inputs: ResizeBilinearInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeBilinearAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, halfPixelCenters, size} = attrs;\n\n  assertNotComplex(images, 'resizeBilinear');\n\n  const imagesStrides = util.computeStrides(images.shape);\n  const [newHeight, newWidth] = size;\n\n  const [batch, oldHeight, oldWidth, numChannels] = images.shape;\n  const xValues = backend.data.get(images.dataId).values as TypedArray;\n  const result = new Float32Array(\n      util.sizeFromShape([batch, newHeight, newWidth, numChannels]));\n\n  const effectiveInputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n    (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n  ];\n\n  const effectiveOutputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n    (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n  ];\n  let outputIdx = 0;\n  const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n  const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n  for (let b = 0; b < batch; b++) {\n    for (let r = 0; r < newHeight; r++) {\n      let sourceFracRow: number;\n      if (halfPixelCenters) {\n        sourceFracRow = effectiveRowSizeRatio * (r + 0.5) - 0.5;\n      } else {\n        sourceFracRow = effectiveRowSizeRatio * r;\n      }\n\n      const sourceRowFloor = Math.max(0, Math.floor(sourceFracRow));\n      const rowFrac = sourceFracRow - sourceRowFloor;\n      const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n      const topRowOffset =\n          b * imagesStrides[0] + sourceRowFloor * imagesStrides[1];\n      const botRowOffset =\n          b * imagesStrides[0] + sourceRowCeil * imagesStrides[1];\n      for (let c = 0; c < newWidth; c++) {\n        let sourceFracCol: number;\n        if (halfPixelCenters) {\n          sourceFracCol = effectiveColSizeRatio * (c + 0.5) - 0.5;\n        } else {\n          sourceFracCol = effectiveColSizeRatio * c;\n        }\n        const sourceColFloor = Math.max(0, Math.floor(sourceFracCol));\n        const colFrac = sourceFracCol - sourceColFloor;\n        const sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n        const topLeftOffest = topRowOffset + sourceColFloor * imagesStrides[2];\n        const botLeftOffset = botRowOffset + sourceColFloor * imagesStrides[2];\n        const topRightOffset = topRowOffset + sourceColCeil * imagesStrides[2];\n        const botRightOffest = botRowOffset + sourceColCeil * imagesStrides[2];\n        for (let d = 0; d < numChannels; d++) {\n          // Begin shader.\n\n          // Compute the fractional index of the source.\n          const topLeft = xValues[topLeftOffest + d];\n          const bottomLeft = xValues[botLeftOffset + d];\n          const topRight = xValues[topRightOffset + d];\n          const bottomRight = xValues[botRightOffest + d];\n\n          const top = topLeft + (topRight - topLeft) * colFrac;\n          const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n          const newValue = top + (bottom - top) * rowFrac;\n\n          result[outputIdx++] = newValue;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batch, newHeight, newWidth, numChannels], 'float32', result);\n}\n\nexport const resizeBilinearConfig: KernelConfig = {\n  kernelName: ResizeBilinear,\n  backendName: 'cpu',\n  kernelFunc: resizeBilinear as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeBilinearGrad, ResizeBilinearGradAttrs, ResizeBilinearGradInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeBilinearGrad(args: {\n  inputs: ResizeBilinearGradInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeBilinearGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  assertNotComplex([dy, images], 'resizeBilinearGrad');\n\n  const imagesStrides = util.computeStrides(images.shape);\n\n  const [batch, xHeight, xWidth, depth] = images.shape;\n  const [, yHeight, yWidth] = dy.shape;\n\n  const output = new Float32Array(batch * xHeight * xWidth * depth);\n\n  // In the backwards pass, we want to find the pixels that were generated\n  // for each pixel in the input image the forward pass and add the\n  // corresponding coefficient from dy to the gradient (with some\n  // interpolation).\n\n  const effectiveXSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n    (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n  ];\n\n  const effectiveYSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n    (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n  ];\n\n  const heightScale = effectiveXSize[0] / effectiveYSize[0];\n  const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n  // Reference implementation\n  // tslint:disable-next-line:max-line-length\n  // https://github.com/tensorflow/tensorflow/blob/3039375c86a5bbc9610c7725dcaa95d635f87ba2/tensorflow/core/kernels/resize_bilinear_op.cc#L275\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  let offset = 0;\n  for (let b = 0; b < batch; b++) {\n    const bOffset = b * imagesStrides[0];\n    for (let r = 0; r < yHeight; r++) {\n      const dxR = r * heightScale;\n      const topDxRIndex = Math.floor(dxR);\n      const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);\n\n      const topDxROffset = bOffset + topDxRIndex * imagesStrides[1];\n      const bottomDxROffset = bOffset + bottomDxRIndex * imagesStrides[1];\n\n      const dxRLerp = dxR - topDxRIndex;\n      const inverseDxRLerp = 1.0 - dxRLerp;\n      for (let c = 0; c < yWidth; c++) {\n        const dxC = c * widthScale;\n        const leftDxCIndex = Math.floor(dxC);\n        const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);\n        const dxCLerp = dxC - leftDxCIndex;\n        const inverseDxCLerp = 1.0 - dxCLerp;\n\n        const topLeftRCOffset = topDxROffset + leftDxCIndex * imagesStrides[2];\n        const topRightRCOffset =\n            topDxROffset + rightDxCIndex * imagesStrides[2];\n        const bottomLeftRCOffset =\n            bottomDxROffset + leftDxCIndex * imagesStrides[2];\n        const bottomRightRCOffset =\n            bottomDxROffset + rightDxCIndex * imagesStrides[2];\n\n        const inverseDxRLerpTimesInverseDxCLerp =\n            inverseDxRLerp * inverseDxCLerp;\n        const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;\n        const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;\n        const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;\n        for (let d = 0; d < depth; d++) {\n          const dyVal = dyValues[offset++];\n          output[topLeftRCOffset + d] +=\n              dyVal * inverseDxRLerpTimesInverseDxCLerp;\n          output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;\n          output[bottomLeftRCOffset + d] += dyVal * dxRLerpTimesInverseDxCLerp;\n          output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batch, xWidth, xHeight, depth], 'float32', output);\n}\n\nexport const resizeBilinearGradConfig: KernelConfig = {\n  kernelName: ResizeBilinearGrad,\n  backendName: 'cpu',\n  kernelFunc: resizeBilinearGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighbor, ResizeNearestNeighborAttrs, ResizeNearestNeighborInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeNearestNeighbor(args: {\n  inputs: ResizeNearestNeighborInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeNearestNeighborAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images} = inputs;\n  const {alignCorners, halfPixelCenters, size} = attrs;\n\n  assertNotComplex(images, 'resizeNearestNeighbor');\n\n  const imagesStrides = util.computeStrides(images.shape);\n  const [newHeight, newWidth] = size;\n\n  const [batch, oldHeight, oldWidth, numChannels] = images.shape;\n  const xValues = backend.data.get(images.dataId).values as TypedArray;\n  const output = new Float32Array(batch * newHeight * newWidth * numChannels);\n\n  const effectiveInputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n    (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n  ];\n\n  const effectiveOutputSize: [number, number] = [\n    (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n    (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n  ];\n\n  const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n  const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n\n  let outputOffset = 0;\n  for (let b = 0; b < batch; b++) {\n    const batchOffset = b * imagesStrides[0];\n    for (let r = 0; r < newHeight; r++) {\n      const sourceFracRow = halfPixelCenters ?\n          effectiveRowSizeRatio * (r + 0.5) :\n          effectiveRowSizeRatio * r;\n      let sourceNearestRow = Math.min(\n          oldHeight - 1,\n          alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));\n      if (halfPixelCenters) {\n        sourceNearestRow = Math.max(0, sourceNearestRow);\n      }\n      const rowOffset = batchOffset + sourceNearestRow * imagesStrides[1];\n      for (let c = 0; c < newWidth; c++) {\n        const sourceFracCol = halfPixelCenters ?\n            effectiveColSizeRatio * (c + 0.5) :\n            effectiveColSizeRatio * c;\n        let sourceNearestCol = Math.min(\n            oldWidth - 1,\n            alignCorners ? Math.round(sourceFracCol) :\n                           Math.floor(sourceFracCol));\n        if (halfPixelCenters) {\n          sourceNearestCol = Math.max(0, sourceNearestCol);\n        }\n        const colOffset = rowOffset + sourceNearestCol * imagesStrides[2];\n        for (let d = 0; d < numChannels; d++) {\n          // Begin shader.\n          // Compute the fractional index of the source.\n          const newVal = xValues[colOffset + d];\n          output[outputOffset++] = newVal;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(\n      [batch, newHeight, newWidth, numChannels], images.dtype, output);\n}\n\nexport const resizeNearestNeighborConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighbor,\n  backendName: 'cpu',\n  kernelFunc: resizeNearestNeighbor as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, ResizeNearestNeighborGrad, ResizeNearestNeighborGradAttrs, ResizeNearestNeighborGradInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function resizeNearestNeighborGrad(args: {\n  inputs: ResizeNearestNeighborGradInputs,\n  backend: MathBackendCPU,\n  attrs: ResizeNearestNeighborGradAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {images, dy} = inputs;\n  const {alignCorners} = attrs;\n\n  assertNotComplex([dy, images], 'resizeNearestNeighborGrad');\n\n  const imagesStrides = util.computeStrides(images.shape);\n  const dyStrides = util.computeStrides(dy.shape);\n  const [batch, xHeight, xWidth, depth] = images.shape;\n  const [, yHeight, yWidth] = dy.shape;\n\n  const output = new Float32Array(batch * xHeight * xWidth * depth);\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n\n  // In the backwards pass, we want to find the pixels that were generated\n  // for each pixel in the input image the forward pass\n\n  const effectiveXSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n    (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n  ];\n\n  const effectiveYSize: [number, number] = [\n    (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n    (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n  ];\n\n  const heightScale = effectiveXSize[0] / effectiveYSize[0];\n  const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n  const invHeightScale = 1 / heightScale;\n  const invWidthScale = 1 / widthScale;\n\n  // This defines the size of the window of values around a particular\n  // index in dy that we want to search for contributions to dx.\n  const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n  const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n  // Loop over the output space.\n  for (let b = 0; b < batch; b++) {\n    const batchOffset = b * imagesStrides[0];\n    for (let r = 0; r < xHeight; r++) {\n      const rowOffset = batchOffset + r * imagesStrides[1];\n\n      // Compute bounds for where in dy we will look\n      const startRLerp = Math.floor(r * invHeightScale);\n      const startDyR = Math.floor(startRLerp - (winHeight / 2));\n      for (let c = 0; c < xWidth; c++) {\n        const colOffset = rowOffset + c * imagesStrides[2];\n\n        // Compute bounds for where in dy we will look\n        const startCLerp = Math.floor(c * invWidthScale);\n        const startDyC = Math.floor(startCLerp - (winWidth / 2));\n\n        for (let d = 0; d < depth; d++) {\n          let accum = 0;\n          // loop over dy\n\n          for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {\n            const dyR = dyRIndex + startDyR;\n            // Guard against the window exceeding the bounds of dy\n            if (dyR < 0 || dyR >= yHeight) {\n              continue;\n            }\n\n            const dyROffset = batchOffset + dyR * dyStrides[1];\n            const sourceFracRow = dyR * heightScale;\n            const sourceNearestRow = Math.min(\n                xHeight - 1,\n                alignCorners ? Math.round(sourceFracRow) :\n                               Math.floor(sourceFracRow));\n            if (r !== sourceNearestRow) {\n              continue;\n            }\n            for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {\n              const dyC = dyCIndex + startDyC;\n              // Guard against the window exceeding the bounds of dy\n              if (dyC < 0 || dyC >= yWidth) {\n                continue;\n              }\n\n              const dyCOffset = dyROffset + dyC * dyStrides[2];\n              const sourceFracCol = dyC * widthScale;\n              const sourceNearestCol = Math.min(\n                  xWidth - 1,\n                  alignCorners ? Math.round(sourceFracCol) :\n                                 Math.floor(sourceFracCol));\n\n              if (c === sourceNearestCol) {\n                accum += dyValues[dyCOffset + d];\n              }\n            }\n          }\n          output[colOffset + d] = accum;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(images.shape, images.dtype, output);\n}\n\nexport const resizeNearestNeighborGradConfig: KernelConfig = {\n  kernelName: ResizeNearestNeighborGrad,\n  backendName: 'cpu',\n  kernelFunc: resizeNearestNeighborGrad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reverse, ReverseAttrs, ReverseInputs, TensorBuffer, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {identity} from './Identity';\n\nexport function reverse(\n    args:\n        {inputs: ReverseInputs, backend: MathBackendCPU, attrs: ReverseAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dims} = attrs;\n\n  assertNotComplex(x, 'reverse');\n\n  const xRank = x.shape.length;\n\n  const $dims = util.parseAxisParam(dims, x.shape);\n  if (xRank === 0) {\n    return identity({inputs: {x}, backend});\n  }\n\n  const outBuf = new TensorBuffer(x.shape, x.dtype);\n  const xBuf = backend.bufferSync(x);\n\n  for (let i = 0; i < outBuf.size; i++) {\n    const outLoc = outBuf.indexToLoc(i);\n    const inLoc = outLoc.slice();\n    $dims.forEach(d => inLoc[d] = x.shape[d] - 1 - inLoc[d]);\n    outBuf.set(xBuf.get(...inLoc), ...outLoc);\n  }\n\n  return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\n\nexport const reverseConfig: KernelConfig = {\n  kernelName: Reverse,\n  backendName: 'cpu',\n  kernelFunc: reverse as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {backend_util, RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const rotateWithOffsetConfig: KernelConfig = {\n  kernelName: RotateWithOffset,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as RotateWithOffsetInputs;\n    const {radians, fillValue, center} = attrs as {} as RotateWithOffsetAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const [centerX, centerY] =\n        backend_util.getImageCenter(center, imageHeight, imageWidth);\n    const fullOpacityValue = 255;\n\n    const sinFactor = Math.sin(radians);\n    const cosFactor = Math.cos(radians);\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n            const y = coords[1];\n\n            // coordX/coordY are the result of rotating and translating x/y.\n            let coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;\n            let coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;\n            coordX = Math.round(coordX + centerX);\n            coordY = Math.round(coordY + centerY);\n\n            let outputValue = fillValue;\n            if (typeof fillValue !== 'number') {\n              if (channel === 3) {\n                outputValue = fullOpacityValue;\n              } else {\n                outputValue = fillValue[channel];\n              }\n            }\n\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth && coordY >= 0 &&\n                coordY < imageHeight) {\n              // set the output to the image value at the coordinate position.\n              const rotatedRowOffset = coordY * (imageWidth * numChannels);\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rotatedRowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n            output[outIdx] = outputValue as number;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Round} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const round = unaryKernelFunc(Round, (xi) => {\n  // The algorithm is based on banker's rounding.\n  const base = Math.floor(xi);\n  if (xi - base < 0.5) {\n    return Math.floor(xi);\n  } else if (xi - base > 0.5) {\n    return Math.ceil(xi);\n  } else {\n    if (base % 2.0 === 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n});\n\nexport const roundConfig: KernelConfig = {\n  kernelName: Round,\n  backendName: 'cpu',\n  kernelFunc: round,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Rank, ScatterNd, ScatterNdAttrs, ScatterNdInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {scatterImpl} from './Scatter_impl';\n\nexport function scatterNd(args: {\n  inputs: ScatterNdInputs,\n  backend: MathBackendCPU,\n  attrs: ScatterNdAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {indices, updates} = inputs;\n  const {shape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(updates, indices, shape);\n  const sumDupeIndices = true;\n\n  const indicesBuf = backend.bufferSync<Rank, 'int32'>(indices);\n  const updatesBuf = backend.bufferSync<Rank, 'int32'|'float32'>(updates);\n\n  const outBuf = scatterImpl(\n      indicesBuf, updatesBuf, shape, outputSize, sliceSize, numUpdates,\n      sliceRank, strides, 0 /* defaultValue */, sumDupeIndices);\n\n  return backend.makeTensorInfo(shape, outBuf.dtype, outBuf.values);\n}\n\nexport const scatterNdConfig: KernelConfig = {\n  kernelName: ScatterNd,\n  backendName: 'cpu',\n  kernelFunc: scatterNd as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nfunction lowerBound(array: TypedArray, value: number) {\n  let left = 0;\n  let right = array.length;\n  let mid = 0;\n  while (left < right) {\n    mid = Math.floor((left + right) / 2);\n    if (array[mid] < value) {\n      left = mid + 1;\n    } else {\n      right = mid;\n    }\n  }\n  return right;\n}\n\nfunction upperBound(array: TypedArray, value: number) {\n  let left = 0;\n  let right = array.length;\n  let mid = 0;\n  while (left < right) {\n    mid = Math.floor((left + right) / 2);\n    if (array[mid] <= value) {\n      left = mid + 1;\n    } else {\n      right = mid;\n    }\n  }\n  return right;\n}\n\nexport function searchSortedImpl(\n    sortedInputs: TypedArray, values: TypedArray, batchSize: number,\n    numInputs: number, numValues: number, side: 'left'|'right'): TypedArray {\n  const output =\n      util.getArrayFromDType('int32', batchSize * numValues) as TypedArray;\n  for (let b = 0; b < batchSize; ++b) {\n    const sortedInputsSlice =\n        sortedInputs.slice(b * numInputs, (b + 1) * numInputs);\n    const outputOffset = b * numValues;\n    for (let i = 0; i < numValues; ++i) {\n      output[outputOffset + i] = side === 'left' ?\n          lowerBound(sortedInputsSlice, values[i + outputOffset]) :\n          upperBound(sortedInputsSlice, values[i + outputOffset]);\n    }\n  }\n  return output;\n}\n","/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SearchSorted, SearchSortedAttrs, SearchSortedInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {searchSortedImpl} from './SearchSorted_impl';\n\nexport function searchSorted(args: {\n  inputs: SearchSortedInputs,\n  backend: MathBackendCPU,\n  attrs: SearchSortedAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {sortedSequence, values} = inputs;\n  const {side} = attrs;\n\n  const $sortedSequence =\n      backend.data.get(sortedSequence.dataId).values as TypedArray;\n  const $values = backend.data.get(values.dataId).values as TypedArray;\n\n  const output = searchSortedImpl(\n      $sortedSequence, $values, sortedSequence.shape[0],\n      sortedSequence.shape[1], values.shape[1], side);\n  return backend.makeTensorInfo(values.shape, 'int32', output);\n}\n\nexport const searchSortedConfig: KernelConfig = {\n  kernelName: SearchSorted,\n  backendName: 'cpu',\n  kernelFunc: searchSorted as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Select, SelectInputs, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function select(args: {inputs: SelectInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {condition, t, e} = inputs;\n\n  assertNotComplex([condition, t, e], 'select');\n  const conditionRank = condition.shape.length;\n\n  const values = backend.data.get(condition.dataId).values as TypedArray;\n  const tValues = backend.data.get(t.dataId).values as TypedArray;\n  const eValues = backend.data.get(e.dataId).values as TypedArray;\n  const resultDtype = upcastType(t.dtype, e.dtype);\n  const newValues =\n      util.makeZerosTypedArray(util.sizeFromShape(t.shape), resultDtype);\n\n  let index = 0;\n  const offset =\n      conditionRank === 0 || conditionRank > 1 || t.shape.length === 1 ?\n      1 :\n      util.sizeFromShape(t.shape.slice(1));\n\n  for (let i = 0; i < values.length; i++) {\n    for (let j = 0; j < offset; j++) {\n      if (values[i] === 1) {\n        newValues[index++] = tValues[i];\n      } else {\n        newValues[index++] = eValues[i];\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(t.shape, resultDtype, newValues);\n}\n\nexport const selectConfig: KernelConfig = {\n  kernelName: Select,\n  backendName: 'cpu',\n  kernelFunc: select as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, Selu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst scaleAlpha = backend_util.SELU_SCALEALPHA;\nconst scale = backend_util.SELU_SCALE;\n\nexport const selu = unaryKernelFunc(Selu, (xi) => {\n  if (xi >= 0) {\n    return scale * xi;\n  } else {\n    return scaleAlpha * (Math.exp(xi) - 1);\n  }\n});\n\nexport const seluConfig: KernelConfig = {\n  kernelName: Selu,\n  backendName: 'cpu',\n  kernelFunc: selu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sign} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sign = unaryKernelFunc(Sign, (xi) => {\n  if (xi < 0) {\n    return -1;\n  } else if (xi > 0) {\n    return 1;\n  } else {\n    return 0;\n  }\n});\n\nexport const signConfig: KernelConfig = {\n  kernelName: Sign,\n  backendName: 'cpu',\n  kernelFunc: sign,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sin} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sin = unaryKernelFunc(Sin, (xi) => Math.sin(xi));\n\nexport const sinConfig: KernelConfig = {\n  kernelName: Sin,\n  backendName: 'cpu',\n  kernelFunc: sin,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sinh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sinh = unaryKernelFunc(Sinh, (xi) => Math.sinh(xi));\n\nexport const sinhConfig: KernelConfig = {\n  kernelName: Sinh,\n  backendName: 'cpu',\n  kernelFunc: sinh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Softplus} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\n// mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n\n// epsilon is the difference between 1.0 and the next representable float.\n// For a single precision 32 bit float this should be 2^-23, see:\n// https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\nconst epsilon = 1.1920928955078125e-7;\nconst threshold = Math.log(epsilon) + 2.0;\n\nexport const softplus = unaryKernelFunc(Softplus, (xi) => {\n  // Value above which exp(x) may overflow, but softplus(x) == x\n  // is within machine epsilon.\n  const tooLarge = xi > -threshold;\n\n  // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n  // is within machine epsilon.\n  const tooSmall = xi < threshold;\n\n  const expX = Math.exp(xi);\n  let result;\n\n  if (tooSmall) {\n    result = expX;\n  } else if (tooLarge) {\n    result = xi;\n  } else {\n    result = Math.log(1.0 + expX);\n  }\n  return result;\n});\n\nexport const softplusConfig: KernelConfig = {\n  kernelName: Softplus,\n  backendName: 'cpu',\n  kernelFunc: softplus,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ReshapeAttrs, ReshapeInputs, SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs, TensorInfo, TransposeAttrs, TransposeInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {padV2Config} from './PadV2';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function spaceToBatchND(args: {\n  inputs: SpaceToBatchNDInputs,\n  backend: MathBackendCPU,\n  attrs: SpaceToBatchNDAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, paddings} = attrs;\n\n  assertNotComplex([x], 'spaceToBatchND');\n\n  const prod = util.sizeFromShape(blockShape);\n\n  const completePaddings: Array<[number, number]> = [[0, 0]];\n  completePaddings.push(...(paddings as Array<[number, number]>));\n\n  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n    completePaddings.push([0, 0]);\n  }\n\n  const paddedX = padV2Config.kernelFunc({\n    inputs: {x},\n    backend,\n    attrs: {paddings: completePaddings, constantValue: 0}\n  }) as TensorInfo;\n\n  const reshapedPaddedShape =\n      backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n\n  const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n      reshapedPaddedShape.length, blockShape.length, false);\n\n  const flattenShape =\n      backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n\n  const reshapeInputs: ReshapeInputs = {x: paddedX};\n  const reshapeAttrs: ReshapeAttrs = {shape: reshapedPaddedShape};\n  const paddedXReshaped =\n      reshape({inputs: reshapeInputs, backend, attrs: reshapeAttrs});\n\n  const transposeInputs: TransposeInputs = {x: paddedXReshaped};\n  const transposeAttrs:\n      TransposeAttrs = {perm: permutedReshapedPaddedPermutation};\n  const paddedXT =\n      transpose({inputs: transposeInputs, backend, attrs: transposeAttrs});\n\n  const resultReshapeInputs: ReshapeInputs = {x: paddedXT};\n  const resultReshapeAttrs: ReshapeAttrs = {shape: flattenShape};\n  const result = reshape(\n      {inputs: resultReshapeInputs, backend, attrs: resultReshapeAttrs});\n\n  backend.disposeIntermediateTensorInfo(paddedX);\n  backend.disposeIntermediateTensorInfo(paddedXReshaped);\n  backend.disposeIntermediateTensorInfo(paddedXT);\n\n  return result;\n}\n\nexport const spaceToBatchNDConfig: KernelConfig = {\n  kernelName: SpaceToBatchND,\n  backendName: 'cpu',\n  kernelFunc: spaceToBatchND as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, SparseFillEmptyRows, SparseFillEmptyRowsInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {sparseFillEmptyRowsImpl} from './SparseFillEmptyRows_impl';\n\nexport function sparseFillEmptyRows(args: {\n  inputs: SparseFillEmptyRowsInputs,\n  backend: MathBackendCPU\n}): [TensorInfo, TensorInfo, TensorInfo, TensorInfo] {\n  const {inputs, backend} = args;\n  const {indices, values, denseShape, defaultValue} = inputs;\n  if (denseShape.shape.length !== 1) {\n    throw new Error(`Dense shape must be a vector, saw:\n        ${denseShape.shape}`);\n  }\n  if (indices.shape.length !== 2) {\n    throw new Error(`Indices must be a matrix, saw:\n        ${indices.shape}`);\n  }\n  if (values.shape.length !== 1) {\n    throw new Error(`Values must be a vector, saw:\n        ${values.shape}`);\n  }\n  if (defaultValue.shape.length !== 0) {\n    throw new Error(`Default value must be a scalar, saw:\n        ${defaultValue.shape}`);\n  }\n\n  const $indices = backend.data.get(indices.dataId).values as TypedArray;\n  const $values = backend.data.get(values.dataId).values as TypedArray;\n  const $denseShape = backend.data.get(denseShape.dataId).values as TypedArray;\n  const $defaultValue =\n      backend.data.get(defaultValue.dataId).values[0] as number;\n\n  const [outputIndices, outputIndicesShape, outputValues,\n         emptyRowIndicator, reverseIndexMap] =\n      sparseFillEmptyRowsImpl(\n          $indices, indices.shape, indices.dtype, $values, values.dtype,\n          $denseShape, $defaultValue);\n  return [\n    backend.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),\n    backend.makeTensorInfo(\n        [outputIndicesShape[0]], values.dtype, outputValues),\n    backend.makeTensorInfo(\n        [emptyRowIndicator.length], 'bool',\n        new Uint8Array(\n            emptyRowIndicator.map((value: boolean) => Number(value)))),\n    backend.makeTensorInfo(\n        [reverseIndexMap.length], indices.dtype,\n        new Int32Array(reverseIndexMap)),\n  ];\n}\n\nexport const sparseFillEmptyRowsConfig: KernelConfig = {\n  kernelName: SparseFillEmptyRows,\n  backendName: 'cpu',\n  kernelFunc: sparseFillEmptyRows as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SparseReshape, SparseReshapeInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {sparseReshapeImpl} from './SparseReshape_impl';\n\nexport function sparseReshape(\n    args: {inputs: SparseReshapeInputs, backend: MathBackendCPU}):\n    [TensorInfo, TensorInfo] {\n  const {inputs, backend} = args;\n  const {inputIndices, inputShape, newShape} = inputs;\n  if (inputIndices.shape.length !== 2) {\n    throw new Error(`Input indices should be a matrix but received shape\n        ${inputIndices.shape}`);\n  }\n  if (inputShape.shape.length !== 1) {\n    throw new Error(`Input shape should be a vector but received shape\n        ${inputShape.shape}`);\n  }\n\n  if (newShape.shape.length !== 1) {\n    throw new Error(\n        `Target shape should be a vector but received shape ${newShape.shape}`);\n  }\n\n  const $inputShape =\n      Array.from(backend.data.get(inputShape.dataId).values as TypedArray);\n  const $inputIndices =\n      backend.data.get(inputIndices.dataId).values as TypedArray;\n  const targetShape =\n      Array.from(backend.data.get(newShape.dataId).values as TypedArray);\n\n  const [newIndices, indicesShape, outputShape] = sparseReshapeImpl(\n      $inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape,\n      targetShape);\n  return [\n    backend.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),\n    backend.makeTensorInfo(\n        [outputShape.length], newShape.dtype, new Int32Array(outputShape)),\n  ];\n}\n\nexport const sparseReshapeConfig: KernelConfig = {\n  kernelName: SparseReshape,\n  backendName: 'cpu',\n  kernelFunc: sparseReshape,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SparseSegmentMean, SparseSegmentMeanInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {sparseSegmentReductionImpl} from './SparseSegmentReduction_impl';\n\nexport function sparseSegmentMean(\n    args: {inputs: SparseSegmentMeanInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {data, indices, segmentIds} = inputs;\n  if (data.shape.length < 1) {\n    throw new Error(\n        `Data should be at least 1 dimensional but received scalar`);\n  }\n  if (indices.shape.length !== 1) {\n    throw new Error(`Indices should be a vector but received shape\n          ${indices.shape}`);\n  }\n  if (segmentIds.shape.length !== 1) {\n    throw new Error(`Segment ids should be a vector but received shape\n          ${segmentIds.shape}`);\n  }\n  if (indices.shape[0] !== segmentIds.shape[0]) {\n    throw new Error(`segmentIds and indices should have same size.`);\n  }\n\n  const $data = backend.data.get(data.dataId).values as TypedArray;\n  const $indices = backend.data.get(indices.dataId).values as TypedArray;\n  const $segmentIds = backend.data.get(segmentIds.dataId).values as TypedArray;\n\n  const [outputData, outputDataShape] = sparseSegmentReductionImpl(\n      $data, data.shape, data.dtype, $indices, $segmentIds, true);\n  return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);\n}\n\nexport const sparseSegmentMeanConfig: KernelConfig = {\n  kernelName: SparseSegmentMean,\n  backendName: 'cpu',\n  kernelFunc: sparseSegmentMean,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SparseSegmentSum, SparseSegmentSumInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {sparseSegmentReductionImpl} from './SparseSegmentReduction_impl';\n\nexport function sparseSegmentSum(\n    args: {inputs: SparseSegmentSumInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {data, indices, segmentIds} = inputs;\n  if (data.shape.length < 1) {\n    throw new Error(\n        `Data should be at least 1 dimensional but received scalar`);\n  }\n  if (indices.shape.length !== 1) {\n    throw new Error(`Indices should be a vector but received shape\n         ${indices.shape}`);\n  }\n  if (segmentIds.shape.length !== 1) {\n    throw new Error(`Segment ids should be a vector but received shape\n         ${segmentIds.shape}`);\n  }\n  if (indices.shape[0] !== segmentIds.shape[0]) {\n    throw new Error(`segmentIds and indices should have same size.`);\n  }\n\n  const $data = backend.data.get(data.dataId).values as TypedArray;\n  const $indices = backend.data.get(indices.dataId).values as TypedArray;\n  const $segmentIds = backend.data.get(segmentIds.dataId).values as TypedArray;\n\n  const [outputData, outputDataShape] = sparseSegmentReductionImpl(\n      $data, data.shape, data.dtype, $indices, $segmentIds);\n  return backend.makeTensorInfo(outputDataShape, data.dtype, outputData);\n}\n\nexport const sparseSegmentSumConfig: KernelConfig = {\n  kernelName: SparseSegmentSum,\n  backendName: 'cpu',\n  kernelFunc: sparseSegmentSum,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Rank, SparseToDense, SparseToDenseAttrs, SparseToDenseInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {scatterImpl} from './Scatter_impl';\n\nexport function sparseToDense(args: {\n  inputs: SparseToDenseInputs,\n  backend: MathBackendCPU,\n  attrs: SparseToDenseAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {sparseIndices, sparseValues, defaultValue} = inputs;\n  const {outputShape} = attrs;\n\n  const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n      backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n  const sumDupeIndices = false;\n\n  const indicesBuf = backend.bufferSync<Rank, 'int32'>(sparseIndices);\n\n  let outBuf;\n  switch (sparseValues.dtype) {\n    case 'bool': {\n      const updatesBuf = backend.bufferSync<Rank, 'bool'>(sparseValues);\n      const $defaultValue =\n          Boolean(backend.data.get(defaultValue.dataId).values[0]);\n      outBuf = scatterImpl(\n          indicesBuf, updatesBuf, outputShape, outputSize, sliceSize,\n          numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);\n      break;\n    }\n    case 'float32': {\n      const updatesBuf = backend.bufferSync<Rank, 'float32'>(sparseValues);\n      const $defaultValue =\n          backend.data.get(defaultValue.dataId).values[0] as number;\n      outBuf = scatterImpl(\n          indicesBuf, updatesBuf, outputShape, outputSize, sliceSize,\n          numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);\n      break;\n    }\n    case 'int32': {\n      const updatesBuf = backend.bufferSync<Rank, 'int32'>(sparseValues);\n      const $defaultValue =\n          backend.data.get(defaultValue.dataId).values[0] as number;\n      outBuf = scatterImpl(\n          indicesBuf, updatesBuf, outputShape, outputSize, sliceSize,\n          numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);\n      break;\n    }\n    case 'string': {\n      const updatesBuf = backend.bufferSync<Rank, 'string'>(sparseValues);\n      const $defaultValue = util.decodeString(\n          backend.data.get(defaultValue.dataId).values[0] as Uint8Array);\n      outBuf = scatterImpl(\n          indicesBuf, updatesBuf, outputShape, outputSize, sliceSize,\n          numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);\n      break;\n    }\n    default:\n      throw new Error(`Unsupported type ${sparseValues.dtype}`);\n  }\n  return backend.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);\n}\n\nexport const sparseToDenseConfig: KernelConfig = {\n  kernelName: SparseToDense,\n  backendName: 'cpu',\n  kernelFunc: sparseToDense as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, SplitVAttrs, SplitVInputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, KernelFunc, SplitV, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {slice} from './Slice';\n\nexport function splitV(\n    args: {inputs: SplitVInputs, backend: MathBackendCPU, attrs: SplitVAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {numOrSizeSplits, axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, x.shape)[0];\n  const splitSizes = backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);\n\n  const begin = new Array(x.shape.length).fill(0);\n  const size = x.shape.slice();\n  return splitSizes.map(s => {\n    const sliceSize = [...size];\n    sliceSize[$axis] = s;\n    const sliceT =\n        slice({inputs: {x}, backend, attrs: {begin, size: sliceSize}});\n    begin[$axis] += s;\n    return sliceT;\n  });\n}\n\nexport const splitVConfig: KernelConfig = {\n  kernelName: SplitV,\n  backendName: 'cpu',\n  kernelFunc: splitV as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Square, SquareInputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const squareConfig: KernelConfig = {\n  kernelName: Square,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as SquareInputs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'square');\n\n    const values = cpuBackend.data.get(x.dataId).values as Float32Array;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = value * value;\n    }\n    const dataId = cpuBackend.write(newValues, x.shape, x.dtype);\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Step, StepAttrs} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const step = unaryKernelFunc(Step, (xi, attrs) => {\n  const stepAttrs = attrs as {} as StepAttrs;\n  if (isNaN(xi)) {\n    return NaN;\n  } else {\n    return xi > 0 ? 1 : stepAttrs.alpha;\n  }\n});\n\nexport const stepConfig: KernelConfig = {\n  kernelName: Step,\n  backendName: 'cpu',\n  kernelFunc: step,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Rank, slice_util, StridedSlice, StridedSliceAttrs, StridedSliceInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\nimport {stridedSliceImpl} from './StridedSlice_impl';\n\nexport function stridedSlice(args: {\n  inputs: StridedSliceInputs,\n  backend: MathBackendCPU,\n  attrs: StridedSliceAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {\n    begin,\n    end,\n    strides,\n    beginMask,\n    endMask,\n    ellipsisMask,\n    newAxisMask,\n    shrinkAxisMask\n  } = attrs;\n\n  assertNotComplex(x, 'stridedSlice');\n\n  const {\n    finalShapeSparse,\n    finalShape,\n    isIdentity,\n    sliceDim0,\n    isSimpleSlice,\n    begin: $begin,\n    end: $end,\n    strides: $strides\n  } =\n      slice_util.sliceInfo(\n          x.shape, begin, end, strides, beginMask, endMask, ellipsisMask,\n          newAxisMask, shrinkAxisMask);\n\n  let result;\n\n  // ref:\n  // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/strided_slice_op.cc\n  if (isIdentity) {\n    // Optimization #1, slice is a no-op plus reshape\n    result = reshape({inputs: {x}, backend, attrs: {shape: finalShape}});\n  } else if (sliceDim0 || isSimpleSlice) {\n    // Optimization #2, slice is memory contiguous (only occurs in dim 0)\n    util.assert(\n        x.shape.length >= 1,\n        () => `Input must have rank at least 1, got: ${x.shape.length}`);\n\n    const size = slice_util.computeOutShape($begin, $end, $strides);\n    // To tolerate begin[0] > end[0] (a 0-output slice), we min(begin, end).\n    const sliced = slice({inputs: {x}, backend, attrs: {begin: $begin, size}});\n    result =\n        reshape({inputs: {x: sliced}, backend, attrs: {shape: finalShape}});\n    backend.disposeIntermediateTensorInfo(sliced);\n  } else {\n    const xBuf = backend.bufferSync<Rank, 'float32'>(x);\n    const outBuf = stridedSliceImpl(finalShapeSparse, xBuf, $strides, $begin);\n\n    result = backend.makeTensorInfo(finalShape, outBuf.dtype, outBuf.values);\n  }\n\n  return result;\n}\n\nexport const stridedSliceConfig: KernelConfig = {\n  kernelName: StridedSlice,\n  backendName: 'cpu',\n  kernelFunc: stridedSlice as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringNGrams, StringNGramsAttrs, StringNGramsInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {stringNGramsImpl} from './StringNGrams_impl';\n\nexport function stringNGrams(args: {\n  inputs: StringNGramsInputs,\n  backend: MathBackendCPU,\n  attrs: StringNGramsAttrs\n}): [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {\n    separator,\n    nGramWidths,\n    leftPad,\n    rightPad,\n    padWidth,\n    preserveShortSequences\n  } = attrs;\n  const {data, dataSplits} = inputs;\n  const $data = backend.data.get(data.dataId).values as Uint8Array[];\n  const $dataSplits = backend.data.get(dataSplits.dataId).values as Int32Array;\n\n  const [nGrams, nGramsSplits] = stringNGramsImpl(\n      $data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth,\n      preserveShortSequences);\n  return [\n    backend.makeTensorInfo([nGrams.length], 'string', nGrams),\n    backend.makeTensorInfo(dataSplits.shape, 'int32', nGramsSplits),\n  ];\n}\n\nexport const stringNGramsConfig: KernelConfig = {\n  kernelName: StringNGrams,\n  backendName: 'cpu',\n  kernelFunc: stringNGrams as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringSplit, StringSplitAttrs, StringSplitInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {stringSplitImpl} from './StringSplit_impl';\n\nexport function stringSplit(args: {\n  inputs: StringSplitInputs,\n  backend: MathBackendCPU,\n  attrs: StringSplitAttrs\n}): [TensorInfo, TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {skipEmpty} = attrs;\n  const {input, delimiter} = inputs;\n\n  if (input.dtype !== 'string') {\n    throw new Error('Input must be of datatype string');\n  }\n  if (input.shape.length !== 1) {\n    throw new Error(`Input must be a vector, got shape: ${input.shape}`);\n  }\n  if (delimiter.shape.length !== 0) {\n    throw new Error(\n        `Delimiter must be a scalar, got shape: ${delimiter.shape}`);\n  }\n\n  const $input = backend.data.get(input.dataId).values as Uint8Array[];\n  const $delimiter = backend.data.get(delimiter.dataId).values[0] as Uint8Array;\n\n  const [indices, values, shape] =\n      stringSplitImpl($input, $delimiter, skipEmpty);\n  const outputSize = values.length;\n  return [\n    backend.makeTensorInfo([outputSize, 2], 'int32', indices),\n    backend.makeTensorInfo([outputSize], 'string', values),\n    backend.makeTensorInfo([2], 'int32', new Int32Array(shape))\n  ];\n}\n\nexport const stringSplitConfig: KernelConfig = {\n  kernelName: StringSplit,\n  backendName: 'cpu',\n  kernelFunc: stringSplit as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, StringToHashBucketFast, StringToHashBucketFastAttrs, StringToHashBucketFastInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {stringToHashBucketFastImpl} from './StringToHashBucketFast_impl';\n\nexport function stringToHashBucketFast(args: {\n  inputs: StringToHashBucketFastInputs,\n  backend: MathBackendCPU,\n  attrs: StringToHashBucketFastAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {numBuckets} = attrs;\n  const {input} = inputs;\n\n  if (input.dtype !== 'string') {\n    throw new Error('Input must be of datatype string');\n  }\n  if (numBuckets <= 0) {\n    throw new Error(`Number of buckets must be at least 1`);\n  }\n\n  const $input = backend.data.get(input.dataId).values as Uint8Array[];\n\n  const output = stringToHashBucketFastImpl($input, numBuckets);\n  return backend.makeTensorInfo(input.shape, 'int32', output);\n}\n\nexport const stringToHashBucketFastConfig: KernelConfig = {\n  kernelName: StringToHashBucketFast,\n  backendName: 'cpu',\n  kernelFunc: stringToHashBucketFast as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tan} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tan = unaryKernelFunc(Tan, (xi) => Math.tan(xi));\n\nexport const tanConfig: KernelConfig = {\n  kernelName: Tan,\n  backendName: 'cpu',\n  kernelFunc: tan,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tanh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tanh = unaryKernelFunc(Tanh, (xi) => Math.tanh(xi));\n\nexport const tanhConfig: KernelConfig = {\n  kernelName: Tanh,\n  backendName: 'cpu',\n  kernelFunc: tanh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Tile, TileAttrs, TileInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {tileImpl} from './Tile_impl';\n\nexport function tile(\n    args: {inputs: TileInputs, backend: MathBackendCPU, attrs: TileAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {reps} = attrs;\n\n  assertNotComplex(x, 'tile');\n  const outBuf = tileImpl(backend.bufferSync(x), reps);\n\n  return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);\n}\n\nexport const tileConfig: KernelConfig = {\n  kernelName: Tile,\n  backendName: 'cpu',\n  kernelFunc: tile as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, TensorInfo, TopK, TopKAttrs, TopKInputs, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {topKImpl} from './TopK_impl';\n\nexport function topK(\n    args: {inputs: TopKInputs, backend: MathBackendCPU, attrs: TopKAttrs}):\n    [TensorInfo, TensorInfo] {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {k, sorted} = attrs;\n\n  assertNotComplex(x, 'topk');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const [allTopKVals, allTopKIndices] =\n      topKImpl(xVals, x.shape, x.dtype as NumericDataType, k, sorted);\n\n  return [\n    backend.makeTensorInfo(\n        allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),\n    backend.makeTensorInfo(\n        allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)\n  ];\n}\n\nexport const topKConfig: KernelConfig = {\n  kernelName: TopK,\n  backendName: 'cpu',\n  kernelFunc: topK as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, TensorInfo, Transform, TransformAttrs, TransformInputs, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function transform(args: {\n  inputs: TransformInputs,\n  attrs: TransformAttrs,\n  backend: MathBackendCPU\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {image, transforms} = inputs;\n  const {interpolation, fillMode, fillValue, outputShape} = attrs;\n\n  const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n  const [outHeight, outWidth] =\n      outputShape != null ? outputShape : [imageHeight, imageWidth];\n  const outShape = [batch, outHeight, outWidth, numChannels];\n\n  const inStrides = util.computeStrides(image.shape);\n  const batchInStride = inStrides[0];\n  const rowInStride = inStrides[1];\n  const colInStride = inStrides[2];\n\n  const outStrides = util.computeStrides(outShape);\n  const batchOutStride = outStrides[0];\n  const rowOutStride = outStrides[1];\n  const colOutStride = outStrides[2];\n\n  const outVals = util.getTypedArrayFromDType(\n      image.dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  outVals.fill(fillValue);\n\n  const imageVals = backend.data.get(image.dataId).values as TypedArray;\n  const transformVals =\n      backend.data.get(transforms.dataId).values as TypedArray;\n\n  // Ref TF implementation:\n  // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/image/image_ops.h\n  for (let b = 0; b < batch; ++b) {\n    const transform = transforms.shape[0] === 1 ?\n        transformVals :\n        transformVals.subarray(b * 8, b * 8 + 8);\n\n    for (let outY = 0; outY < outHeight; ++outY) {\n      for (let outX = 0; outX < outWidth; ++outX) {\n        for (let channel = 0; channel < numChannels; ++channel) {\n          let val;\n\n          const projection = transform[6] * outX + transform[7] * outY + 1;\n\n          if (projection === 0) {\n            // Return the fill value for infinite coordinates,\n            // which are outside the input image\n            continue;\n          }\n\n          const inX =\n              (transform[0] * outX + transform[1] * outY + transform[2]) /\n              projection;\n          const inY =\n              (transform[3] * outX + transform[4] * outY + transform[5]) /\n              projection;\n\n          const x = mapCoord(inX, imageWidth, fillMode);\n          const y = mapCoord(inY, imageHeight, fillMode);\n\n          switch (interpolation) {\n            case 'nearest':\n              val = nearestInterpolation(\n                  imageVals, imageHeight, imageWidth, batchInStride,\n                  rowInStride, colInStride, b, y, x, channel, fillValue);\n              break;\n            case 'bilinear':\n              val = bilinearInterpolation(\n                  imageVals, imageHeight, imageWidth, batchInStride,\n                  rowInStride, colInStride, b, y, x, channel, fillValue);\n              break;\n            default:\n              throw new Error(\n                  `Error in Transform: Expect 'nearest' or ` +\n                  `'bilinear', but got ${interpolation}`);\n          }\n\n          const ind =\n              b * batchOutStride + outY * rowOutStride +\n              outX * colOutStride + channel;\n\n          outVals[ind] = val;\n        }\n      }\n    }\n\n    return backend.makeTensorInfo(outShape, image.dtype, outVals);\n  }\n\n  const dataId = backend.write(outVals, outShape, image.dtype);\n  return {dataId, shape: image.shape, dtype: image.dtype};\n}\n\nexport const transformConfig: KernelConfig = {\n  kernelName: Transform,\n  backendName: 'cpu',\n  kernelFunc: transform as {} as KernelFunc\n};\n\nfunction mapCoord(\n    outCoord: number, len: number,\n    mode: 'constant'|'reflect'|'wrap'|'nearest') {\n  switch (mode) {\n    case 'reflect':\n      return mapCoordReflect(outCoord, len);\n    case 'wrap':\n      return mapCoordWrap(outCoord, len);\n    case 'nearest':\n      return mapCoordNearest(outCoord, len);\n    case 'constant':\n    default:\n      return mapCoordConstant(outCoord, len);\n  }\n}\n\nfunction mapCoordReflect(outCoord: number, len: number): number {\n  // Reflect [abcd] to [dcba|abcd|dcba].\n  let inCoord = outCoord;\n  if (inCoord < 0) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz2 = 2 * len;\n      if (inCoord < sz2) {\n        inCoord = sz2 * Math.trunc(-inCoord / sz2) + inCoord;\n      }\n      inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1;\n    }\n  } else if (inCoord > len - 1) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz2 = 2 * len;\n      inCoord -= sz2 * Math.trunc(inCoord / sz2);\n      if (inCoord >= len) {\n        inCoord = sz2 - inCoord - 1;\n      }\n    }\n  }\n  // clamp is necessary because when outCoord = 3.5 and len = 4,\n  // inCoord = 3.5 and will be rounded to 4 in nearest interpolation.\n  return util.clamp(0, inCoord, len - 1);\n}\n\nfunction mapCoordWrap(outCoord: number, len: number): number {\n  // Wrap [abcd] to [abcd|abcd|abcd].\n  let inCoord = outCoord;\n  if (inCoord < 0) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz = len - 1;\n      inCoord += len * (Math.trunc(-inCoord / sz) + 1);\n    }\n  } else if (inCoord > len - 1) {\n    if (len <= 1) {\n      inCoord = 0;\n    } else {\n      const sz = len - 1;\n      inCoord -= len * Math.trunc(inCoord / sz);\n    }\n  }\n  // clamp is necessary because when outCoord = -0.5 and len = 4,\n  // inCoord = 3.5 and will be rounded to 4 in nearest interpolation.\n  return util.clamp(0, inCoord, len - 1);\n}\n\nfunction mapCoordConstant(outCoord: number, len: number): number {\n  return outCoord;\n}\n\nfunction mapCoordNearest(outCoord: number, len: number): number {\n  return util.clamp(0, outCoord, len - 1);\n}\n\nfunction readWithFillValue(\n    imageVals: TypedArray, imageHeight: number, imageWidth: number,\n    batchStride: number, rowStride: number, colStride: number, batch: number,\n    y: number, x: number, channel: number, fillValue: number): number {\n  const ind = batch * batchStride + y * rowStride + x * colStride + channel;\n  if (0 <= y && y < imageHeight && 0 <= x && x < imageWidth) {\n    return imageVals[ind];\n  } else {\n    return fillValue;\n  }\n}\n\nfunction nearestInterpolation(\n    imageVals: TypedArray, imageHeight: number, imageWidth: number,\n    batchStride: number, rowStride: number, colStride: number, batch: number,\n    y: number, x: number, channel: number, fillValue: number): number {\n  const $y = Math.round(y);\n  const $x = Math.round(x);\n\n  return readWithFillValue(\n      imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride,\n      batch, $y, $x, channel, fillValue);\n}\n\nfunction bilinearInterpolation(\n    imageVals: TypedArray, imageHeight: number, imageWidth: number,\n    batchStride: number, rowStride: number, colStride: number, batch: number,\n    y: number, x: number, channel: number, fillValue: number) {\n  const yFloor = Math.floor(y);\n  const xFloor = Math.floor(x);\n  const yCeil = yFloor + 1;\n  const xCeil = xFloor + 1;\n  // f(x, yFloor) = (xCeil - x) / (xCeil - xFloor) * f(xFloor, yFloor)\n  //               + (x - xFloor) / (xCeil - xFloor) * f(xCeil, yFloor)\n  const valueYFloor =\n      (xCeil - x) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yFloor, xFloor, channel, fillValue) +\n      (x - xFloor) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yFloor, xCeil, channel, fillValue);\n  // f(x, yCeil) = (xCeil - x) / (xCeil - xFloor) * f(xFloor, yCeil)\n  //             + (x - xFloor) / (xCeil - xFloor) * f(xCeil, yCeil)\n  const valueYCeil =\n      (xCeil - x) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yCeil, xFloor, channel, fillValue) +\n      (x - xFloor) *\n          readWithFillValue(\n              imageVals, imageHeight, imageWidth, batchStride, rowStride,\n              colStride, batch, yCeil, xCeil, channel, fillValue);\n  // f(x, y) = (yCeil - y) / (yCeil - yFloor) * f(x, yFloor)\n  //         + (y - yFloor) / (yCeil - yFloor) * f(x, yCeil)\n  return (yCeil - y) * valueYFloor + (y - yFloor) * valueYCeil;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unique, UniqueAttrs, UniqueInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {uniqueImpl} from './Unique_impl';\n\nexport function unique(\n    args: {inputs: UniqueInputs, attrs: UniqueAttrs, backend: MathBackendCPU}):\n    TensorInfo[] {\n  const {inputs, attrs, backend} = args;\n  const {axis} = attrs;\n  const {x} = inputs;\n  assertNotComplex(x, 'unique');\n\n  const values = backend.data.get(x.dataId).values;\n  const {outputValues, outputShape, indices} =\n      uniqueImpl(values, axis, x.shape, x.dtype);\n  return [\n    backend.makeTensorInfo(outputShape, x.dtype, outputValues),\n    backend.makeTensorInfo([indices.length], 'int32', indices),\n  ];\n}\n\nexport const uniqueConfig: KernelConfig = {\n  kernelName: Unique,\n  backendName: 'cpu',\n  kernelFunc: unique as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unpack, UnpackAttrs, UnpackInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {reshape} from './Reshape';\nimport {slice} from './Slice';\n\nexport function unpack(\n    args: {inputs: UnpackInputs, backend: MathBackendCPU, attrs: UnpackAttrs}):\n    TensorInfo[] {\n  const {inputs, backend, attrs} = args;\n  const {value} = inputs;\n  let {axis} = attrs;\n\n  if (axis < 0) {\n    axis += value.shape.length;\n  }\n\n  const valueRank = value.shape.length;\n\n  const num = value.shape[axis];\n  const outShape: number[] = new Array(valueRank - 1);\n  let outIndex = 0;\n  for (let i = 0; i < valueRank; i++) {\n    if (i !== axis) {\n      outShape[outIndex++] = value.shape[i];\n    }\n  }\n\n  const begin = new Array(valueRank).fill(0);\n  const size = value.shape.slice();\n  size[axis] = 1;\n  const res = new Array(num);\n  for (let i = 0; i < res.length; i++) {\n    begin[axis] = i;\n    const tempRes = slice({inputs: {x: value}, backend, attrs: {begin, size}});\n    res[i] = reshape({inputs: {x: tempRes}, backend, attrs: {shape: outShape}});\n    backend.disposeIntermediateTensorInfo(tempRes);\n  }\n\n  return res;\n}\n\nexport const unpackConfig: KernelConfig = {\n  kernelName: Unpack,\n  backendName: 'cpu',\n  kernelFunc: unpack as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, UnsortedSegmentSum, UnsortedSegmentSumAttrs, UnsortedSegmentSumInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {cast} from './Cast';\nimport {equal} from './Equal';\nimport {expandDims} from './ExpandDims';\nimport {multiply} from './Multiply';\nimport {pack} from './Pack';\nimport {sum} from './Sum';\n\nexport function unsortedSegmentSum(args: {\n  inputs: UnsortedSegmentSumInputs,\n  backend: MathBackendCPU,\n  attrs: UnsortedSegmentSumAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, segmentIds} = inputs;\n  const {numSegments} = attrs;\n\n  assertNotComplex(x, 'unsortedSegmentSum');\n\n  const xRank = x.shape.length;\n  const segmentIdsRank = segmentIds.shape.length;\n  const res = [];\n  const intermediates: TensorInfo[] = [];\n\n  // Reshape the segment id's so that they can be broadcast with\n  // x. The new shape should be [segmentIds.shape, 1, ..., 1]\n  const numIters = xRank - segmentIdsRank;\n  let $segmentIds = segmentIds;\n\n  for (let i = 0; i < numIters; ++i) {\n    const expanded = expandDims(\n        {inputs: {input: $segmentIds}, backend, attrs: {dim: i + 1}});\n    $segmentIds = expanded;\n    intermediates.push(expanded);\n  }\n\n  for (let i = 0; i < numSegments; ++i) {\n    const scalarValue = util.createScalarValue(i as {} as 'int32', 'int32');\n    const segmentId = backend.makeTensorInfo([], 'int32', scalarValue);\n    const mask =\n        equal({inputs: {a: segmentId, b: $segmentIds}, backend}) as TensorInfo;\n    const maskCasted =\n        cast({inputs: {x: mask}, backend, attrs: {dtype: 'float32'}});\n    const mul =\n        multiply({inputs: {a: maskCasted, b: x}, backend}) as TensorInfo;\n    const sumTensorInfo =\n        sum({inputs: {x: mul}, backend, attrs: {axis: 0, keepDims: false}});\n    res.push(sumTensorInfo);\n    intermediates.push(segmentId);\n    intermediates.push(mask);\n    intermediates.push(maskCasted);\n    intermediates.push(mul);\n    intermediates.push(sumTensorInfo);\n  }\n\n  const result = pack({inputs: res, backend, attrs: {axis: 0}});\n\n  intermediates.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return result;\n}\n\nexport const unsortedSegmentSumConfig: KernelConfig = {\n  kernelName: UnsortedSegmentSum,\n  backendName: 'cpu',\n  kernelFunc: unsortedSegmentSum as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// We explicitly import the modular kernels so they get registered in the\n// global registry when we compile the library. A modular build would replace\n// the contents of this file and import only the kernels that are needed.\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {_fusedMatMulConfig} from './kernels/_FusedMatMul';\nimport {absConfig} from './kernels/Abs';\nimport {acosConfig} from './kernels/Acos';\nimport {acoshConfig} from './kernels/Acosh';\nimport {addConfig} from './kernels/Add';\nimport {addNConfig} from './kernels/AddN';\nimport {allConfig} from './kernels/All';\nimport {anyConfig} from './kernels/Any';\nimport {argMaxConfig} from './kernels/ArgMax';\nimport {argMinConfig} from './kernels/ArgMin';\nimport {asinConfig} from './kernels/Asin';\nimport {asinhConfig} from './kernels/Asinh';\nimport {atanConfig} from './kernels/Atan';\nimport {atan2Config} from './kernels/Atan2';\nimport {atanhConfig} from './kernels/Atanh';\nimport {avgPoolConfig} from './kernels/AvgPool';\nimport {avgPool3DConfig} from './kernels/AvgPool3D';\nimport {avgPool3DGradConfig} from './kernels/AvgPool3DGrad';\nimport {avgPoolGradConfig} from './kernels/AvgPoolGrad';\nimport {batchMatMulConfig} from './kernels/BatchMatMul';\nimport {batchNormConfig} from './kernels/BatchNorm';\nimport {batchToSpaceNDConfig} from './kernels/BatchToSpaceND';\nimport {bincountConfig} from './kernels/Bincount';\nimport {broadcastArgsConfig} from './kernels/BroadcastArgs';\nimport {castConfig} from './kernels/Cast';\nimport {ceilConfig} from './kernels/Ceil';\nimport {clipByValueConfig} from './kernels/ClipByValue';\nimport {complexConfig} from './kernels/Complex';\nimport {complexAbsConfig} from './kernels/ComplexAbs';\nimport {concatConfig} from './kernels/Concat';\nimport {conv2DConfig} from './kernels/Conv2D';\nimport {conv2DBackpropFilterConfig} from './kernels/Conv2DBackpropFilter';\nimport {conv2DBackpropInputConfig} from './kernels/Conv2DBackpropInput';\nimport {conv3DConfig} from './kernels/Conv3D';\nimport {conv3DBackpropFilterV2Config} from './kernels/Conv3DBackpropFilterV2';\nimport {conv3DBackpropInputV2Config} from './kernels/Conv3DBackpropInputV2';\nimport {cosConfig} from './kernels/Cos';\nimport {coshConfig} from './kernels/Cosh';\nimport {cropAndResizeConfig} from './kernels/CropAndResize';\nimport {cumprodConfig} from './kernels/Cumprod';\nimport {cumsumConfig} from './kernels/Cumsum';\nimport {denseBincountConfig} from './kernels/DenseBincount';\nimport {depthToSpaceConfig} from './kernels/DepthToSpace';\nimport {depthwiseConv2dNativeConfig} from './kernels/DepthwiseConv2dNative';\nimport {depthwiseConv2dNativeBackpropFilterConfig} from './kernels/DepthwiseConv2dNativeBackpropFilter';\nimport {depthwiseConv2dNativeBackpropInputConfig} from './kernels/DepthwiseConv2dNativeBackpropInput';\nimport {diagConfig} from './kernels/Diag';\nimport {dilation2DConfig} from './kernels/Dilation2D';\nimport {dilation2DBackpropFilterConfig} from './kernels/Dilation2DBackpropFilter';\nimport {dilation2DBackpropInputConfig} from './kernels/Dilation2DBackpropInput';\nimport {einsumConfig} from './kernels/Einsum';\nimport {eluConfig} from './kernels/Elu';\nimport {eluGradConfig} from './kernels/EluGrad';\nimport {equalConfig} from './kernels/Equal';\nimport {erfConfig} from './kernels/Erf';\nimport {expConfig} from './kernels/Exp';\nimport {expandDimsConfig} from './kernels/ExpandDims';\nimport {expm1Config} from './kernels/Expm1';\nimport {fftConfig} from './kernels/FFT';\nimport {fillConfig} from './kernels/Fill';\nimport {flipLeftRightConfig} from './kernels/FlipLeftRight';\nimport {floorConfig} from './kernels/Floor';\nimport {floorDivConfig} from './kernels/FloorDiv';\nimport {fusedConv2DConfig} from './kernels/FusedConv2D';\nimport {fusedDepthwiseConv2DConfig} from './kernels/FusedDepthwiseConv2D';\nimport {gatherNdConfig} from './kernels/GatherNd';\nimport {gatherV2Config} from './kernels/GatherV2';\nimport {greaterConfig} from './kernels/Greater';\nimport {greaterEqualConfig} from './kernels/GreaterEqual';\nimport {identityConfig} from './kernels/Identity';\nimport {ifftConfig} from './kernels/IFFT';\nimport {imagConfig} from './kernels/Imag';\nimport {isFiniteConfig} from './kernels/IsFinite';\nimport {isInfConfig} from './kernels/IsInf';\nimport {isNaNConfig} from './kernels/IsNaN';\nimport {leakyReluConfig} from './kernels/LeakyRelu';\nimport {lessConfig} from './kernels/Less';\nimport {lessEqualConfig} from './kernels/LessEqual';\nimport {linSpaceConfig} from './kernels/LinSpace';\nimport {logConfig} from './kernels/Log';\nimport {log1pConfig} from './kernels/Log1p';\nimport {logicalAndConfig} from './kernels/LogicalAnd';\nimport {logicalNotConfig} from './kernels/LogicalNot';\nimport {logicalOrConfig} from './kernels/LogicalOr';\nimport {LRNConfig} from './kernels/LRN';\nimport {LRNGradConfig} from './kernels/LRNGrad';\nimport {maxConfig} from './kernels/Max';\nimport {maximumConfig} from './kernels/Maximum';\nimport {maxPoolConfig} from './kernels/MaxPool';\nimport {maxPool3DConfig} from './kernels/MaxPool3D';\nimport {maxPool3DGradConfig} from './kernels/MaxPool3DGrad';\nimport {maxPoolGradConfig} from './kernels/MaxPoolGrad';\nimport {maxPoolWithArgmaxConfig} from './kernels/MaxPoolWithArgmax';\nimport {meanConfig} from './kernels/Mean';\nimport {minConfig} from './kernels/Min';\nimport {minimumConfig} from './kernels/Minimum';\nimport {mirrorPadConfig} from './kernels/MirrorPad';\nimport {modConfig} from './kernels/Mod';\nimport {multinomialConfig} from './kernels/Multinomial';\nimport {multiplyConfig} from './kernels/Multiply';\nimport {negConfig} from './kernels/Neg';\nimport {nonMaxSuppressionV3Config} from './kernels/NonMaxSuppressionV3';\nimport {nonMaxSuppressionV4Config} from './kernels/NonMaxSuppressionV4';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {notEqualConfig} from './kernels/NotEqual';\nimport {oneHotConfig} from './kernels/OneHot';\nimport {onesLikeConfig} from './kernels/OnesLike';\nimport {packConfig} from './kernels/Pack';\nimport {padV2Config} from './kernels/PadV2';\nimport {powConfig} from './kernels/Pow';\nimport {preluConfig} from './kernels/Prelu';\nimport {prodConfig} from './kernels/Prod';\nimport {raggedTensorToTensorConfig} from './kernels/RaggedTensorToTensor';\nimport {rangeConfig} from './kernels/Range';\nimport {realConfig} from './kernels/Real';\nimport {realDivConfig} from './kernels/RealDiv';\nimport {reciprocalConfig} from './kernels/Reciprocal';\nimport {reluConfig} from './kernels/Relu';\nimport {relu6Config} from './kernels/Relu6';\nimport {reshapeConfig} from './kernels/Reshape';\nimport {resizeBilinearConfig} from './kernels/ResizeBilinear';\nimport {resizeBilinearGradConfig} from './kernels/ResizeBilinearGrad';\nimport {resizeNearestNeighborConfig} from './kernels/ResizeNearestNeighbor';\nimport {resizeNearestNeighborGradConfig} from './kernels/ResizeNearestNeighborGrad';\nimport {reverseConfig} from './kernels/Reverse';\nimport {rotateWithOffsetConfig} from './kernels/RotateWithOffset';\nimport {roundConfig} from './kernels/Round';\nimport {rsqrtConfig} from './kernels/Rsqrt';\nimport {scatterNdConfig} from './kernels/ScatterNd';\nimport {searchSortedConfig} from './kernels/SearchSorted';\nimport {selectConfig} from './kernels/Select';\nimport {seluConfig} from './kernels/Selu';\nimport {sigmoidConfig} from './kernels/Sigmoid';\nimport {signConfig} from './kernels/Sign';\nimport {sinConfig} from './kernels/Sin';\nimport {sinhConfig} from './kernels/Sinh';\nimport {sliceConfig} from './kernels/Slice';\nimport {softmaxConfig} from './kernels/Softmax';\nimport {softplusConfig} from './kernels/Softplus';\nimport {spaceToBatchNDConfig} from './kernels/SpaceToBatchND';\nimport {sparseFillEmptyRowsConfig} from './kernels/SparseFillEmptyRows';\nimport {sparseReshapeConfig} from './kernels/SparseReshape';\nimport {sparseSegmentMeanConfig} from './kernels/SparseSegmentMean';\nimport {sparseSegmentSumConfig} from './kernels/SparseSegmentSum';\nimport {sparseToDenseConfig} from './kernels/SparseToDense';\nimport {splitVConfig} from './kernels/SplitV';\nimport {sqrtConfig} from './kernels/Sqrt';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {stepConfig} from './kernels/Step';\nimport {stridedSliceConfig} from './kernels/StridedSlice';\nimport {stringNGramsConfig} from './kernels/StringNGrams';\nimport {stringSplitConfig} from './kernels/StringSplit';\nimport {stringToHashBucketFastConfig} from './kernels/StringToHashBucketFast';\nimport {subConfig} from './kernels/Sub';\nimport {sumConfig} from './kernels/Sum';\nimport {tanConfig} from './kernels/Tan';\nimport {tanhConfig} from './kernels/Tanh';\nimport {tileConfig} from './kernels/Tile';\nimport {topKConfig} from './kernels/TopK';\nimport {transformConfig} from './kernels/Transform';\nimport {transposeConfig} from './kernels/Transpose';\nimport {uniqueConfig} from './kernels/Unique';\nimport {unpackConfig} from './kernels/Unpack';\nimport {unsortedSegmentSumConfig} from './kernels/UnsortedSegmentSum';\nimport {zerosLikeConfig} from './kernels/ZerosLike';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  _fusedMatMulConfig,\n  absConfig,\n  acosConfig,\n  acoshConfig,\n  addConfig,\n  addNConfig,\n  allConfig,\n  anyConfig,\n  argMaxConfig,\n  argMinConfig,\n  asinConfig,\n  asinhConfig,\n  atanConfig,\n  atan2Config,\n  atanhConfig,\n  avgPoolConfig,\n  avgPool3DConfig,\n  avgPool3DGradConfig,\n  avgPoolGradConfig,\n  batchMatMulConfig,\n  batchNormConfig,\n  batchToSpaceNDConfig,\n  bincountConfig,\n  broadcastArgsConfig,\n  castConfig,\n  ceilConfig,\n  clipByValueConfig,\n  complexConfig,\n  complexAbsConfig,\n  concatConfig,\n  conv2DConfig,\n  conv2DBackpropFilterConfig,\n  conv2DBackpropInputConfig,\n  conv3DConfig,\n  conv3DBackpropFilterV2Config,\n  conv3DBackpropInputV2Config,\n  cosConfig,\n  coshConfig,\n  cropAndResizeConfig,\n  cumprodConfig,\n  cumsumConfig,\n  denseBincountConfig,\n  depthToSpaceConfig,\n  depthwiseConv2dNativeConfig,\n  depthwiseConv2dNativeBackpropFilterConfig,\n  depthwiseConv2dNativeBackpropInputConfig,\n  diagConfig,\n  dilation2DConfig,\n  dilation2DBackpropFilterConfig,\n  dilation2DBackpropInputConfig,\n  einsumConfig,\n  eluConfig,\n  eluGradConfig,\n  equalConfig,\n  erfConfig,\n  expConfig,\n  expandDimsConfig,\n  expm1Config,\n  fftConfig,\n  fillConfig,\n  flipLeftRightConfig,\n  floorConfig,\n  floorDivConfig,\n  fusedConv2DConfig,\n  fusedDepthwiseConv2DConfig,\n  gatherNdConfig,\n  gatherV2Config,\n  greaterConfig,\n  greaterEqualConfig,\n  identityConfig,\n  ifftConfig,\n  imagConfig,\n  isFiniteConfig,\n  isInfConfig,\n  isNaNConfig,\n  leakyReluConfig,\n  lessConfig,\n  lessEqualConfig,\n  linSpaceConfig,\n  logConfig,\n  log1pConfig,\n  logicalAndConfig,\n  logicalNotConfig,\n  logicalOrConfig,\n  LRNConfig,\n  LRNGradConfig,\n  maxConfig,\n  maximumConfig,\n  maxPoolConfig,\n  maxPool3DConfig,\n  maxPool3DGradConfig,\n  maxPoolGradConfig,\n  maxPoolWithArgmaxConfig,\n  meanConfig,\n  minConfig,\n  minimumConfig,\n  mirrorPadConfig,\n  modConfig,\n  multinomialConfig,\n  multiplyConfig,\n  negConfig,\n  nonMaxSuppressionV3Config,\n  nonMaxSuppressionV4Config,\n  nonMaxSuppressionV5Config,\n  notEqualConfig,\n  oneHotConfig,\n  onesLikeConfig,\n  packConfig,\n  padV2Config,\n  powConfig,\n  preluConfig,\n  prodConfig,\n  raggedTensorToTensorConfig,\n  rangeConfig,\n  realConfig,\n  realDivConfig,\n  reciprocalConfig,\n  reluConfig,\n  relu6Config,\n  reshapeConfig,\n  resizeBilinearConfig,\n  resizeBilinearGradConfig,\n  resizeNearestNeighborConfig,\n  resizeNearestNeighborGradConfig,\n  reverseConfig,\n  rotateWithOffsetConfig,\n  roundConfig,\n  rsqrtConfig,\n  scatterNdConfig,\n  searchSortedConfig,\n  selectConfig,\n  seluConfig,\n  sigmoidConfig,\n  signConfig,\n  sinConfig,\n  sinhConfig,\n  sliceConfig,\n  softmaxConfig,\n  softplusConfig,\n  spaceToBatchNDConfig,\n  sparseFillEmptyRowsConfig,\n  sparseReshapeConfig,\n  sparseSegmentMeanConfig,\n  sparseSegmentSumConfig,\n  sparseToDenseConfig,\n  splitVConfig,\n  sqrtConfig,\n  squareConfig,\n  squaredDifferenceConfig,\n  stepConfig,\n  stridedSliceConfig,\n  stringNGramsConfig,\n  stringSplitConfig,\n  stringToHashBucketFastConfig,\n  subConfig,\n  sumConfig,\n  tanConfig,\n  tanhConfig,\n  tileConfig,\n  topKConfig,\n  transformConfig,\n  transposeConfig,\n  uniqueConfig,\n  unpackConfig,\n  unsortedSegmentSumConfig,\n  zerosLikeConfig\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '3.20.0';\nexport {version};\n"],"names":["extendStatics","d","b","Object","setPrototypeOf","__proto__","Array","p","prototype","hasOwnProperty","call","__awaiter","thisArg","_arguments","P","generator","Promise","resolve","reject","fulfilled","value","step","next","e","rejected","result","done","then","apply","__generator","body","f","y","t","g","_","label","sent","trys","ops","verb","throw","return","Symbol","iterator","this","n","v","op","TypeError","pop","length","push","__values","o","s","m","i","__read","r","ar","error","__spread","arguments","concat","assertNotComplex","tensor","opName","isArray","forEach","util","assert","dtype","whereImpl","kernel_impls","_super","_this","data","DataStorage","engine","String","__","constructor","create","tslib_1.__extends","MathBackendCPU","nextDataId","values","shape","firstUse","env","get","backend_util","warn","dataId","id","set","refCount","outId","isString","encodedValues","map","encodeString","write","has","numDataIds","readSync","_b","complexTensorInfos","realValues","real","imagValues","imag","mergeRealAndImagArrays","strings","decodeString","buffer","Error","makeTensorFromTensorInfo","makeTensorInfo","force","disposeData","delete","tensorInfo","start","now","kernelMs","unreliable","reasons","condition","condVals","epsilon","KernelBackend","simpleAbsImpl","vals","resultValues","Float32Array","Math","abs","absConfig","kernelName","Abs","backendName","kernelFunc","args","x","cpuBackend","backend","sizeFromShape","makeOutput","createSimpleBinaryKernelImpl","aShape","bShape","aVals","bVals","newShape","assertAndGetBroadcastShape","resultRank","resultStrides","computeStrides","resultSize","getTypedArrayFromDType","aRank","bRank","aStrides","bStrides","aBroadcastDims","getBroadcastDims","bBroadcastDims","loc","indexToLoc","aLoc","slice","aIndex","locToIndex","bLoc","bIndex","complex","inputs","realVals","imagVals","complexInfo","complexConfig","Complex","zeros","makeZerosTypedArray","identity","incRef","identityConfig","Identity","input","realVal","realConfig","Real","castImpl","inputType","Int32Array","from","zero","toTypedArray","_a","resultData","cast","attrs","zerosTensorInfo","floatX","disposeIntermediateTensorInfo","realPart","hasEncodingLoss","resultShape","resultType","castConfig","Cast","binaryKernelFunc","name","simpleImpl","complexImpl","a","decodedAVals","fromUint8ToStringArray","decodedBVals","$dtype","$aComplex","$aComplexVals","aReal","aImag","aRealVals","aImagVals","$bComplex","$bComplexVals","bReal","bImag","bRealVals","bImagVals","resultRealData","resultImagData","resultReal","resultImag","_c","createComplexBinaryKernelImpl","resultRealVals","resultImagVals","aIdx","bIdx","opResult","addImpl","addComplexImpl","add","Add","addConfig","bincountImpl","xVals","weightsVals","weightsDtype","weightsShape","size","weightsSize","outVals","bincountReduceImpl","xBuf","weightsBuf","binaryOutput","numRows","numCols","outBuf","j","createSimpleUnaryImpl","newValues","unaryKernelFunc","xSize","getArrayFromDType","unaryKernelFuncFromImpl","unaryImpl","ceilImpl","xi","ceil","Ceil","ceilConfig","concatImpl","outShape","simplyConcat","offset_1","colOffset_1","decodedData","tIdx","row","resIdx","col","equalImpl","equal","Equal","equalConfig","expImpl","exp","Exp","expConfig","expm1Impl","expm1","Expm1","expm1Config","floorImpl","floor","Floor","floorConfig","gatherNdImpl","indicesData","paramsBuf","numSlices","sliceRank","sliceSize","strides","paramsShape","paramsSize","index","flattenIndex","dim","k","gatherV2Impl","indicesBuf","flattenOutputShape","originalLoc","batchIdx","indicesIdx","indicesIndex","originalIndex","greaterImpl","greater","Greater","greaterConfig","greaterEqualImpl","greaterEqual","GreaterEqual","greaterEqualConfig","lessImpl","less","Less","lessConfig","lessEqualImpl","lessEqual","LessEqual","lessEqualConfig","linSpaceImpl","stop","num","logImpl","log","Log","logConfig","maxImpl","reduceSize","offset","max","Number","isNaN","maximumImpl","aValue","bValue","maximum","Maximum","maximumConfig","minimumImpl","min","minimum","Minimum","minimumConfig","multiplyImpl","multiplyComplexImpl","multiply","Multiply","multiplyConfig","negImpl","xShape","xDtype","minusOne","createScalarValue","negConfig","Neg","res","notEqualImpl","notEqual","NotEqual","notEqualConfig","transposeImpl","perm","xRank","xStrides","newStrides","newLoc","i_1","transpose","transposeConfig","Transpose","prodImpl","reductionAxes","reduceShape","outDtype","upcastType","prod_1","prodConfig","Prod","axis","keepDims","axes","parseAxisParam","permutation","getAxesPermutation","permutedX","intermediateTensorInfos","getInnerMostAxes","expandShapeToKeepDim","RowPartitionType","shapeShape","valuesShape","valuesDType","defaultValue","defaultValueShape","rowPartitionValues","rowPartitionValuesShapes","rowPartitionTypeStrings","rowPartitionTypes","getRowPartitionTypesHelper","raggedRank","getRaggedRank","RaggedTensorToTensorOp","dimension","FIRST_DIM_SIZE","rowPartitionTensor","getRowPartitionTensor","getRowPartitionTypeByDimension","VALUE_ROWIDS","getMaxWidthValueRowID","ROW_SPLITS","getMaxWidthRowSplit","rowSplit","tensorLength","maxWidth","currentWidth","valueRowIds","indexLength","firstEqualIndex","firstEqualIndexValue","tShape","isPartial","makeShape","firstDim","valueShape","validateDefaultValueShape","tensorShapeFromTensor","combineRaggedTensorToTensorShapes","getMaxWidth","firstDimension","outputIndexMultiplier","firstDimensionOutput","minDimension","currentOutputIndex","parentOutputIndex","outputSize","rowSplitSize","rowLength","realLength","parentOutputIndexCurrent","indexSize","currentOutputColumn","currentValueRowId","nextValueRowId","partitionType","calculateOutputIndexValueRowID","calculateOutputIndexRowSplit","firstPartitionTensor","firstPartitionType","getFirstDimensionSize","calculateOutputSize","multiplier","outputShape","outputTensor","outputIndex","calculateFirstParentOutputIndex","calculateOutputIndex","setOutput","valuesBase","outputBase","elementShape","valueElementSize","outputIndexSize","srcShape_1","tidy","defaultValueTensor","reshape","bCastDefault","broadcastTo","dataSync","srcStart","dstStart","dstEnd","srcI","dstI","src","subarray","copyArray","fill","dst","out","shape_1","tslib_1.__values","raggedTensorToTensorImpl","shapesShape","compute","rangeImpl","numElements","rsqrtImpl","sqrt","rsqrt","Rsqrt","rsqrtConfig","scatterImpl","indices","updates","numUpdates","sumDupeIndices","flattenShape","updatesData","rank","sigmoidImpl","sigmoid","Sigmoid","sigmoidConfig","sliceImpl","begin","isContinous","slice_util","isSliceContinous","flatOffset","computeFlatOffset","inBuf","outLoc","inLoc","idx","fromStringArrayToUint8","$begin","$size","assertParamsValid","sliceConfig","Slice","sparseFillEmptyRowsImpl","indicesShape","indicesDType","denseShape","indicesCount","denseRows","emptyRowIndicator","reverseIndexMap","getSparseFillEmptyRowsIndicesDenseShapeMismatch","outputIndices","outputValues","rowsAreOrdered","lastIndicesRow","csrOffset","getSparseFillEmptyRowsNegativeIndexErrorMessage","getSparseFillEmptyRowsOutOfRangeIndexErrorMessage","allRowsFull","rowEmpty","fullIndicesCount","filledCount","outputI","startingIndex","sparseReshapeImpl","inputIndices","inputIndicesShape","inputDType","inputShape","targetShape","denseSize","nnz","outputRank","product","unknownIndex","getSparseReshapeMultipleNegativeOneOutputDimErrorMessage","getSparseReshapeNegativeOutputDimErrorMessage","getSparseReshapeEmptyTensorZeroOutputDimErrorMessage","missing","trunc","getSparseReshapeInputOutputMultipleErrorMessage","getSparseReshapeInputOutputMismatchErrorMessage","inputRank","inputStrides","outputStrides","newIndices","sparseSegmentReductionImpl","segmentIds","isMean","numIndices","inputFlat","numCol","outputRows","getSparseSegmentReductionNegativeSegmentIdsErrorMessage","outputLength","reduce","output","end","uninitializedIndex","outIndex","nextIndex","getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage","getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage","getSparseSegmentReductionIndicesOutOfRangeErrorMessage","sqrtImpl","Sqrt","sqrtConfig","squaredDifferenceImpl","diff","squaredDifference","SquaredDifference","squaredDifferenceConfig","stridedSliceImpl","separator","nGramWidths","leftPad","rightPad","padWidth","preserveShortSequences","preserveShort","StringNGramsOp","nGramWidth","getPadWidth","splitIndex","outputStartIndex","numNGrams","nGramIndex","this_1","leftPadding","rightPadding","numTokens","dataStartIndex","nGramSize","Uint8Array","nGram","nextNGramIndex","appendToNGram","str","splits","inputDataSize","splitsSize","prevSplit","validSplits","numBatchItems","nGramsSplits","empty","this_2","getNumNGrams","nGrams","outputStartIdx","this_3","createNGrams","dataLength","stringNGramsImpl","dataSplits","split","delimiters","skipEmpty","tokenStart","indexOf","token","delimiter","stringSplitImpl","batchSize","tokens","maxNumEntries","prevTokensLength","nEntries","c","stringToHashBucketFastImpl","numBuckets","fingerPrint64","modulo","getLowBitsUnsigned","subImpl","subComplexImpl","sub","Sub","subConfig","tileImpl","reps","comparePair","valueDiff","select","array","left","right","z","sd","sign","swap","topKImpl","sorted","lastDim","batch","allTopKVals","allTopKIndices","valAndInd","sort","outOffset","topKVals","topKIndices","uniqueImpl","$axis","uniqueElements","inputBuffer","TensorBuffer","uniqueIndices","is1DTensor","element","toString","axisValues","join","undefined","uniqueIndex","keys","outputTmpShape","outputBuffer","uniqueElementIndex","elu","Elu","eluConfig","leakyRelu","alpha","leakyReluConfig","LeakyRelu","preluImpl","xValue","prelu","preluConfig","Prelu","relu","Relu","reluConfig","relu6","Relu6","relu6Config","applyActivation","activation","preluActivationWeights","leakyreluAlpha","$shape","inferFromImplicitShape","$xSize","xData","reshapeConfig","Reshape","batchMatMul","transposeA","transposeB","innerShapeA","innerShapeB","outerShapeA","outerShapeB","outerDimsA","outerDimsB","batchDimA","batchDimB","broadcast_util","b3dShape","a3d","b3d","sharedDim","leftDim","rightDim","batchDim","a3dValues","b3dValues","a3dStrides","b3dStrides","aBatch","aOuterStep","aInnerStep","bInnerStep","bOuterStep","bBatch","resVals","blockSize","bi","i0","j0","k0","iBlock","jBlock","kBlock","sum","batchOffsetA","batchOffsetB","batchMatMulConfig","BatchMatMul","_fusedMatMulConfig","_FusedMatMul","current","addRes","activationRes","bias","intermediates","intermediates_1","acos","Acos","acosConfig","acosh","Acosh","acoshConfig","addNConfig","AddN","tensors","currVals","allConfig","All","origAxes","permutedAxes","$x","assertAxesAreInnerMostDims","all_1","reshapedResult","anyConfig","Any","anyVal","argMaxConfig","ArgMax","outSize","maxIndex","argMinConfig","ArgMin","minIndex","asin","Asin","asinConfig","asinh","Asinh","asinhConfig","atan","Atan","atanConfig","atan2Impl","atan2","Atan2","atan2Config","atanh","Atanh","atanhConfig","pool","xValues","convInfo","poolType","strideHeight","strideWidth","dilationHeight","dilationWidth","effectiveFilterHeight","effectiveFilterWidth","padTop","padInfo","top","padLeft","initialValue","NEGATIVE_INFINITY","POSITIVE_INFINITY","outputVals","outputBatchStrides","outputRowStrides","outputColStrides","outputBatchOffset","inputBatchOffset","inChannels","yR","outHeight","xRCorner","xRMin","xRMax","inHeight","outputRowOffset","yC","outWidth","xCCorner","xCMin","xCMax","inWidth","minMaxValue","avgValue","count","xR","xROffset","xC","pixel","maxPoolPositions","flattenPositions","includeBatchInIndex","maxPositions","maxValue","maxPosition","wR","wC","pool3d","strideDepth","dilationDepth","effectiveFilterDepth","padFront","front","outputDepthStrides","channel","yDepth","outDepth","xDepthCorner","xDepthMin","xDepthMax","inDepth","outputDepthOffset","yRow","xRowCorner","xRowMin","xRowMax","yCol","xColCorner","xColMin","xColMax","outputColOffset","xDepth","xDepthOffset","xRow","xRowOffset","xCol","avgPoolConfig","AvgPool","filterSize","pad","dimRoundingMode","eitherStridesOrDilationsAreOne","computePool2DInfo","filterWidth","filterHeight","arraysEqual","inShape","strides_1","avgPool3DConfig","AvgPool3D","dataFormat","computePool3DInfo","avgPool3DGradConfig","AvgPool3DGrad","dy","filterDepth","dx","avgMultiplier","dyBuf","bufferSync","dxDepth","dxRow","dxCol","dyDepthCorner","dyRowCorner","dyColCorner","dotProd","wDepth","dyDepth","wRow","dyRow","wCol","dyCol","avgPoolGradConfig","AvgPoolGrad","dyData","dxR","dxC","dyRCorner","dyCCorner","dyR","dyC","batchNormConfig","FusedBatchNorm","scale","mean","variance","varianceEpsilon","mVals","varVals","sVals","offVals","offValsLength","sValsLength","varValsLength","mValsLength","offi","mi","si","vi","batchToSpaceNDConfig","BatchToSpaceND","blockShape","crops","prod","reshaped","getReshaped","permuted","getPermuted","reshapedPermuted","getReshapedPermuted","sliceBeginCoords","getSliceBeginCoords","getSliceSize","xReshaped","xTransposed","xTransposedReshaped","bincountConfig","Bincount","weights","broadcastArgsConfig","BroadcastArgs","s0","s1","s0Vals","s1Vals","broadcastShape","clipByValue","ClipByValue","clipAttrs","clipValueMax","clipValueMin","clipByValueConfig","complexAbsConfig","ComplexAbs","complexVals","real_1","imag_1","hypot","imagVal","imagConfig","Imag","computeOutShape","$inputs","filter","shapes","assertParamsConsistent","reals","imags","realConcated","imagConcated","inputs2D","innerSize","inputsValShapes","finalOutShape","outInfo","concatConfig","Concat","conv2D","dilations","$dataFormat","convertConv2DDataFormat","computeConv2DInfo","isChannelsLast","filterStrides","xBatchStride","xRowStride","xColStride","xChannelStride","yBatchStride","yRowStride","yColStride","yChannelStride","wVals","yVals","xOffset1","yOffset1","yOffset2","wOffset1","xOffset2","yOffset3","xOffset3","wOffset3","d1","xVal","d2","outChannels","conv2DConfig","Conv2D","conv2DBackpropFilterConfig","Conv2DBackpropFilter","filterShape","dW","topPad","dyVals","yRMin","yRMax","yCMin","yCMax","conv2DBackpropInputConfig","Conv2DBackpropInput","dyStrides","dxValues","dyValues","fltValues","fltS0","fltS1","fltS2","dyOffset","fltOffset","conv3DConfig","Conv3D","computeConv3DInfo","yF","xFCorner","wF","xF","wOffset2","yOffset4","xOffset4","wOffset4","conv3DBackpropFilterV2Config","Conv3DBackpropFilterV2","dw","dwValues","dwS0","dwS1","dwS2","dwS3","dyS0","dyS1","dyS2","dyS3","xS0","xS1","xS2","xS3","frontPad","yFMin","yFMax","conv3DBackpropInputV2Config","Conv3DBackpropInputV2","dxS0","dxS1","dxS2","dxS3","fltS3","xFMin","cos","Cos","cosConfig","cosh","Cosh","coshConfig","cropAndResizeConfig","CropAndResize","image","boxes","boxInd","cropSize","method","extrapolationValue","imageHeight","imageWidth","numChannels","numBoxes","cropHeight","cropWidth","boxVals","boxIndVals","imageVals","inStride","outStride","startInd","y1","x1","y2","x2","bInd","heightScale","widthScale","yInd","ind","topInd","bottomInd","yLerp","xInd","leftInd","rightInd","xLerp","topLeft","topRight","bottomLeft","bottom","closestX","round","closestY","inInd","outInd","cumprodConfig","Cumprod","exclusive","reverse","permutedAxis","resultDtype","makeOnesTypedArray","finalDim","indexAdjuster","prevIdx","reverseTransposedResult","getUndoAxesPermutation","cumsumConfig","Cumsum","denseBincountConfig","DenseBincount","depthToSpaceConfig","DepthToSpace","inputHeight","inputWidth","inputDepth","outputHeight","outputWidth","outputDepth","outputIdx","h","inH","offsetH","w","inW","offsetD","inputIdx","depthwiseConv2dNative","$dilations","chMul","q","depthwiseConv2dNativeConfig","DepthwiseConv2dNative","depthwiseConv2dNativeBackpropFilterConfig","DepthwiseConv2dNativeBackpropFilter","dm","depthwiseConv2dNativeBackpropInputConfig","DepthwiseConv2dNativeBackpropInput","diagConfig","Diag","dilation2DConfig","Dilation2D","filterVals","filterRank","outRank","hOut","hBeg","wOut","wBeg","curVal","MIN_SAFE_INTEGER","hIn","wIn","xIndex","filterIndex","val","dilation2DBackpropFilterConfig","Dilation2DBackpropFilter","toNestedArray","$filter","$dy","gradients","makeZerosNestedTypedArray","hMax","wMax","dilation2DBackpropInputConfig","Dilation2DBackpropInput","hInMax","wInMax","sum_1","oldResult","sumConfig","Sum","einsumConfig","Einsum","equation","allDims","summedDims","idDims","checkEinsumDimSizes","_d","path","steps","nSteps","numDimsRemaining","tensorsToDispose","_e","idTerm","_g","dimsToExpand","isIdentityPermutation","splice","tensorsToDispose_1","eluGradConfig","EluGrad","ERF_P","a1","ERF_A1","a2","ERF_A2","a3","ERF_A3","a4","ERF_A4","a5","ERF_A5","erf","Erf","erfConfig","expandDims","$dim","expandDimsConfig","ExpandDims","realDivImpl","div","RealDiv","realDivConfig","fftBatch","inverse","innerDim","inputVals","real2D","imag2D","input_1","getComplexWithIndex","$realInfo","$imagInfo","fftImpl","inputSize","fftRadix2","realInfo","imagInfo","sizeInfo","sizeInfoCopy","divRealInfo","divImagInfo","divRealVals","divImagVals","rawOutput","ret","real_2","imag_2","exponent","term","assignToTypedArray","fourierTransformByMatmul","splitRealAndImagArrays","half","evenComplex","complexWithEvenIndex","evenRealVals","evenImagVals","evenShape","evenRealInfo","evenImagInfo","evenTensorInfo","oddComplex","complexWithOddIndex","oddRealVals","oddImagVals","oddShape","oddRealInfo","oddImagInfo","oddTensorInfo","$evenComplex","$evenRealVals","$evenImagVals","$evenShape","$evenRealInfo","$evenImagInfo","$evenTensorInfo","$oddComplex","$oddRealVals","$oddImagVals","$oddShape","$oddRealInfo","$oddImagInfo","$oddTensorInfo","exponents","eShape","eRealInfo","eImagInfo","exponentInfo","addPart","subPart","addPartReal","subPartReal","addPartImag","subPartImag","$real","$imag","$realVals","$imagVals","fftConfig","FFT","innerDimensionSize","input2D","resultReshaped","inferDtype","fillValues","fillConfig","Fill","flipLeftRightConfig","FlipLeftRight","batchOffset","rowOffset","colOffset","coordX","outIdx","outputValue","floorDivImpl","floorDiv","FloorDiv","floorDivConfig","fusedConv2DConfig","FusedConv2D","resultOld","reshapedBias","reshapedAlpha","fusedDepthwiseConv2DConfig","FusedDepthwiseConv2D","gatherNdConfig","GatherNd","params","gatherV2Config","GatherV2","batchDims","parsedAxis","indicesVals","axisDim","$batchDims","indicesSize","shapeInfo","segment_util","collectGatherOpShapeInfo","flattenX","outerSize","dimSize","ifftConfig","IFFT","isFinite","IsFinite","isFiniteConfig","isInf","IsInf","Infinity","isInfConfig","IsNan","isNaNConfig","linSpaceConfig","LinSpace","log1p","Log1p","log1pConfig","logicalAndImpl","logicalAnd","LogicalAnd","logicalAndConfig","logicalNot","LogicalNot","logicalNotConfig","logicalOrImpl","logicalOr","LogicalOr","logicalOrConfig","LRNConfig","LRN","depthRadius","beta","channels","maxD","sumAcrossChannels","currentChannel","beginSumOffset","endSumOffset","pow","LRNGradConfig","LRNGrad","dySize","yValues","depthBegin","depthEnd","norm","dyi","reductionIndices","maxOutShape","maxConfig","Max","maxPoolConfig","MaxPool","maxPool3DConfig","MaxPool3D","maxPool3DGradConfig","MaxPool3DGrad","maxPosBuf","maxPool3dPositions","mask","maxPoolGradConfig","MaxPoolGrad","maxPoolWithArgmaxConfig","MaxPoolWithArgmax","maxPools","pooled","indexes","pooledDataId","indexesDataId","meanConfig","Mean","computeOutAndReduceShapes","toDispose","reduceSizeScalar","minConfig","Min","min_1","mirrorPadConfig","MirrorPad","paddings","mode","coords","inIndex","modImpl","rem","mod","Mod","modConfig","softmax","logits","logitsRank","maxLogit","expandedShape","maxLogitReshaped","sumExp","sumReshaped","softmaxConfig","Softmax","multinomialConfig","Multinomial","numSamples","seed","normalized","probabilities","numEvents","probVals","resShape","cdf","event","random","seedrandom","alea","sampleId","nonMaxSuppressionV3Impl","nonMaxSuppressionV3Config","NonMaxSuppressionV3","scores","maxOutputSize","iouThreshold","scoreThreshold","boxesVals","scoresVals","selectedIndices","nonMaxSuppressionV4Impl","nonMaxSuppressionV4Config","NonMaxSuppressionV4","padToMaxOutputSize","validOutputs","nonMaxSuppressionV5Impl","nonMaxSuppressionV5Config","NonMaxSuppressionV5","softNmsSigma","selectedScores","oneHotConfig","OneHot","depth","onValue","offValue","indicesVal","zerosLike","imagPart","zerosLikeConfig","ZerosLike","onesLikeConfig","OnesLike","onesLike","pack","assertShapesMatch","expandedT","packConfig","Pack","padV2Config","PadV2","constantValue","outCoords","powImpl","Pow","powConfig","raggedTensorToTensorConfig","RaggedTensorToTensor","rowPartitionTensors","$values","$defaultValue","$rowPartitionValues","rangeConfig","Range","reciprocal","Reciprocal","reciprocalConfig","resizeBilinearConfig","ResizeBilinear","images","alignCorners","halfPixelCenters","imagesStrides","newHeight","newWidth","oldHeight","oldWidth","effectiveInputSize","effectiveOutputSize","effectiveRowSizeRatio","effectiveColSizeRatio","sourceFracRow","sourceRowFloor","rowFrac","sourceRowCeil","topRowOffset","botRowOffset","sourceFracCol","sourceColFloor","colFrac","sourceColCeil","topLeftOffest","botLeftOffset","topRightOffset","botRightOffest","newValue","resizeBilinearGradConfig","ResizeBilinearGrad","xHeight","xWidth","yHeight","yWidth","effectiveXSize","effectiveYSize","bOffset","topDxRIndex","bottomDxRIndex","topDxROffset","bottomDxROffset","dxRLerp","inverseDxRLerp","leftDxCIndex","rightDxCIndex","dxCLerp","inverseDxCLerp","topLeftRCOffset","topRightRCOffset","bottomLeftRCOffset","bottomRightRCOffset","inverseDxRLerpTimesInverseDxCLerp","inverseDxRLerpTimesDxCLerp","dxRLerpTimesInverseDxCLerp","dxRLerpTimesDxCLerp","dyVal","resizeNearestNeighborConfig","ResizeNearestNeighbor","outputOffset","sourceNearestRow","sourceNearestCol","newVal","resizeNearestNeighborGradConfig","ResizeNearestNeighborGrad","invHeightScale","invWidthScale","winHeight","winWidth","startRLerp","startDyR","startCLerp","startDyC","accum","dyRIndex","dyROffset","dyCIndex","dyCOffset","reverseConfig","Reverse","dims","$dims","rotateWithOffsetConfig","RotateWithOffset","radians","fillValue","center","centerX","centerY","sinFactor","sin","cosFactor","coordY","Round","base","roundConfig","scatterNdConfig","ScatterNd","lowerBound","mid","upperBound","searchSortedConfig","SearchSorted","sortedSequence","side","sortedInputs","numInputs","numValues","sortedInputsSlice","searchSortedImpl","selectConfig","Select","conditionRank","tValues","eValues","scaleAlpha","SELU_SCALEALPHA","SELU_SCALE","selu","Selu","seluConfig","Sign","signConfig","Sin","sinConfig","sinh","Sinh","sinhConfig","threshold","softplus","Softplus","tooLarge","tooSmall","expX","softplusConfig","spaceToBatchNDConfig","SpaceToBatchND","completePaddings","paddedX","reshapedPaddedShape","permutedReshapedPaddedPermutation","paddedXReshaped","paddedXT","sparseFillEmptyRowsConfig","SparseFillEmptyRows","$indices","$denseShape","outputIndicesShape","sparseReshapeConfig","SparseReshape","$inputShape","$inputIndices","sparseSegmentMeanConfig","SparseSegmentMean","$data","$segmentIds","outputData","outputDataShape","sparseSegmentSumConfig","SparseSegmentSum","sparseToDenseConfig","SparseToDense","sparseIndices","sparseValues","Boolean","splitVConfig","SplitV","numOrSizeSplits","splitSizes","prepareSplitSize","sliceT","squareConfig","Square","Step","stepAttrs","NaN","stepConfig","stridedSliceConfig","StridedSlice","beginMask","endMask","ellipsisMask","newAxisMask","shrinkAxisMask","finalShapeSparse","finalShape","isIdentity","sliceDim0","isSimpleSlice","$end","$strides","sliced","stringNGramsConfig","StringNGrams","stringSplitConfig","StringSplit","stringToHashBucketFastConfig","StringToHashBucketFast","tan","Tan","tanConfig","tanh","Tanh","tanhConfig","tileConfig","Tile","topKConfig","TopK","transformConfig","Transform","transforms","interpolation","fillMode","inStrides","batchInStride","rowInStride","colInStride","outStrides","batchOutStride","rowOutStride","colOutStride","transformVals","transform_1","outY","outX","projection","inX","inY","mapCoord","nearestInterpolation","bilinearInterpolation","outCoord","len","inCoord","sz2","clamp","mapCoordReflect","sz","mapCoordWrap","mapCoordNearest","mapCoordConstant","readWithFillValue","batchStride","rowStride","colStride","yFloor","xFloor","yCeil","xCeil","uniqueConfig","Unique","unpackConfig","Unpack","valueRank","tempRes","unsortedSegmentSumConfig","UnsortedSegmentSum","numSegments","numIters","expanded","scalarValue","segmentId","maskCasted","mul","sumTensorInfo","kernelConfigs","kernelConfigs_1","kernelConfig","registerKernel"],"mappings":";;;;;;;;;;;;;;;;6nBAgBIA,EAAgB,SAASC,EAAGC,GAI5B,OAHAF,EAAgBG,OAAOC,gBAClB,CAAEC,UAAW,cAAgBC,OAAS,SAAUL,EAAGC,GAAKD,EAAEI,UAAYH,IACvE,SAAUD,EAAGC,GAAK,IAAK,IAAIK,KAAKL,EAAOC,OAAOK,UAAUC,eAAeC,KAAKR,EAAGK,KAAIN,EAAEM,GAAKL,EAAEK,KACzFP,EAAcC,EAAGC,EAC5B,WAgDgBS,EAAUC,EAASC,EAAYC,EAAGC,GAE9C,OAAO,IAAKD,IAAMA,EAAIE,WAAU,SAAUC,EAASC,GAC/C,SAASC,EAAUC,GAAS,IAAMC,EAAKN,EAAUO,KAAKF,IAAW,MAAOG,GAAKL,EAAOK,IACpF,SAASC,EAASJ,GAAS,IAAMC,EAAKN,EAAiB,MAAEK,IAAW,MAAOG,GAAKL,EAAOK,IACvF,SAASF,EAAKI,GAJlB,IAAeL,EAIaK,EAAOC,KAAOT,EAAQQ,EAAOL,QAJ1CA,EAIyDK,EAAOL,MAJhDA,aAAiBN,EAAIM,EAAQ,IAAIN,GAAE,SAAUG,GAAWA,EAAQG,OAITO,KAAKR,EAAWK,GAClGH,GAAMN,EAAYA,EAAUa,MAAMhB,EAASC,GAAc,KAAKS,UAEtE,UAEgBO,EAAYjB,EAASkB,GACjC,IAAsGC,EAAGC,EAAGC,EAAGC,EAA3GC,EAAI,CAAEC,MAAO,EAAGC,KAAM,WAAa,GAAW,EAAPJ,EAAE,GAAQ,MAAMA,EAAE,GAAI,OAAOA,EAAE,IAAOK,KAAM,GAAIC,IAAK,IAChG,OAAOL,EAAI,CAAEZ,KAAMkB,EAAK,GAAIC,MAASD,EAAK,GAAIE,OAAUF,EAAK,IAAwB,mBAAXG,SAA0BT,EAAES,OAAOC,UAAY,WAAa,OAAOC,OAAUX,EACvJ,SAASM,EAAKM,GAAK,OAAO,SAAUC,GAAK,OACzC,SAAcC,GACV,GAAIjB,EAAG,MAAM,IAAIkB,UAAU,mCAC3B,KAAOd,OACH,GAAIJ,EAAI,EAAGC,IAAMC,EAAY,EAARe,EAAG,GAAShB,EAAU,OAAIgB,EAAG,GAAKhB,EAAS,SAAOC,EAAID,EAAU,SAAMC,EAAEvB,KAAKsB,GAAI,GAAKA,EAAEV,SAAWW,EAAIA,EAAEvB,KAAKsB,EAAGgB,EAAG,KAAKtB,KAAM,OAAOO,EAE3J,OADID,EAAI,EAAGC,IAAGe,EAAK,CAAS,EAARA,EAAG,GAAQf,EAAEb,QACzB4B,EAAG,IACP,KAAK,EAAG,KAAK,EAAGf,EAAIe,EAAI,MACxB,KAAK,EAAc,OAAXb,EAAEC,QAAgB,CAAEhB,MAAO4B,EAAG,GAAItB,MAAM,GAChD,KAAK,EAAGS,EAAEC,QAASJ,EAAIgB,EAAG,GAAIA,EAAK,CAAC,GAAI,SACxC,KAAK,EAAGA,EAAKb,EAAEI,IAAIW,MAAOf,EAAEG,KAAKY,MAAO,SACxC,QACI,KAAMjB,EAAIE,EAAEG,MAAML,EAAIA,EAAEkB,OAAS,GAAKlB,EAAEA,EAAEkB,OAAS,KAAkB,IAAVH,EAAG,IAAsB,IAAVA,EAAG,IAAW,CAAEb,EAAI,EAAG,SACjG,GAAc,IAAVa,EAAG,MAAcf,GAAMe,EAAG,GAAKf,EAAE,IAAMe,EAAG,GAAKf,EAAE,IAAM,CAAEE,EAAEC,MAAQY,EAAG,GAAI,MAC9E,GAAc,IAAVA,EAAG,IAAYb,EAAEC,MAAQH,EAAE,GAAI,CAAEE,EAAEC,MAAQH,EAAE,GAAIA,EAAIe,EAAI,MAC7D,GAAIf,GAAKE,EAAEC,MAAQH,EAAE,GAAI,CAAEE,EAAEC,MAAQH,EAAE,GAAIE,EAAEI,IAAIa,KAAKJ,GAAK,MACvDf,EAAE,IAAIE,EAAEI,IAAIW,MAChBf,EAAEG,KAAKY,MAAO,SAEtBF,EAAKlB,EAAKpB,KAAKE,EAASuB,GAC1B,MAAOZ,GAAKyB,EAAK,CAAC,EAAGzB,GAAIS,EAAI,UAAeD,EAAIE,EAAI,EACtD,GAAY,EAARe,EAAG,GAAQ,MAAMA,EAAG,GAAI,MAAO,CAAE5B,MAAO4B,EAAG,GAAKA,EAAG,QAAK,EAAQtB,MAAM,GArB9BL,CAAK,CAACyB,EAAGC,KAuB7D,UAkBgBM,EAASC,GACrB,IAAIC,EAAsB,mBAAXZ,QAAyBA,OAAOC,SAAUY,EAAID,GAAKD,EAAEC,GAAIE,EAAI,EAC5E,GAAID,EAAG,OAAOA,EAAE9C,KAAK4C,GACrB,GAAIA,GAAyB,iBAAbA,EAAEH,OAAqB,MAAO,CAC1C7B,KAAM,WAEF,OADIgC,GAAKG,GAAKH,EAAEH,SAAQG,OAAI,GACrB,CAAElC,MAAOkC,GAAKA,EAAEG,KAAM/B,MAAO4B,KAG5C,MAAM,IAAIL,UAAUM,EAAI,0BAA4B,kCACxD,UAEgBG,EAAOJ,EAAGR,GACtB,IAAIU,EAAsB,mBAAXb,QAAyBW,EAAEX,OAAOC,UACjD,IAAKY,EAAG,OAAOF,EACf,IAAmBK,EAAYpC,EAA3BkC,EAAID,EAAE9C,KAAK4C,GAAOM,EAAK,GAC3B,IACI,WAAc,IAANd,GAAgBA,KAAM,MAAQa,EAAIF,EAAEnC,QAAQI,MAAMkC,EAAGR,KAAKO,EAAEvC,OAExE,MAAOyC,GAAStC,EAAI,CAAEsC,MAAOA,WAEzB,IACQF,IAAMA,EAAEjC,OAAS8B,EAAIC,EAAU,SAAID,EAAE9C,KAAK+C,WAExC,GAAIlC,EAAG,MAAMA,EAAEsC,OAE7B,OAAOD,CACX,UAGgBE,IACZ,IAAK,IAAIF,EAAK,GAAIH,EAAI,EAAGA,EAAIM,UAAUZ,OAAQM,IAC3CG,EAAKA,EAAGI,OAAON,EAAOK,UAAUN,KACpC,OAAOG,CACX,UC1IgBK,EACZC,EAAiCC,GAC9B7D,MAAM8D,QAAQF,KACjBA,EAAS,CAACA,IAEZA,EAAOG,SAAQ,SAAApC,GACJ,MAALA,GACFqC,OAAKC,OACW,cAAZtC,EAAEuC,OACF,WAAM,OACFL,iEAGd,CCbA,IAAMM,EAAYC,eAAaD,wBA2B7B,aAAA,MACEE,0BAVKC,YAAY,GAGXA,YAAW,EAQjBA,EAAKC,KAAO,IAAIC,cAAYF,EAAMG,8BFzBZ9E,EAAGC,GACzB,GAAiB,mBAANA,GAA0B,OAANA,EAC3B,MAAM,IAAI+C,UAAU,uBAAyB+B,OAAO9E,GAAK,iCAE7D,SAAS+E,IAAOpC,KAAKqC,YAAcjF,EADnCD,EAAcC,EAAGC,GAEjBD,EAAEO,UAAkB,OAANN,EAAaC,OAAOgF,OAAOjF,IAAM+E,EAAGzE,UAAYN,EAAEM,UAAW,IAAIyE,EACnF,CEOoCG,MAM1BC,uBAAA,WACN,OAAOA,EAAeC,cAQxBD,kBAAA,SAAME,EAAoCC,EAAiBhB,GAErD3B,KAAK4C,WACP5C,KAAK4C,UAAW,EACZC,QAAMC,IAAI,YACZC,eAAaC,KACT,uPAOR,IAAMC,EAAS,CAACC,GAAIlD,KAAKyC,cAIzB,OAFAzC,KAAKgC,KAAKmB,IAAIF,EAAQ,CAACP,SAAQf,QAAOyB,SAAU,IAEzCH,GASTT,2BAAA,SACIG,EAAiBhB,EACjBe,GACF,IAAIW,EACJ,GAAc,WAAV1B,GAAgC,MAAVe,GAAkBA,EAAOpC,OAAS,GACxDmB,OAAK6B,SAASZ,EAAO,IAAK,CAC5B,IAAMa,EACDb,EAA0Bc,KAAI,SAAApG,GAAK,OAAAqE,OAAKgC,aAAarG,MAE1DiG,EAAQrD,KAAK0D,MAAMH,EAAeZ,EAAOhB,QAEzC0B,EAAQrD,KAAK0D,MAAMhB,EAAsBC,EAAOhB,GAGlD,MAAO,CAACsB,OAAQI,EAAOV,QAAOhB,UAIhCa,qBAAA,SAASS,GACP,OAAIjD,KAAKgC,KAAK2B,IAAIV,GACGjD,KAAKgC,KAAKc,IAAIG,GACfG,SAEb,GAITZ,mBAAA,SAAOS,GACcjD,KAAKgC,KAAKc,IAAIG,GACtBG,YAIbZ,mBAAA,SAAOS,GACDjD,KAAKgC,KAAK2B,IAAIV,IACGjD,KAAKgC,KAAKc,IAAIG,GACtBG,YAIfZ,iBAAA,SACIS,EAAgBP,EAAoCC,EACpDhB,EAAiByB,GACnBpD,KAAKgC,KAAKmB,IAAIF,EAAQ,CAACP,SAAQf,QAAOyB,cAGxCZ,uBAAA,WACE,OAAOxC,KAAKgC,KAAK4B,cAGbpB,iBAAN,SAAWS,sEACT,SAAOjD,KAAK6D,SAASZ,WAEvBT,qBAAA,SAASS,GACD,IAAAa,mBAACnC,UAAOoC,uBAEd,GAAc,cAAVpC,EAAuB,CACzB,IAAMqC,EACFhE,KAAK6D,SAASE,EAAmBE,KAAKhB,QACpCiB,EACFlE,KAAK6D,SAASE,EAAmBI,KAAKlB,QAC1C,OAAOF,eAAaqB,uBAAuBJ,EAAYE,GAGzD,OAAOlE,KAAKgC,KAAKc,IAAIG,GAAQP,QAG/BF,uBAAA,SAA+CpD,GAE7C,IAAM4C,EAAOhC,KAAK6D,SAASzE,EAAE6D,QAC7B,GAAgB,WAAZ7D,EAAEuC,MACJ,IAEE,IAAM0C,EAAWrC,EAAsBwB,KAAI,SAAApG,GAAK,OAAAqE,OAAK6C,aAAalH,MAClE,OAAOmH,SAAOnF,EAAEuD,MAAsBvD,EAAEuC,MAAO0C,GAE/C,SACA,MAAM,IAAIG,MAAM,oDAGpB,OAAOD,SAAOnF,EAAEuD,MAAsBvD,EAAEuC,MAAOK,IAIjDQ,uBAAA,SACIE,EAAoCC,EAAiBhB,GACvD,OAAOO,WAASuC,yBACLzE,KAAK0E,eAAe/B,EAAOhB,EAAOe,GAAS1C,OAUxDwC,wBAAA,SAAYS,EAAgB0B,GAC1B,gBAD0BA,MACtB3E,KAAKgC,KAAK2B,IAAIV,GAAS,CAEzB,GADAjD,KAAKgC,KAAKc,IAAIG,GAAQG,YACjBuB,GAAS3E,KAAKgC,KAAKc,IAAIG,GAAQG,SAAW,EAC7C,OAAO,EAGF,IAAAW,sCAEmB,MAAtBA,IACF/D,KAAK4E,YAAYb,EAAmBE,KAAKhB,QAAQ,GACjDjD,KAAK4E,YAAYb,EAAmBI,KAAKlB,QAAQ,IAGnDjD,KAAKgC,KAAK6C,OAAO5B,GAEnB,OAAO,GAGTT,0CAAA,SAA8BsC,GAC5B9E,KAAK4E,YAAYE,EAAW7B,SAGxBT,iBAAN,SAAWtD,4EAIT,OAHM6F,EAAQtD,OAAKuD,MACnB9F,OAEO,CAAC+F,SADSxD,OAAKuD,MAAQD,WAIhCvC,mBAAA,WACE,MAAO,CAEL0C,YAAY,EACZC,QACI,CAAC,wHAKT3C,kBAAA,SAAM4C,GACJhE,EAAiB,CAACgE,GAAY,SAE9B,IAAMC,EAAWrF,KAAK6D,SAASuB,EAAUnC,QACzC,OAAOrB,EAAUwD,EAAUzC,MAAO0C,IAGpC7C,oBAAA,aAEAA,2BAAA,WACE,OAAO,IAITA,oBAAA,WACE,OAAOV,YAAMwD,uBAjMmBC,0BCdpBC,EAAcC,GAE5B,IADA,IAAMC,EAAe,IAAIC,aAAaF,EAAKnF,QAClCM,EAAI,EAAGA,EAAI6E,EAAKnF,SAAUM,EACjC8E,EAAa9E,GAAKgF,KAAKC,IAAIJ,EAAK7E,IAElC,OAAO8E,CACT,CDaiBlD,aAAa,ECXvB,IAaMsD,EAA0B,CACrCC,WAAYC,MACZC,YAAa,MACbC,WAhBiB,SAACC,GACX,IAAAC,aACDC,EAAaF,EAAKG,QAExBlF,EAAiBgF,EAAG,OAEpB,IAAIV,EAAe,IAAIC,aAAalE,OAAK8E,cAAcH,EAAEzD,QAIzD,OAFA+C,EAAeF,EADAa,EAAWrE,KAAKc,IAAIsD,EAAEnD,QAAQP,QAGtC2D,EAAWG,WAAWd,EAAcU,EAAEzD,MAAOyD,EAAEzE,MACxD,YCjBgB8E,EAA6BtG,GAE3C,OAAO,SAACuG,EAAkBC,EAAkBC,EACpCC,EAAmBlF,GACzB,IAAMmF,EAAW/D,eAAagE,2BAA2BL,EAAQC,GAE3DK,EAAaF,EAASxG,OACtB2G,EAAgBxF,OAAKyF,eAAeJ,GACpCK,EAAa1F,OAAK8E,cAAcO,GAEhClI,EACF6C,OAAK2F,uBAAuBzF,EAA0BwF,GAEpDE,EAAQX,EAAOpG,OACfgH,EAAQX,EAAOrG,OAEfiH,EAAW9F,OAAKyF,eAAeR,GAC/Bc,EAAW/F,OAAKyF,eAAeP,GAE/Bc,EAAiB1E,eAAa2E,iBAAiBhB,EAAQI,GACvDa,EAAiB5E,eAAa2E,iBAAiBf,EAAQG,GAE7D,GAAIW,EAAenH,OAASqH,EAAerH,SAAW,EACpD,IAAK,IAAIM,EAAI,EAAGA,EAAIhC,EAAO0B,SAAUM,EACnChC,EAAOgC,GAAKT,EAAGyG,EAAMhG,EAAIgG,EAAMtG,QAASuG,EAAMjG,EAAIiG,EAAMvG,6BAGjDM,GACP,IAAMgH,EAAMnG,OAAKoG,WAAWjH,EAAGoG,EAAYC,GAErCa,EAAOF,EAAIG,OAAOV,GACxBI,EAAejG,SAAQ,SAAApE,GAAK,OAAA0K,EAAK1K,GAAK,KACtC,IAAM4K,EAASvG,OAAKwG,WAAWH,EAAMT,EAAOE,GAEtCW,EAAON,EAAIG,OAAOT,GACxBK,EAAenG,SAAQ,SAAApE,GAAK,OAAA8K,EAAK9K,GAAK,KACtC,IAAM+K,EAAS1G,OAAKwG,WAAWC,EAAMZ,EAAOE,GAE5C5I,EAAOgC,GAAKT,EAAGyG,EAAMoB,GAASnB,EAAMsB,KAXtC,IAASvH,EAAI,EAAGA,EAAIhC,EAAO0B,SAAUM,IAA5BA,GAeX,MAAO,CAAChC,EAAQkI,GAEpB,UC/CgBsB,EAAQjC,GAEf,IAAAkC,WAAQ/B,YACRrC,SAAME,SAEPmE,EAAWhC,EAAQtE,KAAKc,IAAImB,EAAKhB,QAAQP,OACzC6F,EAAWjC,EAAQtE,KAAKc,IAAIqB,EAAKlB,QAAQP,OAEzC8F,EAAclC,EAAQ5B,eAAeT,EAAKtB,MAAO,aAYvD,OAVgB2D,EAAQtE,KAAKc,IAAI0F,EAAYvF,QAKrCc,mBAAqB,CAC3BE,KAAMqC,EAAQ5B,eAAeT,EAAKtB,MAAO,UAAW2F,GACpDnE,KAAMmC,EAAQ5B,eAAeP,EAAKxB,MAAO,UAAW4F,IAG/CC,CACT,CAEO,IAAMC,EAA8B,CACzC1C,WAAY2C,UACZzC,YAAa,MACbC,WAAYkC,YCpBEO,EACZrC,EAAyB3D,EACzBhB,GACF,gBADEA,aACY,cAAVA,EAIF,OAAOyG,EAAQ,CAACC,OAAQ,CAACpE,KAHZ0E,EAAMrC,EAAS3D,EAAO,WAGJwB,KAFlBwE,EAAMrC,EAAS3D,EAAO,YAEG2D,YAGxC,IAAM5D,EAASjB,OAAKmH,oBAAoBnH,OAAK8E,cAAc5D,GAAQhB,GAEnE,OAAO2E,EAAQ5B,eAAe/B,EAAOhB,EAAOe,EAC9C,UCnBgBmG,EACZ1C,GACK,IAAAkC,WAAQ/B,YACRF,MAIP,OAFAE,EAAQwC,OAAO1C,EAAEnD,QAEV,CAACA,OAAQmD,EAAEnD,OAAQN,MAAOyD,EAAEzD,MAAOhB,MAAOyE,EAAEzE,MACrD,CAEO,IAAMoH,EAA+B,CAC1ChD,WAAYiD,WACZ/C,YAAa,MACbC,WAAY2C,YCbE5E,EAAKkC,GAEZ,IAAAkC,WAAQ/B,YACR2C,UAEDhF,EAAOqC,EAAQtE,KAAKc,IAAImG,EAAMhG,QAAQc,mBAAmBE,KACzDiF,EAAU5C,EAAQtE,KAAKc,IAAImB,EAAKhB,QAAQP,OAK9C,OAAO4D,EAAQ5B,eAAeT,EAAKtB,MAAOsB,EAAKtC,MAAOuH,EACxD,CAEO,IAAMC,EAA2B,CACtCpD,WAAYqD,OACZnD,YAAa,MACbC,WAAYjC,YCZEoF,EACZ3G,EAAoBC,EAAiB2G,EACrC3H,GACF,GAAc,UAAVA,EAEF,MAAO,CAACgB,EAAO,QADM4G,WAAWC,KAAK9G,IAIvC,GAAc,SAAVf,EAAkB,CAIpB,IAAM8H,EAAOhI,OAAKiI,aAAa,CAAC,GAAIJ,GAE9BK,6DAACC,OAGP,MAAO,MAAc,OAAQA,GAE/B,MAAM,IAAIpF,MAAM,iCAAiC8E,SAAgB3H,EACnE,UAEgBkI,EACZ1D,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACAzE,UAGP,GAAc,cAAVA,EAAuB,CACzB,GAAgB,cAAZyE,EAAEzE,MACJ,OAAOkH,EAAS,CAACR,OAAQ,CAACjC,KAAIE,YAGhC,IAAMyD,EAAkBpB,EAAMrC,EAASF,EAAEzD,MAAOyD,EAAEzE,OAC5CqI,EAASH,EAAK,CAACxB,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACnI,MAAO,aAEpD/C,EACFwJ,EAAQ,CAACC,OAAQ,CAACpE,KAAM+F,EAAQ7F,KAAM4F,GAAkBzD,YAK5D,OAHAA,EAAQ2D,8BAA8BF,GACtCzD,EAAQ2D,8BAA8BD,GAE/BpL,EAIT,GAAgB,cAAZwH,EAAEzE,MAAuB,CAC3B,IAAMuI,EAAWjG,EAAK,CAACoE,OAAQ,CAACY,MAAO7C,GAAIE,YACrC1H,EAASiL,EAAK,CAACxB,OAAQ,CAACjC,EAAG8D,GAAW5D,UAASwD,MAAO,CAACnI,WAI7D,OAFA2E,EAAQ2D,8BAA8BC,GAE/BtL,EAGT,IAAK6C,OAAK0I,gBAAgB/D,EAAEzE,MAAOA,GAIjC,MAAO,CAACsB,QADFrE,EAASiK,EAAS,CAACR,OAAQ,CAACjC,KAAIE,aACfrD,OAAQN,MAAO/D,EAAO+D,MAAOhB,SAGtD,IACMgI,MADSrD,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,6BACnC0H,OAAaC,OAAYT,OAEhC,OAAOtD,EAAQ5B,eAAe0F,EAAaC,EAAYT,EACzD,CAEO,IAAMU,EAA2B,CACtCvE,WAAYwE,OACZtE,YAAa,MACbC,WAAY2D,YC9DEW,EACZC,EAAcC,EACdC,EAAuChJ,GACzC,OAAmB,MAAfgJ,EACK,SAAChB,OAACtB,WAAQ/B,YACRsE,MAAGvN,MACJgJ,EAAaC,EAEnBlF,EAAiB,CAACwJ,EAAGvN,GAAIoN,GAEzB,IAAM7D,EAAQP,EAAWrE,KAAKc,IAAI8H,EAAE3H,QAAQP,OACtCmE,EAAQR,EAAWrE,KAAKc,IAAIzF,EAAE4F,QAAQP,OAEtCmI,EAA2B,WAAZD,EAAEjJ,MAEnBoB,eAAa+H,uBAAuBlE,GACpCA,EACEmE,EAA2B,WAAZH,EAAEjJ,MAEnBoB,eAAa+H,uBAAuBjE,GACpCA,EACEmE,EAASrJ,GAASiJ,EAAEjJ,MAEpBmC,gCAAC8F,OAAYQ,OAGnB,OAAO/D,EAAW3B,eAAe0F,EAAaY,EAAQpB,IAInD,SAACD,OAACtB,WAAQ/B,YACRsE,MAAGvN,MACJgJ,EAAaC,EAEnB,GAAgB,cAAZsE,EAAEjJ,OAAqC,cAAZtE,EAAEsE,MAAuB,CACtD,IAAMsJ,EAAYpB,EACd,CAACxB,OAAQ,CAACjC,EAAGwE,GAAItE,QAASD,EAAYyD,MAAO,CAACnI,MAAO,eAEnDuJ,EAAgB7E,EAAWrE,KAAKc,IAAImI,EAAUhI,QAE9CkI,EAAQD,EAAcnH,mBAAmBE,KACzCmH,EAAQF,EAAcnH,mBAAmBI,KAEzCkH,EACFhF,EAAWrE,KAAKc,IAAIqI,EAAMlI,QAAQP,OAChC4I,EACFjF,EAAWrE,KAAKc,IAAIsI,EAAMnI,QAAQP,OAEhC6I,EAAY1B,EACd,CAACxB,OAAQ,CAACjC,EAAG/I,GAAIiJ,QAASD,EAAYyD,MAAO,CAACnI,MAAO,eAEnD6J,EAAgBnF,EAAWrE,KAAKc,IAAIyI,EAAUtI,QAE9CwI,EAAQD,EAAczH,mBAAmBE,KACzCyH,EAAQF,EAAczH,mBAAmBI,KAEzCwH,EACFtF,EAAWrE,KAAKc,IAAI2I,EAAMxI,QAAQP,OAChCkJ,EACFvF,EAAWrE,KAAKc,IAAI4I,EAAMzI,QAAQP,OAEhCoB,kCAAC+H,OAAgBC,OAAgB1B,OAGjC2B,EACF1F,EAAW3B,eAAe0F,EAAa,UAAWyB,GAEhDG,EACF3F,EAAW3B,eAAe0F,EAAa,UAAW0B,GAEhDlN,EAASwJ,EACX,CAACC,OAAQ,CAACpE,KAAM8H,EAAY5H,KAAM6H,GAAa1F,QAASD,IAO5D,OALAA,EAAW4D,8BAA8BgB,GACzC5E,EAAW4D,8BAA8BsB,GACzClF,EAAW4D,8BAA8B8B,GACzC1F,EAAW4D,8BAA8B+B,GAElCpN,EAEP,IAAMgI,EAAQP,EAAWrE,KAAKc,IAAI8H,EAAE3H,QAAQP,OACtCmE,EAAQR,EAAWrE,KAAKc,IAAIzF,EAAE4F,QAAQP,OAEtCsI,EAASrJ,GAASiJ,EAAEjJ,MAEpBsK,gCAACrC,OAAYQ,OAGnB,OAAO/D,EAAW3B,eAAe0F,EAAaY,EAAQpB,GAG5D,UAMgBsC,EAA8B/L,GAE5C,OAAO,SAACuG,EAAkBC,EAAkB0E,EACpCC,EAAyBK,EACzBC,GACN,IAAMxB,EAAcrH,eAAagE,2BAA2BL,EAAQC,GAC9DQ,EAAa1F,OAAK8E,cAAc6D,GAChCpD,EAAaoD,EAAY9J,OACzB2G,EAAgBxF,OAAKyF,eAAekD,GAEpC+B,EAAiB1K,OAAK2F,uBAAuB,UAAWD,GACxDiF,EAAiB3K,OAAK2F,uBAAuB,UAAWD,GAExDM,EAAiB1E,eAAa2E,iBAAiBhB,EAAQ0D,GACvDzC,EAAiB5E,eAAa2E,iBAAiBf,EAAQyD,GAEvDxD,EAAQ7D,eAAaqB,uBAAuBiH,EAAWC,GACvDzE,EAAQ9D,eAAaqB,uBAAuBuH,EAAWC,GAEvDvE,EAAQX,EAAOpG,OACfiH,EAAW9F,OAAKyF,eAAeR,GAE/BY,EAAQX,EAAOrG,OACfkH,EAAW/F,OAAKyF,eAAeP,GAErC,GAAIc,EAAenH,OAASqH,EAAerH,SAAW,EACpD,IAAK,IAAIM,EAAI,EAAGA,EAAIuL,EAAe7L,OAAQM,IAAK,CAC9C,IAAMyL,EAAOzL,EAAIgG,EAAMtG,OACjBgM,EAAO1L,EAAIiG,EAAMvG,OAEjB1B,EACFuB,EAAGyG,EAAa,EAAPyF,GAAWzF,EAAa,EAAPyF,EAAW,GAAIxF,EAAa,EAAPyF,GAC5CzF,EAAa,EAAPyF,EAAW,IAExBH,EAAevL,GAAKhC,EAAOqF,KAC3BmI,EAAexL,GAAKhC,EAAOuF,yBAGpBvD,GACP,IAAMgH,EAAMnG,OAAKoG,WAAWjH,EAAGoG,EAAYC,GAErCa,EAAOF,EAAIG,OAAOV,GACxBI,EAAejG,SAAQ,SAAApE,GAAK,OAAA0K,EAAK1K,GAAK,KACtC,IAAM4K,EAASvG,OAAKwG,WAAWH,EAAMT,EAAOE,GAEtCW,EAAON,EAAIG,OAAOT,GACxBK,EAAenG,SAAQ,SAAApE,GAAK,OAAA8K,EAAK9K,GAAK,KACtC,IAAM+K,EAAS1G,OAAKwG,WAAWC,EAAMZ,EAAOE,GAEtC+E,EACFpM,EAAGyG,EAAe,EAAToB,GAAapB,EAAe,EAAToB,EAAa,GAAInB,EAAe,EAATsB,GAChDtB,EAAe,EAATsB,EAAa,IAE1BgE,EAAevL,GAAK2L,EAAStI,KAC7BmI,EAAexL,GAAK2L,EAASpI,MAhB/B,IAASvD,EAAI,EAAGA,EAAIuL,EAAe7L,OAAQM,MAAlCA,GAmBX,MAAO,CAACuL,EAAgBC,EAAgBhC,GAE5C,CC3KO,IAAMoC,EACT/F,YAA+BmE,EAAWvN,GAAc,OAAAuN,EAAIvN,CAAC,IACpDoP,EACTP,YAAgCf,EAAOC,EAAOK,EAAOC,GACnD,MAAO,CAACzH,KAAMkH,EAAQM,EAAOtH,KAAMiH,EAAQM,EAC5C,IAEQgB,EAAMlC,EAAiBmC,MAAKH,EAASC,GAErCG,EAA0B,CACrC7G,WAAY4G,MACZ1G,YAAa,MACbC,WAAYwG,YCfEG,EACZC,EAAmBC,EAAyBC,EAC5CC,EAAwBC,GAI1B,IAHA,IAAMC,EAAc1L,OAAK8E,cAAc0G,GACjCG,EAAU3L,OAAKmH,oBAAoBsE,EAAMF,GAEtCpM,EAAI,EAAGA,EAAIkM,EAAMxM,OAAQM,IAAK,CACrC,IAAMrC,EAAQuO,EAAMlM,GACpB,GAAIrC,EAAQ,EACV,MAAM,IAAIiG,MAAM,iCAGdjG,GAAS2O,IAKXE,EAAQ7O,IADN4O,EAAc,EACEJ,EAAYnM,GAEZ,GAItB,OAAOwM,CACT,UAEgBC,EACZC,EAAuBC,EAA6BL,EACpDM,gBAAAA,MAMF,IALA,IAAMC,EAAUH,EAAK3K,MAAM,GACrB+K,EAAUJ,EAAK3K,MAAM,GAErBgL,EAASpJ,SAAO,CAACkJ,EAASP,GAAOK,EAAW5L,OAEzCf,EAAI,EAAGA,EAAI6M,EAAS7M,IAC3B,IAAK,IAAIgN,EAAI,EAAGA,EAAIF,EAASE,IAAK,CAChC,IAAMrP,EAAQ+O,EAAKxK,IAAIlC,EAAGgN,GAC1B,GAAIrP,EAAQ,EACV,MAAM,IAAIiG,MAAM,iCAGdjG,GAAS2O,IAITM,EACFG,EAAOxK,IAAI,EAAGvC,EAAGrC,GAEbgP,EAAWL,KAAO,EACpBS,EAAOxK,IAAIwK,EAAO7K,IAAIlC,EAAGrC,GAASgP,EAAWzK,IAAIlC,EAAGgN,GAAIhN,EAAGrC,GAE3DoP,EAAOxK,IAAIwK,EAAO7K,IAAIlC,EAAGrC,GAAS,EAAGqC,EAAGrC,IAMhD,OAAOoP,CACT,UCrDgBE,EAAsB1N,GAEpC,OAAO,SAACuC,EAAQf,EAAOmI,GAGrB,IAFA,IAAMgE,EACFrM,OAAK2F,uBAAuBzF,EAA0Be,EAAOpC,QACxDM,EAAI,EAAGA,EAAI8B,EAAOpC,SAAUM,EACnCkN,EAAUlN,GAAKT,EAAGuC,EAAO9B,GAAIkJ,GAE/B,OAAOgE,EAEX,UCFgBC,EACZtD,EAActK,EAA0BwB,GAC1C,OAAO,SAACgI,OAACtB,WAAQyB,UAAOxD,YACfF,MAEP,GADAhF,EAAiBgF,EAAGqE,GACJ,WAAZrE,EAAEzE,OAAgC,WAAVA,EAC1B,MAAM,IAAI6C,MAAM,wDAQlB,IALA,IAAM6B,EAAaC,EACb5D,EAAS2D,EAAWrE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACvCsL,EAAQvM,OAAK8E,cAAcH,EAAEzD,OAC7BqI,EAASrJ,GAASyE,EAAEzE,MACpBmM,EAAYrM,OAAKwM,kBAAkBjD,EAAQgD,GACxCpN,EAAI,EAAGA,EAAIoN,IAASpN,EAC3BkN,EAAUlN,GAAKT,EAAGuC,EAAO9B,GAAIkJ,GAE/B,OAAOzD,EAAW3B,eAAe0B,EAAEzD,MAAOqI,EAAQ8C,GAEtD,UAWgBI,EACZzD,EAAc0D,EAA4BxM,GAC5C,OAAO,SAACgI,OAACtB,WAAQyB,UAAOxD,YACfF,MAEP,GADAhF,EAAiBgF,EAAGqE,GACJ,WAAZrE,EAAEzE,OAAgC,WAAVA,EAC1B,MAAM,IAAI6C,MAAM,wDAGlB,IAAM6B,EAAaC,EACb5D,EAAS2D,EAAWrE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACvCsI,EAASrJ,GAASyE,EAAEzE,MACpBmM,EAAYK,EAAUzL,EAAQsI,EAAQlB,GAC5C,OAAOzD,EAAW3B,eAAe0B,EAAEzD,MAAOqI,EAAQ8C,GAEtD,CCvDO,IAAMM,EAAWP,GAAsB,SAACQ,GAAO,OAAAzI,KAAK0I,KAAKD,MACnDC,EAAOJ,EAAwBK,OAAMH,GAErCI,EAA2B,CACtCzI,WAAYwI,OACZtI,YAAa,MACbC,WAAYoI,YCTEG,EACZpG,EAAuDqG,EACvD/M,EAAiBgN,GACnB,IAAMvB,EAAU3L,OAAKwM,kBAAkBtM,EAAOF,OAAK8E,cAAcmI,IAEjE,GAAIC,GAA0B,WAAVhN,EAAoB,CAEtC,IAAIiN,EAAS,EACbvG,EAAO7G,SAAQ,SAAAyH,GACb,IAAMiE,EAAOzL,OAAK8E,cAAc0C,EAAMtG,OAErCyK,EAAuBjK,IAAI8F,EAAMxD,KAAoBmJ,GACtDA,GAAU1B,SAEP,CACL,IAAI2B,EAAY,EAEhBxG,EAAO7G,SAAQ,SAAAyH,GAOb,IANA,IAAM6F,EAAwB,WAAVnN,EAChBoB,eAAa+H,uBAAuB7B,EAAMxD,MAC1CwD,EAAMxD,KAENsJ,EAAO,EAEFC,EAAM,EAAGA,EAAM/F,EAAMtG,MAAM,KAAMqM,EAExC,IADA,IAAMC,EAASD,EAAMN,EAAS,GAAKG,EAC1BK,EAAM,EAAGA,EAAMjG,EAAMtG,MAAM,KAAMuM,EACxC9B,EAAQ6B,EAASC,GAAOJ,EAAYC,KAIxCF,GAAa5F,EAAMtG,MAAM,MAI7B,OAAOyK,CACT,CCjCO,IAAM+B,EACT1I,GAA6B,SAACmE,EAAWvN,GAAc,OAACuN,IAAMvN,EAAK,EAAI,KAC9D+R,EACT5E,EAAiB6E,QAAOF,EAAW,KAAwB,QAElDG,EAA4B,CACvCvJ,WAAYsJ,QACZpJ,YAAa,MACbC,WAAYkJ,GCRDG,EAAU1B,GAAsB,SAACQ,GAAO,OAAAzI,KAAK4J,IAAInB,MACjDmB,EAAMtB,EAAwBuB,MAAKF,EAAS,WAE5CG,EAA0B,CACrC3J,WAAY0J,MACZxJ,YAAa,MACbC,WAAYsJ,GCNDG,EAAY9B,GAAsB,SAACQ,GAAO,OAAAzI,KAAKgK,MAAMvB,MACrDuB,EAAQ1B,EAAwB2B,QAAOF,GAEvCG,EAA4B,CACvC/J,WAAY8J,QACZ5J,YAAa,MACbC,WAAY0J,GCNDG,EAAYlC,GAAsB,SAACQ,GAAO,OAAAzI,KAAKoK,MAAM3B,MACrD2B,EAAQ9B,EAAwB+B,QAAOF,GAEvCG,EAA4B,CACvCnK,WAAYkK,QACZhK,YAAa,MACbC,WAAY8J,YCTEG,GACZC,EAAyBC,EAA4B1O,EACrD2O,EAAmBC,EAAmBC,EAAmBC,EACzDC,EAAuBC,GAGzB,IAFA,IAAMhD,EAASpJ,SAAO,CAAC+L,EAAWE,GAAY7O,GAErCf,EAAI,EAAGA,EAAI0P,EAAW1P,IAAK,CAGlC,IAFA,IAAMgQ,EAAQ,GACVC,EAAe,EACVjD,EAAI,EAAGA,EAAI2C,EAAW3C,IAAK,CAClC,IAAMkD,EAAMV,EAAYxP,EAAI2P,EAAY3C,GACxCiD,GAAgBC,EAAML,EAAQ7C,GAC9BgD,EAAMrQ,KAAKuQ,GAEb,GAAID,EAAe,GAAKA,GAAgBF,EAAaH,EACnD,MAAM,IAAIhM,MACN,oBAAoBoM,0BAA6BF,GAGvD,IAAK,IAAIK,EAAI,EAAGA,EAAIP,EAAWO,IAC7BpD,EAAOjL,OAAO9B,EAAI4P,EAAYO,GAC1BV,EAAUvN,UAAVuN,IAAiBA,EAAUxI,WAAWgJ,EAAeL,EAAYO,KAIzE,OAAOpD,CACT,UC1BgBqD,GACZ1D,EAA0B2D,EAC1BC,GAEF,IADA,IAAMvD,EAASpJ,SAAO2M,EAAoB5D,EAAK3L,OACtCf,EAAI,EAAGA,EAAI+M,EAAOT,OAAQtM,EAAG,CACpC,IAEMuQ,EAFSxD,EAAO9F,WAAWjH,GAEImH,QAC/BqJ,EAAWD,EAAY,GACvBE,EAAaF,EAAY,GACzBG,EAAeL,EAAWhJ,WAAW,CAACmJ,EAAUC,IACtDF,EAAY,GAAKF,EAAWvO,OAAO4O,GAEnC,IAAMC,EAAgBjE,EAAKrF,WAAWkJ,GAElC,GAAKI,GAAiBA,EAAgBjE,EAAK5K,OAAOpC,SACpDqN,EAAOjL,OAAO9B,GAAK0M,EAAK5K,OAAO6O,IAInC,OAAO5D,CACT,CClBO,IAAM6D,GACT/K,GAA6B,SAACmE,EAAWvN,GAAc,OAACuN,EAAIvN,EAAK,EAAI,KAC5DoU,GACTjH,EAAiBkH,UAASF,GAAa,KAAwB,QAEtDG,GAA8B,CACzC5L,WAAY2L,UACZzL,YAAa,MACbC,WAAYuL,ICRDG,GACTnL,GAA6B,SAACmE,EAAWvN,GAAc,OAACuN,GAAKvN,EAAK,EAAI,KAC7DwU,GAAerH,EACxBsH,eAAcF,GAAkB,KAAwB,QAE/CG,GAAmC,CAC9ChM,WAAY+L,eACZ7L,YAAa,MACbC,WAAY2L,ICRDG,GACTvL,GAA6B,SAACmE,EAAWvN,GAAc,OAACuN,EAAIvN,EAAK,EAAI,KAC5D4U,GACTzH,EAAiB0H,OAAMF,GAAU,KAAwB,QAEhDG,GAA2B,CACtCpM,WAAYmM,OACZjM,YAAa,MACbC,WAAY+L,ICRDG,GACT3L,GAA6B,SAACmE,EAAWvN,GAAc,OAACuN,GAAKvN,EAAK,EAAI,KAC7DgV,GACT7H,EAAiB8H,YAAWF,GAAe,KAAwB,QAE1DG,GAAgC,CAC3CxM,WAAYuM,YACZrM,YAAa,MACbC,WAAYmM,aCXEG,GACZzN,EAAe0N,EAAcC,GAC/B,IAAMlU,GAAQiU,EAAO1N,IAAU2N,EAAM,GAE/BhQ,EAASjB,OAAKmH,oBAAoB8J,EAAK,WAC7ChQ,EAAO,GAAKqC,EACZ,IAAK,IAAInE,EAAI,EAAGA,EAAI8B,EAAOpC,OAAQM,IACjC8B,EAAO9B,GAAK8B,EAAO9B,EAAI,GAAKpC,EAG9B,OAAOkE,CACT,CCRO,IAAMiQ,GAAU9E,GAAsB,SAACQ,GAAO,OAAAzI,KAAKgN,IAAIvE,MACjDuE,GAAM1E,EAAwB2E,MAAKF,IAEnCG,GAA0B,CACrC/M,WAAY8M,MACZ5M,YAAa,MACbC,WAAY0M,aCTEG,GACZnM,EAAmBoM,EAAoBtE,EACvC/M,GAIF,IAHA,IAAM8D,EAAOhE,OAAK2F,uBACdzF,EAA0BF,OAAK8E,cAAcmI,IAExC9N,EAAI,EAAGA,EAAI6E,EAAKnF,SAAUM,EAAG,CAGpC,IAFA,IAAMqS,EAASrS,EAAIoS,EACfE,EAAMtM,EAAMqM,GACPrF,EAAI,EAAGA,EAAIoF,IAAcpF,EAAG,CACnC,IAAMrP,EAAQqI,EAAMqM,EAASrF,IACzBuF,OAAOC,MAAM7U,IACbA,EAAQ2U,KACVA,EAAM3U,GAGVkH,EAAK7E,GAAKsS,EAEZ,OAAOzN,CACT,CChBO,IAAM4N,GAAc5M,YACrB6M,EAAQC,GAAW,OAAA3N,KAAKsN,IAAII,EAAkBC,EAAiB,IACxDC,GAAUhJ,EAAiBiJ,UAASJ,IAEpCK,GAA8B,CACzC3N,WAAY0N,UACZxN,YAAa,MACbC,WAAYsN,ICPDG,GAAclN,YACrB6M,EAAQC,GAAW,OAAA3N,KAAKgO,IAAIN,EAAkBC,EAAiB,IACxDM,GAAUrJ,EAAiBsJ,UAASH,IAEpCI,GAA8B,CACzChO,WAAY+N,UACZ7N,YAAa,MACbC,WAAY2N,ICRDG,GAAevN,YACtB6M,EAAgBC,GAAmB,OAAAD,EAASC,CAAM,IAC3CU,GACT/H,YAAgCf,EAAOC,EAAOK,EAAOC,GACnD,MAAO,CACLzH,KAAMkH,EAAQM,EAAQL,EAAQM,EAC9BvH,KAAMgH,EAAQO,EAAQN,EAAQK,EAEjC,IAEQyI,GACT1J,EAAiB2J,WAAUH,GAAcC,IAEhCG,GAA+B,CAC1CrO,WAAYoO,WACZlO,YAAa,MACbC,WAAYgO,aCdEG,GAAQvH,EAAmBwH,EAAkBC,GAE3D,IAAMC,EACF/S,OAAKgT,mBAAmB,EAAsBF,GAClD,OAAOP,GAAa,GAAIM,EAAQE,EAAU1H,EAAOyH,EACnD,CAeO,IAAMG,GAA0B,CACrC3O,WAAY4O,MACZ1O,YAAa,MACbC,oBAhBkBC,GAEX,IAAAkC,WAAQ/B,YACRF,MAEPhF,EAAiBgF,EAAG,OAEpB,IACMuD,OADQrD,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,2BAClCkS,OAAK9N,OAEZ,OAAOR,EAAQ5B,eAAeoC,EAAUV,EAAEzE,MAAOiT,EACnD,GCnBaC,GACTpO,YAA+BmE,EAAGvN,GAAM,OAACuN,IAAMvN,EAAK,EAAI,CAAC,IAChDyX,GACTtK,EAAiBuK,WAAUF,GAAc,KAAsB,QAEtDG,GAA+B,CAC1CjP,WAAYgP,WACZ9O,YAAa,MACbC,WAAY4O,aCVEG,GACZnI,EAAmBwH,EAAkB3S,EAAiBuT,EACtDpO,GASF,IARA,IAAMqO,EAAQb,EAAOhU,OACf0N,EAAQvM,OAAK8E,cAAc+N,GAC3Bc,EAAW3T,OAAKyF,eAAeoN,GAC/Be,EAAa5T,OAAKyF,eAAeJ,GAEjClI,EAAS6C,OAAK2F,uBAChBzF,EAA0BF,OAAK8E,cAAcO,IAExClG,EAAI,EAAGA,EAAIoN,IAASpN,EAAG,CAK9B,IAJA,IAAMgH,EAAMnG,OAAKoG,WAAWjH,EAAGuU,EAAOC,GAGhCE,EAAmB,IAAI7X,MAAMmK,EAAItH,QAC9BiV,EAAI,EAAGA,EAAID,EAAOhV,OAAQiV,IACjCD,EAAOC,GAAK3N,EAAIsN,EAAKK,IAIvB3W,EADiB6C,OAAKwG,WAAWqN,EAAQH,EAAOE,IAC7BvI,EAAMlM,GAE3B,OAAOhC,CACT,UCpBgB4W,GAAUrP,GAKjB,IAAAkC,WAAQyB,UAAOxD,YACfF,MACA8O,SAEP9T,EAAiBgF,EAAG,aAKpB,IAHA,IAAM+O,EAAQ/O,EAAEzD,MAAMrC,OAEhBwG,EAAqB,IAAIrJ,MAAM0X,GAC5BvU,EAAI,EAAGA,EAAIkG,EAASxG,OAAQM,IACnCkG,EAASlG,GAAKwF,EAAEzD,MAAMuS,EAAKtU,IAG7B,IACMhC,EAASqW,GADA3O,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACL0D,EAAEzD,MAAOyD,EAAEzE,MAAOuT,EAAMpO,GAG7D,MAAO,CAAC7D,OADOqD,EAAQ5C,MAAM9E,EAAQkI,EAAUV,EAAEzE,OACjCgB,MAAOmE,EAAUnF,MAAOyE,EAAEzE,MAC5C,CAEO,IAAM8T,GAAgC,CAC3C1P,WAAY2P,YACZzP,YAAa,MACbC,WAAYsP,aC7BEG,GACZrB,EAAkBC,EAAkBzH,EACpC8I,GASF,IAPM,IAAAjM,qDAAC+E,OAAUmH,OAEXC,EAAWC,aAAWxB,EAAQ,SAC9BnH,EAAU3L,OAAKmH,oBACDnH,OAAK8E,cAAcmI,GAAWoH,GAC5C9C,EAAavR,OAAK8E,cAAcsP,GAE7BjV,EAAI,EAAGA,EAAIwM,EAAQ9M,SAAUM,EAAG,CAGvC,IAFA,IAAMqS,EAASrS,EAAIoS,EACfgD,EAAO,EACFpI,EAAI,EAAGA,EAAIoF,IAAcpF,EAChCoI,GAAQlJ,EAAMmG,EAASrF,GAEzBR,EAAQxM,GAAKoV,EAGf,MAAO,CAAC5I,UAASsB,WAAUoH,WAC7B,CAuCO,IAAMG,GAA2B,CACtClQ,WAAYmQ,OACZjQ,YAAa,MACbC,oBAvCEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA+P,SAAMC,aAEbhV,EAAiBgF,EAAG,QAEpB,IAAM+O,EAAQ/O,EAAEzD,MAAMrC,OAChB+V,EAAO5U,OAAK6U,eAAeH,EAAM/P,EAAEzD,OAEnC4T,EAAcxT,eAAayT,mBAAmBH,EAAMlB,GACtDS,EAAgBS,EAChBI,EAAYrQ,EACVsQ,EAA0B,GACb,MAAfH,IACFE,EAAYjB,GAAU,CAACnN,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACoL,KAAMqB,KAC3DG,EAAwBnW,KAAKkW,GAC7Bb,EAAgB7S,eAAa4T,iBAAiBf,EAActV,OAAQ6U,IAGtE,IAAMrI,EAAQxG,EAAQtE,KAAKc,IAAI2T,EAAUxT,QAAQP,OAC3CiH,0BAACyD,YAASsB,aAAUoH,aAGtB1L,EAAcsE,EAQlB,OAPI0H,IACFhM,EAAcrH,eAAa6T,qBAAqBlI,EAAU2H,IAG5DK,EAAwBlV,SACpB,SAAApC,GAAK,OAAAkH,EAAQ2D,8BAA8B7K,MAExCkH,EAAQ5B,eAAe0F,EAAa0L,EAAU1I,EACvD,GC9DOyJ,GAAmB9T,eAAa8T,+BAMrC,WACYlU,EAA2BmU,EAC3BpU,EAA4BqU,EAC5BC,EAA+BC,EAC/BC,EACSC,EACAC,EACjBC,GANQrX,WAAA2C,EAA2B3C,gBAAA8W,EAC3B9W,YAAA0C,EAA4B1C,iBAAA+W,EAC5B/W,iBAAAgX,EAA+BhX,kBAAAiX,EAC/BjX,uBAAAkX,EACSlX,wBAAAmX,EACAnX,8BAAAoX,EAEnBpX,KAAKsX,kBACDvU,eAAawU,2BAA2BF,GAC5CrX,KAAKwX,WAAazU,eAAa0U,cAAczX,KAAKsX,0BAG5CI,2CAAA,SAA+BC,GACrC,OAAI3X,KAAKsX,kBAAkB,KAAOT,GAAiBe,eAC1C5X,KAAKsX,kBAAkBK,EAAY,GAEnC3X,KAAKsX,kBAAkBK,IAK1BD,kCAAA,SAAsBC,GAC5B,OAAI3X,KAAKsX,kBAAkB,KAAOT,GAAiBe,eAC1C5X,KAAKmX,mBAAmBQ,EAAY,GAEpC3X,KAAKmX,mBAAmBQ,IAI3BD,wBAAA,SAAYC,GAClB,IAAME,EAAqB7X,KAAK8X,sBAAsBH,EAAY,GAClE,OAAQ3X,KAAK+X,+BAA+BJ,EAAY,IACtD,KAAKd,GAAiBmB,aACpB,OAAON,EAAuBO,sBAAsBJ,GACtD,KAAKhB,GAAiBqB,WACpB,OAAOR,EAAuBS,oBAAoBN,GACpD,QACE,MAAM,IAAIrT,MAAM,gCACZqS,GAAiB7W,KAAK+X,+BAClBJ,EAAY,OAInBD,sBAAP,SAA2BU,GACzB,IAAMC,EAAeD,EAAS9X,OAC9B,GAAqB,IAAjB+X,GAAuC,IAAjBA,EACxB,OAAO,EAGT,IADA,IAAIC,EAAW,EACN1X,EAAI,EAAGA,EAAIyX,EAAe,IAAKzX,EAAG,CACzC,IAAM2X,EAAeH,EAASxX,EAAI,GAAKwX,EAASxX,GAC5C2X,EAAeD,IACjBA,EAAWC,GAGf,OAAOD,GAGFZ,wBAAP,SAA6Bc,GAC3B,IAAMC,EAAcD,EAAYlY,OAChC,GAAoB,IAAhBmY,EACF,OAAO,EAKT,IAHA,IAAIC,EAAkB,EAClBC,EAAuBH,EAAY,GACnCF,EAAW,EACN1X,EAAI,EAAGA,EAAI6X,IAAe7X,EAAG,CACpC,IAAMrC,EAAQia,EAAY5X,GACtBrC,IAAUoa,IACZA,EAAuBpa,EACvB+Z,EAAW1S,KAAKsN,IAAItS,EAAI8X,EAAiBJ,GACzCI,EAAkB9X,GAGtB,OAAOgF,KAAKsN,IAAIuF,EAAcC,EAAiBJ,IAGzCZ,kCAAA,SACJtY,EAAewZ,EAAkBC,GACnC,gBADmCA,MACb,IAAlBD,EAAOtY,OAAc,CACvB,IAAc,IAAVlB,EAAE,GACJ,MAAO,GAET,MAAM,IAAIoF,MACN,kFAGN,OAAOsU,GAAU1Z,EAAGyZ,IAGdnB,gCAAA,SAAoBqB,GAC1B,IAAMC,EAAahZ,KAAK+W,YAClBG,EAAoBlX,KAAKkX,kBAE/BnU,eAAakW,0BAA0B/B,EAAmB8B,GAE1D,IAAMrW,EAAQ3C,KAAKkZ,sBAAsBlZ,KAAK2C,MAAO3C,KAAK8W,YAIpDlY,EAHcmE,eAAaoW,kCAC7BnZ,KAAKwX,WAAY7U,EAAOqW,GAIxBpa,EAAO,GAAK,IACdA,EAAO,GAAKma,GAEd,IAAK,IAAInY,EAAI,EAAGA,GAAKZ,KAAKwX,aAAc5W,EAClChC,EAAOgC,GAAK,IACdhC,EAAOgC,GAAKZ,KAAKoZ,YAAYxY,IAIjC,OAAOhC,GAaD8Y,4CAAA,SACJ2B,EAAwBC,EACxBC,GAIF,IAHA,IAAMC,EAAe5T,KAAKgO,IAAIyF,EAAgBE,GACxC3a,EAAmB,GACrB6a,EAAqB,EAChB7Y,EAAI,EAAGA,EAAI4Y,IACb5Y,EAAG6Y,GAAsBH,EAC9B1a,EAAO2B,KAAKkZ,GAEd,IAAS7Y,EAAI4Y,EAAc5Y,EAAIyY,IAAkBzY,EAC/ChC,EAAO2B,MAAM,GAMf,OAJAkB,OAAKC,OACD9C,EAAO0B,SAAW+Y,GAClB,WAAM,MAAA,6DAEHza,GAGD8Y,yCAAA,SACJU,EAAsBsB,EACtBJ,EAA+BK,GAGjC,IAFA,IAAMC,EAAexB,EAAS9X,OACxB1B,EAAmB,GAChBgC,EAAI,EAAGA,EAAIgZ,EAAe,IAAKhZ,EAAG,CACzC,IAAMiZ,EAAYzB,EAASxX,EAAI,GAAKwX,EAASxX,GACzCkZ,EAAalU,KAAKgO,IAAI+F,EAAYE,GAClCE,EAA2BL,EAAkB9Y,IAEf,IAA9BmZ,IACFD,EAAa,GAEf,IAAK,IAAIlM,EAAI,EAAGA,EAAIkM,IAAclM,EAChChP,EAAO2B,KAAKwZ,GACZA,GAA4BT,EAE9B,IAAS1L,EAAI,EAAGA,EAAIiM,EAAYC,IAAclM,EAC5ChP,EAAO2B,MAAM,GAGjB,GAAIqZ,EAAe,GAAKhb,EAAO0B,SAAW8X,EAASwB,EAAe,GAChE,MAAM,IAAIpV,MAAM,2BAGlB,OAAO5F,GAwBD8Y,2CAAA,SACJc,EAAyBkB,EACzBJ,EAA+BK,GACjC,IAAMK,EAAYxB,EAAYlY,OACxB1B,EAAmB,GACzB,GAAkB,IAAdob,EACF,MAAO,GAGT,IAAIC,EAAsB,EACtBC,EAAoB1B,EAAY,GAEpC,GAAI0B,GAAqBR,EAAkBpZ,OACzC,MAAM,IAAIkE,MACN,yBAAyB0V,8BACrBR,EAAkBpZ,QAG5B,IAAImZ,EAAqBC,EAAkBQ,GAC3Ctb,EAAO2B,KAAKkZ,GACZ,IAAK,IAAI7Y,EAAI,EAAGA,EAAIoZ,IAAapZ,EAAG,CAClC,IAAMuZ,EAAiB3B,EAAY5X,GACnC,GAAIuZ,IAAmBD,EACjBT,GAAsB,MACtBQ,EACwBN,EACxBF,GAAsBH,EAEtBG,GAAsB,OAGrB,CAIL,GAHAQ,EAAsB,EACtBC,EAAoBC,EAEhBA,GAAkBT,EAAkBpZ,OACtC,MAAM,IAAIkE,MACN,sBAAsB2V,6BAClBT,EAAkBpZ,QAG5BmZ,EAAqBC,EAAkBS,GAEzCvb,EAAO2B,KAAKkZ,GAGd,GAAI7a,EAAO0B,SAAWkY,EAAYlY,OAChC,MAAM,IAAIkE,MAAM,oBAGlB,OAAO5F,GAGD8Y,iCAAA,SACJC,EAAmB+B,EACnBJ,EAA+BK,GACjC,IAAM9B,EAAqB7X,KAAK8X,sBAAsBH,GAChDyC,EAAgBpa,KAAK+X,+BAA+BJ,GAC1D,OAAQyC,GACN,KAAKvD,GAAiBmB,aACpB,OAAOhY,KAAKqa,+BACRxC,EAAoB6B,EAAmBJ,EACvCK,GACN,KAAK9C,GAAiBqB,WACpB,GAAIL,EAAmBvX,OAAS,EAAIoZ,EAAkBpZ,OACpD,MAAM,IAAIkE,MAAM,oDACZqT,EAAmBvX,OAAS,SAAOoZ,EAAkBpZ,QAE3D,OAAON,KAAKsa,6BACRzC,EAAoB6B,EAAmBJ,EACvCK,GACN,QACE,MAAM,IAAInV,MACN,+BAA+BqS,GAAiBuD,MAIlD1C,kCAAA,WACN,IAAM6C,EAAuBva,KAAKmX,mBAAmB,GACrD,GAAsC,IAAlCnX,KAAKsX,kBAAkBhX,OACzB,MAAM,IAAIkE,MAAM,iCAElB,IAAMgW,EAAqBxa,KAAKsX,kBAAkB,GAClD,OAAQkD,GACN,KAAK3D,GAAiBe,eACpB,OAAO2C,EAAqB,GAC9B,KAAK1D,GAAiBmB,aACpB,MAAM,IAAIxT,MAAM,kDAClB,KAAKqS,GAAiBqB,WACpB,OAAOlY,KAAKoX,yBAAyB,GAAG,GAAK,EAC/C,QACE,MAAM,IAAI5S,MACN,sBAAsBqS,GAAiB2D,MAIjD9C,oBAAA,WAEE,GAD6B1X,KAAKmX,mBAAmB,GAC5B7W,QAAU,EACjC,MAAM,IAAIkE,MACN,wEAGN,IAAM6U,EAAiBrZ,KAAKya,wBACtBd,EAAa3Z,KAAK0a,oBAAoBrB,GACtCsB,EAAuB,IAAIld,MAAMuC,KAAKwX,WAAa,GAEzDmD,EAAWA,EAAWra,OAAS,GAAK,EACpC,IAAK,IAAIM,EAAI+Z,EAAWra,OAAS,EAAGM,GAAK,IAAKA,EAC5C+Z,EAAW/Z,GAAK+Z,EAAW/Z,EAAI,GAAK+Y,EAAW/Y,EAAI,GAGrD,IAAMga,EAAwB9B,GAAUa,GAAY,GAC9CkB,EACFpZ,OAAKwM,kBACDjO,KAAKgX,YAAavV,OAAK8E,cAAcqU,IAG7C,GADiBD,EAAW,GAAKhB,EAAW,GAC7B,EAAG,CAChB,IAAImB,EAAc9a,KAAK+a,gCACnB1B,EAAgBsB,EAAW,GAAIhB,EAAW,IAC9C,IAAS/Y,EAAI,EAAGA,GAAKZ,KAAKwX,aAAc5W,EAAG,CAGzCka,EAFuB9a,KAAKgb,qBACxBpa,EAAI,EAAGka,EAAaH,EAAW/Z,GAAI+Y,EAAW/Y,IAIpDZ,KAAKib,UAAUjb,KAAKwX,WAAYsD,EAAaD,EAAcD,GAG7D,MAAO,CAACA,EAAaC,IAEvBnD,sBAAA,SACIF,EAAoBsD,EAAuBD,EAC3CD,GACF,GAA4B,IAAxBC,EAAava,OAAjB,CAIA,IAAM4a,EAAalb,KAAK0C,OAClByY,EAAaN,EAEfO,EAAeR,EAAY7S,QAC/BqT,EAAeA,EAAarT,MAAMyP,EAAa,GAC/C,IAAM6D,EAAmB5Z,OAAK8E,cAAc6U,GACtCE,EAAkBR,EAAYxa,OAIhC2W,EAAejX,KAAKiX,aACxB,GAAIA,EAAa3W,SAAW+a,GAA4C,IAAxBpE,EAAa3W,OAAc,CACzE,IAAMib,EAAWvb,KAAKkX,kBACtBsE,QAAK,WACH,IAAMC,EAAqBC,UAAQzE,EAAcsE,GAC3CI,EAAeC,cAAYH,EAAoBL,GACrDnE,EAAe0E,EAAaE,cAUhC,IAHA,IAAIC,EAAW,EACXC,EAAW,EACXC,EAAS,EACJC,EAAO,EAAGA,GAAQX,IAAmBW,EAAM,CAElD,IAAIC,EAAOD,EAAOX,EAAkBR,EAAYmB,IAAS,EAIzD,GAAIC,IAASF,EAAb,CASA,GAAID,EAAWC,EAAQ,CAErB,IAAMG,EAAMjB,EAAWkB,SAASN,EAAWT,GAG3CgB,GAFYlB,EAAWiB,SAASL,EAAWV,GAE5Bc,GADAH,EAASD,GAAYV,GAKtC,GAAIY,GAAQX,EAAiB,CAE3B,IAAM3B,EAAakB,EAAava,OAChC4b,EAAOtW,KAAKoK,MAAM2J,EAAa0B,GAEjC,GAAIa,EAAOF,EACT,GAAiC,IAA7Bhc,KAAKiX,aAAa3W,OACpB6a,EACKiB,SAASJ,EAASX,EAAkBa,EAAOb,GAC3CiB,KAAKtc,KAAKiX,aAAa,IAC5B+E,EAASE,OAET,KAAOA,EAAOF,GAAQ,CAEpBK,GADYlB,EAAWpT,MAAMiU,EAASX,GACvBpE,EAAcoE,KAC3BW,EAMJE,EAAO,GAETJ,EAAWG,EAAO,EAClBF,EAAWC,IAGXF,EAAWG,EAEXD,GADAD,EAAWC,GACS,SA9ClBA,UAoDV,SAASK,GAAUE,EAAiBJ,EAAiBjP,GACnD,IAAK,IAAItM,EAAI,EAAGA,EAAIsM,EAAMtM,IACxB2b,EAAI3b,GAAKub,EAAIvb,EAEjB,CAEA,SAASkY,GAAUnW,EAA4BkW,WACvC2D,EAAgB,OACtB,IAAgB,IAAAC,EAAAC,EAAA/Z,iCAAO,CAAlB,IAAImO,UACP,GAAIA,EAAM,EAAG,CACX,IAAK+H,EACH,MAAM,IAAIrU,MAAM,aAAasM,mBAE/B,GAAIA,GAAO,EACT,MAAM,IAAItM,MAAM,aAAasM,oBAE/BA,GAAO,EAET0L,EAAIjc,KAAKuQ,qGAGX,OAAO0L,CACT,UAEgBG,GACZha,EAAmBia,EAAuBla,EAC1CqU,EAAuBC,EAAuBC,EAC9CC,EAA6BC,EAC7BC,EACAE,GACF,OAAO,IAAII,GACA/U,EAAOia,EAAala,EAAQqU,EAAaC,EAAaC,EACtDC,EAAmBC,EAAoBC,EACvCE,GACNuF,SACP,UC3cgBC,GACZ/X,EAAe0N,EAAcjU,EAC7BmD,GAKF,GAJsBoD,IAAU0N,GACI1N,EAAQ0N,GAAQjU,EAAO,GACvBiU,EAAO1N,GAASvG,EAAO,EAIzD,OAAOiD,OAAKmH,oBAAoB,EAAGjH,GAGrC,IAAMob,EAAcnX,KAAKC,IAAID,KAAK0I,MAAMmE,EAAO1N,GAASvG,IAClDkE,EAASjB,OAAKmH,oBAAoBmU,EAAapb,GAEjD8Q,EAAO1N,GAAkB,IAATvG,IAGlBA,GAAQ,GAGVkE,EAAO,GAAKqC,EACZ,IAAK,IAAInE,EAAI,EAAGA,EAAI8B,EAAOpC,OAAQM,IACjC8B,EAAO9B,GAAK8B,EAAO9B,EAAI,GAAKpC,EAE9B,OAAOkE,CACT,CCvBO,IAAMsa,GAAYnP,GAAsB,SAACQ,GAAO,OAAA,EAAIzI,KAAKqX,KAAK5O,MACxD6O,GAAQhP,EAAwBiP,QAAOH,IAEvCI,GAA4B,CACvCrX,WAAYoX,QACZlX,YAAa,MACbC,WAAYgX,aCFdG,GACIC,EAAmCC,EACnC5a,EAAiBgX,EAAoBnJ,EAAmBgN,EACxDjN,EAAmBE,EAAmBwG,EACtCwG,GACF,IAAMC,EAAe,CAAC/D,EAAanJ,EAAWA,GAExCJ,EAAckN,EAAQ5a,OACtBib,EAAcJ,EAAQ7a,OAE5B,GAAmB,IAAfiX,EACF,OAAOpV,SAAO5B,EAAsB4a,EAAQ5b,OAG9C,IAAMgM,EAASpJ,SAAOmZ,EAAcH,EAAQ5b,OAChB,iBAAjBsV,GAEwB,iBAAjBA,EADftJ,EAAOjL,OAAoB4Z,KAAKrF,GAGA,kBAAjBA,GACftJ,EAAOjL,OAAsB4Z,MAAMrF,GAGtC,IAAK,IAAIrW,EAAI,EAAGA,EAAI4c,EAAY5c,IAAK,CAGnC,IAFA,IAAMgQ,EAAQ,GACVC,EAAe,EACVjD,EAAI,EAAGA,EAAI2C,EAAW3C,IAAK,CAClC,IAAMkD,EAAMV,EAAYxP,EAAI2P,EAAY3C,GACxCgD,EAAMrQ,KAAKuQ,GACXD,GAAgBC,EAAML,EAAQ7C,GAGhC,GAAIiD,EAAe,GAAKA,GAAgB8I,EAAanJ,EACnD,MAAM,IAAIhM,MAAM,oBAAoBoM,0BAA6BjO,GAGnE,IAAK,IAAIoO,EAAI,EAAGA,EAAIP,EAAWO,IACzB0M,EACD9P,EAAOjL,OAAsBmO,EAAeL,EAAYO,IACpD4M,EAA2B/c,EAAI4P,EAAYO,GAEhDpD,EAAOjL,OAAOmO,EAAeL,EAAYO,GAAsB,IAAjBwM,EAAQK,KAClDD,EAAY,GACZA,EAAY/c,EAAI4P,EAAYO,GAKtC,OAAOpD,CACT,CCrDO,IAAMkQ,GACThQ,GAAsB,SAACQ,GAAO,OAAA,GAAK,EAAIzI,KAAK4J,KAAKnB,OACxCyP,GACT/P,EAAgBgQ,WAAS,SAAC1P,GAAO,OAAA,GAAK,EAAIzI,KAAK4J,KAAKnB,OAE3C2P,GAA8B,CACzCjY,WAAYgY,UACZ9X,YAAa,MACbC,WAAY4X,aCREG,GACZxY,EAAqByY,EAAiBhR,EAAgBvK,EACtDhB,GACF,IAAMwc,EAAcC,aAAWC,iBAAiB1b,EAAOub,EAAOhR,GACxD5M,EAASmB,OAAK8E,cAAc2G,GAC5BkI,EAAW3T,OAAKyF,eAAevE,GAErC,GAAIwb,EAAa,CACf,IAAMG,EAAaF,aAAWG,kBAAkBL,EAAO9I,GAEvD,MAAc,WAAVzT,EACM8D,EAAsBsC,MAAMuW,EAAYA,EAAahe,GAGvDmF,EAAoB2W,SAASkC,EAAYA,EAAahe,GAShE,IANA,IAAMwO,EAAwB,WAAVnN,EAChBoB,eAAa+H,uBAAuBrF,GACpCA,EAEE+Y,EAAQja,SAAO5B,EAAOhB,EAAOmN,GAC7BnB,EAASpJ,SAAO2I,EAAMvL,GACnBf,EAAI,EAAGA,EAAI+M,EAAOT,OAAQtM,EAAG,CACpC,IAAM6d,EAAS9Q,EAAO9F,WAAWjH,GAC3B8d,EAAQD,EAAOjb,KAAI,SAACmb,EAAa/Q,GAAM,OAAA+Q,EAAMT,EAAMtQ,MACzDD,EAAOxK,UAAPwK,KAAW6Q,EAAM1b,UAAN0b,IAAaE,KAAWD,IAGrC,MAAc,WAAV9c,EACKoB,eAAa6b,uBAAuBjR,EAAOjL,QAE7CiL,EAAOjL,MAChB,UAEgBqF,GACZ5B,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA8X,UAAOhR,SAEd9L,EAAiBgF,EAAG,SAEd,IAAAuD,4CAACkV,OAAQC,OACfV,aAAWW,kBAAkB3Y,EAAGyY,EAAQC,GAExC,IACM1R,EAAU6Q,GADH3X,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACRmc,EAAQC,EAAO1Y,EAAEzD,MAAOyD,EAAEzE,OAC1D,OAAO2E,EAAQ5B,eAAeoa,EAAO1Y,EAAEzE,MAAOyL,EAChD,CAEO,IAAM4R,GAA4B,CACvCjZ,WAAYkZ,QACZhZ,YAAa,MACbC,WAAY6B,aC1DEmX,GACZ5B,EAAqB6B,EAAwBC,EAC7C1c,EAAoBsU,EAAuBqI,EAC3CpI,GAEF,IAAMqI,EAAeH,EAAa,GAC5BI,EAAYF,EAAW,GAEvBG,EAA+B,IAAI/hB,MAAM8hB,GACzCE,EAA4B,IAAIhiB,MAAM6hB,GAEtC1B,EAAOuB,EAAa,GAE1B,GAAkB,IAAdI,EAAiB,CACnB,GAAqB,IAAjBD,EACF,MAAM,IAAI9a,MACNzB,eAAa2c,gDACTJ,IAIV,MAAO,CAFDK,EAAgBle,OAAKwM,kBAAkBmR,EAAc,GAG1C,CAAC,EAAGxB,GAFfgC,EAAene,OAAKwM,kBAAkB+I,EAAa,GAEfwI,EAAmBC,GAQ/D,IAJA,IAAII,GAAiB,EACjBC,EAAiB,EACfC,EAAsB,IAAItiB,MAAM8hB,GAAWjD,KAAK,GAE7C1b,EAAI,EAAGA,EAAI0e,IAAgB1e,EAAG,CAGrC,IADMoO,EAAMsO,EAAQ1c,EAAIgd,IACd,EACR,MAAM,IAAIpZ,MACNzB,eAAaid,gDAAgDpf,EAAGoO,IAEtE,GAAIA,GAAOuQ,EACT,MAAM,IAAI/a,MACNzB,eAAakd,kDACTrf,EAAGoO,EAAKuQ,MAEhBQ,EAAU/Q,GACZ6Q,EAAiBA,GAAmB7Q,GAAO8Q,EAC3CA,EAAiB9Q,EAInB,IADA,IAAIkR,GAAc,EACTlR,EAAM,EAAGA,EAAMuQ,IAAavQ,EAAK,CAExC,IAAMmR,EAA+B,IAAnBJ,EAAU/Q,GAC5BwQ,EAAkBxQ,GAAOmR,EACzBD,EAAcA,IAAgBC,EAE9BJ,EAAU/Q,GAAOpJ,KAAKsN,IAAI6M,EAAU/Q,GAAM,GAOtCA,EAAM,IACR+Q,EAAU/Q,IAAQ+Q,EAAU/Q,EAAM,IAItC,GAAIkR,GAAeL,EAAgB,CACjC,IAAMF,EAA4BrC,EAC5BsC,EAA2Bld,EACjC,IAAS9B,EAAI,EAAGA,EAAI0e,IAAgB1e,EAClC6e,EAAgB7e,GAAKA,EAEvB,MAAO,CACL+e,EAAe,CAACL,EAAc1B,GAAOgC,EAAcJ,EACnDC,GAGF,IAAMW,EAAmBL,EAAUR,EAAY,GAMzCc,GALAV,EACFle,OAAKwM,kBAAkBmR,EAAcgB,EAAmBxC,GAEtDgC,EACFne,OAAKwM,kBAAkB+I,EAAaoJ,GACV,IAAI3iB,MAAM8hB,GAAWjD,KAAK,IAGxD,IAAS1b,EAAI,EAAGA,EAAI0e,IAAgB1e,EAAG,CAErC,IACMqS,EAASoN,EADTrR,EAAMsO,EAAQ1c,EAAIgd,IAElB0C,GAAoB,IAARtR,EAAa,EAAI+Q,EAAU/Q,EAAM,IAAMiE,EACzDoN,EAAYrR,KACZ,IAAK,IAAIpB,EAAI,EAAGA,EAAIgQ,IAAQhQ,EAE1B+R,EAAcW,EAAU1C,EAAOhQ,GAAK0P,EAAQ1c,EAAIgd,EAAOhQ,GAEzDgS,EAAaU,GAAW5d,EAAO9B,GAE/B6e,EAAgB7e,GAAK0f,EAIvB,IAAStR,EAAM,EAAGA,EAAMuQ,IAAavQ,EAAK,CAExC,GAAiB,IADAqR,EAAYrR,GACT,CAClB,IAAMuR,EAAyB,IAARvR,EAAa,EAAI+Q,EAAU/Q,EAAM,GAIxD2Q,EAAcY,EAAgB3C,EAAO,GAAK5O,EAC1C,IAAK,IAAIE,EAAM,EAAGA,EAAM0O,IAAQ1O,EAC9ByQ,EAAcY,EAAgB3C,EAAO1O,GAAO,EAE9C0Q,EAAaW,GAAiBtJ,GAGlC,MAAO,CACL0I,EAAe,CAACS,EAAkBxC,GAAOgC,EAAcJ,EACvDC,EAGN,UCzHgBe,GACZC,EAA0BC,EAA6BC,EACvDC,EACAC,GAUF,IATA,IAAMC,EAAYrf,OAAK8E,cAAcqa,GAC/BG,EAAML,EAAkB,GACxBM,EAAaH,EAAYvgB,OAIzBsa,EAAwB,GAC1BqG,EAAU,EACVC,GAAgB,EACX9jB,EAAI,EAAGA,EAAI4jB,IAAc5jB,EAAG,CACnC,IAAM8P,EAAO2T,EAAYzjB,GACzB,IAAc,IAAV8P,EAAa,CACf,IAAsB,IAAlBgU,EACF,MAAM,IAAI1c,MACNzB,eACKoe,yDACGD,EAAc9jB,IAE5B8jB,EAAe9jB,EACfwd,EAAYra,KAAK,OACZ,CACL,GAAI2M,EAAO,EACT,MAAM,IAAI1I,MACNzB,eAAaqe,8CACThkB,EAAG8P,IAEb+T,GAAW/T,EACX0N,EAAYra,KAAK2M,IAGrB,IAAsB,IAAlBgU,EAAqB,CACvB,GAAID,GAAW,EACb,MAAM,IAAIzc,MACNzB,eAAase,wDAEnB,IAAMC,EAAU1b,KAAK2b,MAAMT,EAAYG,GACvC,GAAIA,EAAUK,IAAYR,EACxB,MAAM,IAAItc,MACNzB,eAAaye,gDACTZ,EAAYhG,IAGtBA,EAAYsG,GAAgBI,EAG9B,GADmB7f,OAAK8E,cAAcqU,KACnBkG,EACjB,MAAM,IAAItc,MACNzB,eAAa0e,gDACTb,EAAYhG,IAGtB,IAAM8G,EAAYd,EAAWtgB,OACvBqhB,EAAyB,GAC/B,GAAID,EAAY,EAAG,CACjBC,EAAaD,EAAY,GAAK,EAC9B,IAAStkB,EAAIskB,EAAY,EAAGtkB,GAAK,IAAKA,EACpCukB,EAAavkB,GAAKukB,EAAavkB,EAAI,GAAKwjB,EAAWxjB,EAAI,GAI3D,IAAMwkB,EAA0B,GAChC,GAAIZ,EAAa,EAAG,CAClBY,EAAcZ,EAAa,GAAK,EAChC,IAAS5jB,EAAI4jB,EAAa,EAAG5jB,GAAK,IAAKA,EACrCwkB,EAAcxkB,GAAKwkB,EAAcxkB,EAAI,GAAKwd,EAAYxd,EAAI,GAM9D,IAFA,IAAMykB,EACFpgB,OAAKwM,kBAAkB0S,EAAYI,EAAMC,GACpCpgB,EAAI,EAAGA,EAAImgB,IAAOngB,EAAG,CAE5B,IADA,IAAIsC,EAAK,EACA0K,EAAI,EAAGA,EAAI8T,IAAa9T,EAE/B1K,GAAMud,EAAa7f,EAAI8gB,EAAY9T,GAAK+T,EAAa/T,GAEvD,IAASA,EAAI,EAAGA,EAAIoT,IAAcpT,EAEhCiU,EAAWjhB,EAAIogB,EAAapT,GAAKhI,KAAK2b,MAAMre,EAAK0e,EAAchU,IAC/D1K,GAAM0e,EAAchU,GAGxB,MAAO,CAACiU,EAAY,CAACd,EAAKC,GAAapG,EACzC,UCvFgBkH,GACZ7Y,EAAmB2X,EAAsBD,EACzCrD,EAAqByE,EAAwBC,EAC7C/K,gBAD6C+K,mBAC7C/K,KACF,IAAMgL,EAAa3E,EAAQhd,OAGrB4hB,EAAsB,CAACtB,EAAW,GAAI3X,EAAM3I,OAASsgB,EAAW,IAChEuB,EAASD,EAAU,GAKnBE,EADFH,EAAa,EAAIF,EAAWE,EAAa,GAAK,EAAI,EAGtD,GAAIG,EAAa,EACf,MAAM,IAAI5d,MACNzB,eAAasf,2DAGnB,IAAMzH,EAAcgG,EAAW7Y,QAC/B6S,EAAY,GAAKwH,EAEjB,IAAME,EACF1H,EAAY2H,QAAO,SAACtB,EAAS1iB,GAAU,OAAA0iB,EAAU1iB,IAAO,GAEtDikB,EAAS/gB,OAAKwM,kBAAkB0S,EAAY2B,GAIlD,GAAmB,IAAfL,EAIF,OAHIG,EAAa,GACfI,EAAOlG,KAAKrF,GAEP,CAACuL,EAAQ5H,GAGlB,GAAIwH,GAAc,EAChB,MAAM,IAAI5d,MACNzB,eAAasf,2DAQnB,IALA,IAAItd,EAAQ,EAAG0d,EAAM,EAEjBC,EAAqB,EACrBC,EAAWZ,EAAWhd,KAEb,CAEX,IAAI6d,EAAY,EAChB,GAAIH,EAAMR,EAAY,CAEpB,GAAIU,KADJC,EAAYb,EAAWU,IACK,GACxBA,EACF,SAGF,GAAIE,GAAYC,EACd,MAAM,IAAIpe,MAAMzB,eACX8f,gEAIT,GAAIF,EAAW,GAAKA,GAAYP,EAC9B,MAAM,IAAI5d,MACNzB,eAAa+f,yDACTH,EAAUP,IAKhBO,EAAWD,GACbF,EAAOlG,KAAKrF,EAAcyL,EAAqBP,EAAQQ,EAAWR,GAGpE,IAAK,IAAIvhB,EAAImE,EAAOnE,EAAI6hB,IAAO7hB,EAAG,CAChC,IAAMgQ,EAAQ0M,EAAQ1c,GACtB,GAAIgQ,EAAQ,GAAKA,GAASsR,EAAU,GAClC,MAAM,IAAI1d,MACNzB,eAAaggB,uDACTniB,EAAG0c,EAAQ1c,GAAIshB,EAAU,KAEnC,IAAK,IAAItU,EAAI,EAAGA,EAAIuU,EAAQvU,IAC1B4U,EAAOG,EAAWR,EAASvU,IAAM3E,EAAM2H,EAAQuR,EAASvU,GAI5D,GAAIoU,EACF,IAASpU,EAAI,EAAGA,EAAIuU,EAAQvU,IAC1B4U,EAAOG,EAAWR,EAASvU,IAAM6U,EAAM1d,EAQ3C,GAJAA,EAAQ0d,EAERC,EAAqBC,EAAW,EAChCA,EAAWC,IAFTH,EAGQR,EACR,MASJ,OAJIS,EAAqBN,GACvBI,EAAOlG,KAAKrF,EAAcyL,EAAqBP,EAAQC,EAAaD,GAG/D,CAACK,EAAQ5H,EAClB,CCzGO,IAAMoI,GAAWnV,GAAsB,SAACQ,GAAO,OAAAzI,KAAKqX,KAAK5O,MACnD4O,GAAOlP,EAAgBkV,QAAM,SAAC5U,GAAO,OAAAzI,KAAKqX,KAAK5O,MAE/C6U,GAA2B,CACtCnd,WAAYkd,OACZhd,YAAa,MACbC,WAAY+W,ICNDkG,GACT1c,YAA+BmE,EAAWvN,GACxC,IAAM+lB,EAAOxY,EAAIvN,EACjB,OAAO+lB,EAAOA,CACf,IACQC,GACT7Y,EAAiB8Y,oBAAmBH,IAE3BI,GAAwC,CACnDxd,WAAYud,oBACZrd,YAAa,MACbC,WAAYmd,aCdEG,GACZ9U,EAAoBpB,EAAuBmD,EAC3CyN,GAGF,IAFA,IAAMvQ,EAASpJ,SAAOmK,EAAUpB,EAAK3L,OAE5Bf,EAAI,EAAGA,EAAI+M,EAAOT,KAAMtM,IAAK,CAIpC,IAHA,IAAMgH,EAAM+F,EAAO9F,WAAWjH,GAExB0U,EAAmB,IAAI7X,MAAMmK,EAAItH,QAC9BsN,EAAI,EAAGA,EAAI0H,EAAOhV,OAAQsN,IACjC0H,EAAO1H,GAAKhG,EAAIgG,GAAK6C,EAAQ7C,GAAKsQ,EAAMtQ,GAE1CD,EAAOxK,UAAPwK,KAAWL,EAAKxK,UAALwK,IAAYgI,KAAY1N,IAGrC,OAAO+F,CACT,CCVA,kBAQE,WACI8V,EAAmBC,EAAuBC,EAC1CC,EAAkBC,EAAkBC,GACtC9jB,KAAKyjB,UAAYhiB,OAAKgC,aAAaggB,GACnCzjB,KAAK0jB,YAAcA,EACnB1jB,KAAK2jB,QAAUliB,OAAKgC,aAAakgB,GACjC3jB,KAAK4jB,SAAWniB,OAAKgC,aAAamgB,GAClC5jB,KAAK6jB,SAAWA,EAChB7jB,KAAK+jB,cAAgBD,SAGfE,wBAAA,SAAYC,GAIlB,OAAOre,KAAKgO,IACR5T,KAAK6jB,SAAW,EAAII,EAAa,EAAIjkB,KAAK6jB,SAAUI,EAAa,IAG/DD,yBAAA,SAAa1jB,EAAgB2jB,GACnC,IAAMJ,EAAW7jB,KAAKkkB,YAAYD,GAClC,OAAOre,KAAKsN,IAAI,EAAK5S,EAAS,EAAIujB,EAAYI,EAAc,IAGtDD,yBAAA,SACJhiB,EAAoBmiB,EAAoB3B,EACxC4B,EAA0BC,EAAmBJ,GAC/C,mBAASK,GACP,IAAMT,EAAWU,EAAKL,YAAYD,GAC5BO,EAAc5e,KAAKsN,IAAI,EAAG2Q,EAAWS,GACrCG,EACF7e,KAAKsN,IAAI,EAAG2Q,GAAYQ,GAAaC,EAAa,KAChDI,EAAYT,GAAcO,EAAcC,GACxCE,EACFR,GAAcK,EAAc,EAAI,EAAIF,EAAaT,GAIjDe,EAAY,EAEhBA,GAAaJ,EAAcD,EAAKZ,QAAQrjB,OAExC,IAAK,IAAIL,EAAI,EAAGA,EAAIykB,IAAazkB,EAC/B2kB,GAAa5iB,EAAK2iB,EAAiB1kB,GAAGK,OAGxCskB,GAAaH,EAAeF,EAAKX,SAAStjB,OAG1CskB,IADsBJ,EAAcC,EAAeC,EAAY,GAClCH,EAAKd,UAAUnjB,OAG5CkiB,EAAO4B,EAAmBE,GAAc,IAAIO,WAAWD,GACvD,IAAME,EAAQtC,EAAO4B,EAAmBE,GAEpCS,EAAiB,EACfC,EAAgB,SAACC,GACnB,OAAAA,EAAIzjB,SAAQ,SAACjD,GAAU,OAAAumB,EAAMC,KAAoBxmB,MAErD,IAAS0B,EAAI,EAAGA,EAAIukB,IAAevkB,EACjC+kB,EAAcT,EAAKZ,SACnBqB,EAAcT,EAAKd,WAGrB,IAASxjB,EAAI,EAAGA,EAAIykB,EAAY,IAAKzkB,EACnC+kB,EAAchjB,EAAK2iB,EAAiB1kB,IACpC+kB,EAAcT,EAAKd,WAIrB,GAAIiB,EAAY,EAAG,CAIjBM,EAAchjB,EAAK2iB,EAAiBD,EAAY,IAChD,IAASzkB,EAAI,EAAGA,EAAIwkB,IAAgBxkB,EAClC+kB,EAAcT,EAAKd,WACnBuB,EAAcT,EAAKX,cAEhB,CAKL,IAAS3jB,EAAI,EAAGA,EAAIwkB,EAAe,IAAKxkB,EACtC+kB,EAAcT,EAAKX,UACnBoB,EAAcT,EAAKd,WAErBuB,EAAcT,EAAKX,mBA7DdU,EAAa,EAAGA,EAAaD,IAAaC,IAA1CA,IAqEJN,oBAAA,SAAQhiB,EAAoBkjB,GAA5B,WAICC,EAAgBnjB,EAAK1B,OACrB8kB,EAAaF,EAAO5kB,OAC1B,GAAI8kB,EAAa,EAAG,CAClB,IAAIC,EAAYH,EAAO,GACvB,GAAkB,IAAdG,EACF,MAAM,IAAI7gB,MAAM,oCAAoC6gB,GAEtD,IAAK,IAAIzkB,EAAI,EAAGA,EAAIwkB,IAAcxkB,EAAG,CACnC,IAAI0kB,EAAcJ,EAAOtkB,IAAMykB,EAE/B,KADAC,EAAcA,GAAgBJ,EAAOtkB,IAAMukB,GAEzC,MAAM,IAAI3gB,MAAM,uBAAuB0gB,EAAOtkB,oBAC1CykB,OAAcF,OAEpBE,EAAYH,EAAOtkB,GAErB,GAAIykB,IAAcF,EAChB,MAAM,IAAI3gB,MAAM,gDACZ2gB,WAAsBE,GAI9B,IAAME,EAAgBH,EAAa,EAC7BI,EAAe/jB,OAAKwM,kBAAkB,QAASmX,GAErD,GAAsB,IAAlBD,GAAsC,IAAfC,EAAkB,CAC3C,IAAMK,EAAsB,IAAIhoB,MAAM0nB,GACtC,IAASvkB,EAAI,EAAGA,GAAK2kB,IAAiB3kB,EACpC4kB,EAAa5kB,GAAK,EAEpB,MAAO,CAAC6kB,EAAOD,GAGjBA,EAAa,GAAK,iBACT5kB,GACP,IAAMN,EAAS4kB,EAAOtkB,GAAKskB,EAAOtkB,EAAI,GAClCyjB,EAAY,EAChBqB,EAAKhC,YAAYliB,SAAQ,SAACyiB,GACxBI,GAAatiB,EAAK4jB,aAAarlB,EAAQ2jB,MAErCyB,EAAK3B,eAAiBzjB,EAAS,GAAmB,IAAd+jB,IACtCA,EAAY,GAEdmB,EAAa5kB,GAAK4kB,EAAa5kB,EAAI,GAAKyjB,UAT1C,IAASzjB,EAAI,EAAGA,GAAK2kB,IAAiB3kB,IAA7BA,GAYT,IAAMglB,EAAuB,IAAInoB,MAAM+nB,EAAaD,eAE3C3kB,GACP,IAAMujB,EAAae,EAAOtkB,GACtBilB,EAAiBL,EAAa5kB,GAalC,GAZAklB,EAAKpC,YAAYliB,SAAQ,SAACyiB,GACxB,IAAM3jB,EAAS4kB,EAAOtkB,EAAI,GAAKskB,EAAOtkB,GAChCyjB,EAAYtiB,EAAK4jB,aAAarlB,EAAQ2jB,GAC5CliB,EAAKgkB,aACD/jB,EAAMmiB,EAAYyB,EAAQC,EAAgBxB,EAAWJ,GACzD4B,GAAkBxB,KAOhByB,EAAK/B,eAAiB8B,IAAmBL,EAAa5kB,GAAI,CAC5D,IAAMolB,EAAad,EAAOtkB,EAAI,GAAKskB,EAAOtkB,GAG1C,GAAmB,IAAfolB,mBAMJ,IAAM/B,EAAa+B,EAAa,EAAIF,EAAKjC,SAEzCiC,EAAKC,aACD/jB,EAAMmiB,EAAYyB,EAAQC,EAFZ,EAEuC5B,YA5B7D,IAASrjB,EAAI,EAAGA,EAAI2kB,IAAiB3kB,IAA5BA,GA+BT,MAAO,CAACglB,EAAQJ,kBAIJS,GACZjkB,EAAoBkkB,EAAwBzC,EAC5CC,EAAuBC,EAAiBC,EAAkBC,EAC1DC,GACF,OAAO,IAAIE,GACAP,EAAWC,EAAaC,EAASC,EAAUC,EAC3CC,GACNjH,QAAQ7a,EAAMkkB,EACrB,CC7MA,SAASC,GACLlB,EAAiBmB,EAAwBC,EACzCznB,GACF,GAAKqmB,EAAI3kB,OAIT,GAA0B,IAAtB8lB,EAAW9lB,OAOf,GAA0B,IAAtB8lB,EAAW9lB,OAkBf,KAAIgmB,EAAa,EACjB,IAAS1lB,EAAI,EAAGA,EAAIqkB,EAAI3kB,OAAS,EAAGM,IAClC,GAAKA,IAAMqkB,EAAI3kB,SAA4C,IAAhC8lB,EAAWG,QAAQtB,EAAIrkB,IAAa,CACvD4lB,EAAQvB,EAAI7I,SAASkK,EAAY1lB,GAClCylB,GAA8B,IAAjBG,EAAMlmB,QACtB1B,EAAO2B,KAAKimB,GAEdF,EAAa1lB,EAAI,EAPH,KAlBlB,CAGE,IAFA,IAAM6lB,EAAYL,EAAW,GACzBlnB,EAAI+lB,EAAIsB,QAAQE,IACN,IAAPvnB,GAAU,CACf,IAAMsnB,EAAQvB,EAAI7I,SAAS,EAAGld,GACzBmnB,GAA8B,IAAjBG,EAAMlmB,QACtB1B,EAAO2B,KAAKimB,GAGdtnB,GADA+lB,EAAMA,EAAI7I,SAASld,EAAI,IACfqnB,QAAQE,GAEbJ,GAA4B,IAAfpB,EAAI3kB,QACpB1B,EAAO2B,KAAK0kB,QAlBd,IAAK,IAAIrkB,EAAI,EAAGA,EAAIqkB,EAAI3kB,SAAUM,EAChChC,EAAO2B,KAAK0kB,EAAI7I,SAASxb,EAAGA,EAAI,GAiCtC,UAEgB8lB,GACZzd,EAAqBwd,EACrBJ,GASF,IARA,IAAMM,EAAY1d,EAAM3I,OAGlBsmB,EAAuB,GAEzBjN,EAAa,EACbkN,EAAgB,EACd5E,EAAuB,IAAIxkB,MAAMkpB,GAC9B/lB,EAAI,EAAGA,EAAI+lB,IAAa/lB,EAAG,CAClC,IAAMkmB,EAAmBF,EAAOtmB,OAChC6lB,GAAMld,EAAMrI,GAAI6lB,EAAWJ,EAAWO,GACtC,IAAMG,EAAWH,EAAOtmB,OAASwmB,EACjC7E,EAAWrhB,GAAKmmB,EAChBpN,GAAcoN,EACdF,EAAgBjhB,KAAKsN,IAAI2T,EAAeE,GAG1C,IAAMzJ,EAAU7b,OAAKwM,kBAAkB,QAAsB,EAAb0L,GAC1CjX,EAAuB,IAAIjF,MAAMkc,GACjChX,EAA0B,CAACgkB,EAAWE,GAExCG,EAAI,EACR,IAASpmB,EAAI,EAAGA,EAAI+lB,IAAa/lB,EAC/B,IAAK,IAAIgN,EAAI,EAAGA,EAAIqU,EAAWrhB,KAAMgN,EAEnC0P,EAAY,EAAJ0J,GAASpmB,EACjB0c,EAAY,EAAJ0J,EAAQ,GAAKpZ,EACrBlL,EAAOskB,GAAKJ,EAAOI,KACjBA,EAIN,MAAO,CAAC1J,EAAS5a,EAAQC,EAC3B,UChFgBskB,GACZhe,EAAqBie,GAGvB,IAFA,IAAM1E,EAAS/gB,OAAKwM,kBAAkB,QAAShF,EAAM3I,QAE5CM,EAAI,EAAGA,EAAIqI,EAAM3I,SAAUM,EAClC4hB,EAAO5hB,GACHa,OAAK0lB,cAAcle,EAAMrI,IAAIwmB,OAAOF,GAAYG,qBAGtD,OAAO7E,CACT,CCPO,IAAM8E,GAAU7gB,YACjB6M,EAAgBC,GAAmB,OAAAD,EAASC,CAAM,IAC3CgU,GACTrb,YAAgCf,EAAOC,EAAOK,EAAOC,GACnD,MAAO,CAACzH,KAAMkH,EAAQM,EAAOtH,KAAMiH,EAAQM,EAC5C,IACQ8b,GAAMhd,EAAiBid,MAAKH,GAASC,IAErCG,GAA0B,CACrC3hB,WAAY0hB,MACZxhB,YAAa,MACbC,WAAYshB,aCTEG,GACZra,EACAsa,GAEF,IADA,IAAM9gB,EAAqB,IAAIrJ,MAAM6P,EAAKsQ,MACjChd,EAAI,EAAGA,EAAIkG,EAASxG,OAAQM,IACnCkG,EAASlG,GAAK0M,EAAK3K,MAAM/B,GAAKgnB,EAAKhnB,GAErC,IAAMhC,EAAS2F,SAAOuC,EAAUwG,EAAK3L,OACrC,IAASf,EAAI,EAAGA,EAAIhC,EAAO8D,OAAOpC,SAAUM,EAAG,CAI7C,IAHA,IAAM0U,EAAS1W,EAAOiJ,WAAWjH,GAE3BuQ,EAAwB,IAAI1T,MAAM6P,EAAKsQ,MACpChQ,EAAI,EAAGA,EAAIuD,EAAY7Q,OAAQsN,IACtCuD,EAAYvD,GAAK0H,EAAO1H,GAAKN,EAAK3K,MAAMiL,GAG1C,IAAM2D,EAAgBjE,EAAKrF,WAAWkJ,GAEtCvS,EAAO8D,OAAO9B,GAAK0M,EAAK5K,OAAO6O,GAEjC,OAAO3S,CACT,CCnBA,IAAMipB,GAAc,SAACjd,EAASvN,GAC5B,IAAMyqB,EAAYzqB,EAAEkB,MAAQqM,EAAErM,MAC9B,OAAqB,IAAdupB,EAAkBld,EAAEgG,MAAQvT,EAAEuT,MAAQkX,CAC/C,EAaA,SAASC,GAAOC,EAAejX,EAAWkX,EAAUC,GAClD,iBADwCD,kBAAUC,EAAQF,EAAM1nB,OAAS,GAClE4nB,EAAQD,GAAM,CAInB,GAAIC,EAAQD,EAAO,IAAK,CACtB,IAAMhoB,EAAIioB,EAAQD,EAAO,EACnB1S,EAAIxE,EAAIkX,EAAO,EACfE,EAAIviB,KAAKgN,IAAI3S,GACbS,EAAI,GAAMkF,KAAK4J,IAAI,EAAI2Y,EAAI,GAC3BC,EAAK,GAAMxiB,KAAKqX,KAAKkL,EAAIznB,GAAKT,EAAIS,GAAKT,GAAK2F,KAAKyiB,KAAK9S,EAAItV,EAAI,GAGpE8nB,GAAOC,EAAOjX,EAFEnL,KAAKsN,IAAI+U,EAAMriB,KAAKoK,MAAMe,EAAIwE,EAAI7U,EAAIT,EAAImoB,IACzCxiB,KAAKgO,IAAIsU,EAAOtiB,KAAKoK,MAAMe,GAAK9Q,EAAIsV,GAAK7U,EAAIT,EAAImoB,KAIpE,IAAMhpB,EAAI4oB,EAAMjX,GACZnQ,EAAIqnB,EACJra,EAAIsa,EAOR,IALAzmB,OAAK6mB,KAAKN,EAAOC,EAAMlX,GAEnB8W,GAAYG,EAAME,GAAQ9oB,GAAK,GACjCqC,OAAK6mB,KAAKN,EAAOC,EAAMC,GAElBtnB,EAAIgN,GAAG,CAIZ,IAHAnM,OAAK6mB,KAAKN,EAAOpnB,EAAGgN,GACpBhN,IACAgN,IACOia,GAAYG,EAAMpnB,GAAIxB,GAAK,GAChCwB,GAAQ,EAEV,KAAOinB,GAAYG,EAAMpa,GAAIxO,GAAK,GAChCwO,GAAQ,EAGwB,IAAhCia,GAAYG,EAAMC,GAAO7oB,GAC3BqC,OAAK6mB,KAAKN,EAAOC,EAAMra,IAEvBA,GAAQ,EACRnM,OAAK6mB,KAAKN,EAAOpa,EAAGsa,IAIlBta,GAAKmD,IACPkX,EAAOra,EAAI,GAETmD,GAAKnD,IACPsa,EAAQta,EAAI,GAGlB,UAEgB2a,GACZniB,EAAekO,EAAkBC,EAAyBxD,EAC1DyX,GAQF,IALA,IAAMC,EAAUnU,EAAOA,EAAOhU,OAAS,GACjCqJ,sBAAC+e,OAAOxb,OACRyb,EAAclnB,OAAK2F,uBAAuBmN,EAAQmU,EAAQ3X,GAC1D6X,EAAiBnnB,OAAK2F,uBAAuB,QAASshB,EAAQ3X,cAE3D1T,GACP,IAAM4V,EAAS5V,EAAI6P,EACbzH,EAAOW,EAAEgW,SAASnJ,EAAQA,EAAS/F,GAErC2b,EAAoB,IAAIprB,MAAMgI,EAAKnF,QACvCmF,EAAKjE,SACD,SAACjD,EAAeqS,GAAkB,OAAAiY,EAAUjY,GAAS,CAACrS,QAAOqS,YAE7DG,EAAI8X,EAAUvoB,SAChBynB,GAAOc,EAAW9X,GAClB8X,EAAYA,EAAU9gB,MAAM,EAAGgJ,IAG7ByX,GACFK,EAAUC,KAAKjB,IAMjB,IAHA,IAAMkB,EAAY1rB,EAAI0T,EAChBiY,EAAWL,EAAYvM,SAAS2M,EAAWA,EAAYhY,GACvDkY,EAAcL,EAAexM,SAAS2M,EAAWA,EAAYhY,GAC1DnQ,EAAI,EAAGA,EAAImQ,EAAGnQ,IACrBooB,EAASpoB,GAAKioB,EAAUjoB,GAAGrC,MAC3B0qB,EAAYroB,GAAKioB,EAAUjoB,GAAGgQ,OAtBzBvT,EAAI,EAAGA,EAAIqrB,EAAOrrB,MAAlBA,GA2BT,IAAMud,EAActG,EAAOvM,QAG3B,OAFA6S,EAAYA,EAAYta,OAAS,GAAKyQ,EAE/B,CACLxM,SAAOqW,EAA4BrG,EAAQoU,GAC3CpkB,SAAOqW,EAA4B,QAASgO,GAEhD,UCxHgBM,GACZxmB,EAAuByT,EAAcxT,EAAiBhB,GAgExD,IA1DA,IAAMwnB,EAAQ1nB,OAAK6U,eAAeH,EAAMxT,GAAO,GAyDzCmE,EAAW,CAAC,EAAGnE,EAAM,GAAI,GACtB/B,EAAI,EAAGA,EAAIuoB,EAAOvoB,IACzBkG,EAAS,IAAMnE,EAAM/B,GAEvBkG,EAAS,GAAKnE,EAAMwmB,GACpB,IAASvoB,EAAIuoB,EAAQ,EAAGvoB,EAAI+B,EAAMrC,OAAQM,IACxCkG,EAAS,IAAMnE,EAAM/B,GAKvB,IAAMwoB,EAA0C,GAG1C9L,EAAU,IAAI/T,WAAW5G,EAAMwmB,IAE/BE,EAAc,IAAIC,eAAaxiB,EAAUnF,EAAOe,GAGhD6mB,EAA0B,GAC1BC,EAA6B,IAAhB1iB,EAAS,IAA4B,IAAhBA,EAAS,GACjD,IAASlG,EAAI,EAAGA,EAAI+B,EAAMwmB,GAAQvoB,IAAK,CAErC,IAAI6oB,SACJ,GAAID,EAEFC,EAAU/mB,EAAO9B,GAAG8oB,eACf,CAEL,IADA,IAAMC,EAAa,GACVhpB,EAAI,EAAGA,EAAImG,EAAS,GAAInG,IAC/B,IAAK,IAAIV,EAAI,EAAGA,EAAI6G,EAAS,GAAI7G,IAC/B0pB,EAAWppB,KAAK8oB,EAAYvmB,IAAInC,EAAGC,EAAGX,IAG1CwpB,EAAUE,EAAWC,KAAK,KAI5B,QAAgCC,IAA5BT,EAAeK,GACjBnM,EAAQ1c,GAAKwoB,EAAeK,OACvB,CACL,IAAMK,EAAcxsB,OAAOysB,KAAKX,GAAgB9oB,OAChD8oB,EAAeK,GAAWK,EAC1BxM,EAAQ1c,GAAKkpB,EACbP,EAAchpB,KAAKK,IAOvB,IAAMopB,EAAiBljB,EAASiB,QAChCiiB,EAAe,GAAK1sB,OAAOysB,KAAKX,GAAgB9oB,OAChD,IAAM2pB,EAAe,IAAIX,eAAaU,EAAgBroB,GACtD4nB,EAAc/nB,SAAQ,SAAC0oB,EAAoBtpB,GACzC,IAAK,IAAID,EAAI,EAAGA,EAAImG,EAAS,GAAInG,IAC/B,IAAK,IAAIV,EAAI,EAAGA,EAAI6G,EAAS,GAAI7G,IAC/BgqB,EAAa9mB,IAAIkmB,EAAYvmB,IAAInC,EAAGupB,EAAoBjqB,GAAIU,EAAGC,EAAGX,MAOxE,IAAM2a,EAAcjY,EAAMoF,QAG1B,OAFA6S,EAAYuO,GAASa,EAAe,GAE7B,CACLpK,aAAcqK,EAAavnB,OAC3BkY,cACA0C,UAEJ,owBC7HgB,OAAO,WAAM,OAAA,IAAI9a,IAAkB,GCT5C,IAAM2nB,GACTpc,EAAgBqc,OAAK,SAAC/b,GAAO,OAAAA,GAAM,EAAIA,EAAMzI,KAAK4J,IAAInB,GAAM,KAEnDgc,GAA0B,CACrCtkB,WAAYqkB,MACZnkB,YAAa,MACbC,WAAYikB,aCLEG,GAAUnkB,GAKjB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACAmkB,UAEPnpB,EAAiB,CAACgF,GAAI,aAMtB,IAJA,IAAM4H,EAAQvM,OAAK8E,cAAcH,EAAEzD,OAC7BmK,EAAQxG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACnC0K,EAAU3L,OAAK2F,uBAAuB,UAAW4G,GAE9CpN,EAAI,EAAGA,EAAIkM,EAAMxM,OAAQM,IAChCwM,EAAQxM,GAAKkM,EAAMlM,GAAK,EAAI2pB,EAAQzd,EAAMlM,GAAKkM,EAAMlM,GAGvD,OAAO0F,EAAQ5B,eAAe0B,EAAEzD,MAAO,UAAWyK,EACpD,CAEO,IAAMod,GAAgC,CAC3CzkB,WAAY0kB,YACZxkB,YAAa,MACbC,WAAYokB,ICxBRI,GAAYjkB,GACd,SAACkkB,EAAgBrX,GAAmB,OAAAqX,EAAS,EAAIrX,EAASqX,EAASA,cAEvDC,GAAMzkB,GAEb,IAAAkC,WAAQ/B,YACRF,MAAGmkB,UAEVnpB,EAAiB,CAACgF,EAAGmkB,GAAQ,SAE7B,IAAM3jB,EAAQN,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACnCmE,EAAQP,EAAQtE,KAAKc,IAAIynB,EAAMtnB,QAAQP,OAEvCiH,yCAACC,OAAYQ,OAGnB,OAAO9D,EAAQ5B,eAAe0F,EAAa,UAAWR,EACxD,CAEO,IAAMihB,GAA4B,CACvC9kB,WAAY+kB,QACZ7kB,YAAa,MACbC,WAAY0kB,ICxBDG,GAAOhd,EAAgBid,QAAM,SAAC3c,GAAO,OAAAzI,KAAKsN,IAAI,EAAG7E,MAEjD4c,GAA2B,CACtCllB,WAAYilB,OACZ/kB,YAAa,MACbC,WAAY6kB,ICLDG,GACTnd,EAAgBod,SAAO,SAAC9c,GAAO,OAAAzI,KAAKgO,IAAIhO,KAAKsN,IAAI,EAAG7E,GAAK,MAEhD+c,GAA4B,CACvCrlB,WAAYolB,QACZllB,YAAa,MACbC,WAAYglB,aCCEG,GACZ/kB,EAAyBF,EAAeklB,EACxCC,EAAqCC,GACvC,GAAmB,WAAfF,EACF,OAAOziB,EAAS,CAACR,OAAQ,CAACjC,KAAIE,YACzB,GAAmB,SAAfglB,EACT,OAAOP,GAAK,CAAC1iB,OAAQ,CAACjC,KAAIE,YACrB,GAAmB,QAAfglB,EACT,OAAOnB,GAAI,CAAC9hB,OAAQ,CAACjC,KAAIE,YACpB,GAAmB,UAAfglB,EACT,OAAOJ,GAAM,CAAC7iB,OAAQ,CAACjC,KAAIE,YACtB,GAAmB,UAAfglB,EACT,OAAOV,GAAM,CAACviB,OAAQ,CAACjC,IAAGmkB,MAAOgB,GAAyBjlB,YACrD,GAAmB,cAAfglB,EACT,OAAOhB,GAAU,CAACjiB,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACygB,MAAOiB,KAClD,GAAmB,YAAfF,EACT,OAAOxN,GAAQ,CAACzV,OAAQ,CAACjC,KAAIE,YAE/B,MAAM,IAAI9B,MACN,cAAc8mB,mDACpB,UC3BgB5P,GACZvV,GAGK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACAzD,UAEDqL,EAAQvM,OAAK8E,cAAcH,EAAEzD,OAC7B8oB,EAAShqB,OAAKiqB,uBAAuB/oB,EAAOqL,GAC5C2d,EAASlqB,OAAK8E,cAAcklB,GAElChqB,OAAKC,OACDsM,IAAU2d,GACV,WAAM,MAAA,kBAAkBF,WAAeE,EAAjC,gCACQvlB,EAAEzD,eAAcqL,EADxB,mFAIV1H,EAAQwC,OAAO1C,EAAEnD,QAEjB,IAAM2oB,EAAQtlB,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAEjC,GAAgC,MAA5B2oB,EAAM7nB,mBAA4B,CACpC,IAAME,EAAO2nB,EAAM7nB,mBAAmBE,KAChCE,EAAOynB,EAAM7nB,mBAAmBI,KAEtCF,EAAKtB,MAAQ8oB,EACbtnB,EAAKxB,MAAQ8oB,EAGf,MAAO,CAACxoB,OAAQmD,EAAEnD,OAAQN,MAAO8oB,EAAQ9pB,MAAOyE,EAAEzE,MACpD,CAEO,IAAMkqB,GAA8B,CACzC9lB,WAAY+lB,UACZ7lB,YAAa,MACbC,WAAYwV,aCjCEqQ,GAAY5lB,GAKnB,IAAAkC,WAAQ/B,YAASwD,UACjBc,MAAGvN,MACH2uB,eAAYC,eAEnB7qB,EAAiB,CAACwJ,EAAGvN,GAAI,UAEzB,IAAMgK,EAAQuD,EAAEjI,MAAMrC,OAChBgH,EAAQjK,EAAEsF,MAAMrC,OAEhB4rB,EAAcF,EAAaphB,EAAEjI,MAAM0E,EAAQ,GAAKuD,EAAEjI,MAAM0E,EAAQ,GAChE8kB,EAAcF,EAAa5uB,EAAEsF,MAAM2E,EAAQ,GAAKjK,EAAEsF,MAAM2E,EAAQ,GAEhE8kB,EAAcJ,EAAaphB,EAAEjI,MAAM0E,EAAQ,GAAKuD,EAAEjI,MAAM0E,EAAQ,GAChEglB,EAAcJ,EAAa5uB,EAAEsF,MAAM2E,EAAQ,GAAKjK,EAAEsF,MAAM2E,EAAQ,GAEhEglB,EAAa1hB,EAAEjI,MAAMoF,MAAM,GAAI,GAC/BwkB,EAAalvB,EAAEsF,MAAMoF,MAAM,GAAI,GAE/BykB,EAAY/qB,OAAK8E,cAAc+lB,GAC/BG,EAAYhrB,OAAK8E,cAAcgmB,GAI/B7d,EAFoBge,iBAAe3lB,2BACrC6D,EAAEjI,MAAMoF,MAAM,GAAI,GAAI1K,EAAEsF,MAAMoF,MAAM,GAAI,IACT5G,OAAO,CAACirB,EAAaC,IAExD5qB,OAAKC,OACDwqB,IAAgBC,GAChB,WAAM,MAAA,kCAAkCD,YACjCC,8BAAuCvhB,EAAEjI,cACzCtF,EAAEsF,yBAAwBqpB,EAC7B,mBAAmBC,oBAmC3B,IAjCA,IAEMU,EAAWV,EAAa,CAACQ,EAAWJ,EAAaF,GACzB,CAACM,EAAWN,EAAaE,GAGjDO,EAAMlR,GAAQ,CAACrT,OAAQ,CAACjC,EAAGwE,GAAItE,UAASwD,MAAO,CAACnH,MANrCqpB,EAAa,CAACQ,EAAWN,EAAaE,GACzB,CAACI,EAAWJ,EAAaF,MAMjDW,EAAMnR,GAAQ,CAACrT,OAAQ,CAACjC,EAAG/I,GAAIiJ,UAASwD,MAAO,CAACnH,MAAOgqB,KAEvDG,EAAYd,EAAaY,EAAIjqB,MAAM,GAAKiqB,EAAIjqB,MAAM,GAClDoqB,EAAUf,EAAaY,EAAIjqB,MAAM,GAAKiqB,EAAIjqB,MAAM,GAChDqqB,EAAWf,EAAaY,EAAIlqB,MAAM,GAAKkqB,EAAIlqB,MAAM,GACjDsqB,EAAWrnB,KAAKsN,IAAIsZ,EAAWC,GAE/BS,EAAY5mB,EAAQtE,KAAKc,IAAI8pB,EAAI3pB,QAAQP,OACzCyqB,EAAY7mB,EAAQtE,KAAKc,IAAI+pB,EAAI5pB,QAAQP,OAEzC0qB,EAAa3rB,OAAKyF,eAAe0lB,EAAIjqB,OACrC0qB,EAAa5rB,OAAKyF,eAAe2lB,EAAIlqB,OAErCgH,qCAAC2jB,OAAQC,OAAYC,OAGrB1pB,qCAAC2pB,OAAYC,OAAYC,OAIzBzgB,EAAO6f,EAAUC,EACjBpuB,EAAS2F,SAAO,CAAC0oB,EAAUF,EAASC,GAAWJ,EAAIjrB,OAEnDisB,EAAUhvB,EAAO8D,OACjBmrB,EAAYvnB,EAAQunB,UAEjBC,EAAK,EAAGA,EAAKb,EAAUa,IAC9B,IAAK,IAAIC,EAAK,EAAGA,EAAKhB,EAASgB,GAAMF,EACnC,IAAK,IAAIG,EAAK,EAAGA,EAAKhB,EAAUgB,GAAMH,EACpC,IAAK,IAAII,EAAK,EAAGA,EAAKnB,EAAWmB,GAAMJ,EAMrC,IAJA,IAAMK,EAAStoB,KAAKgO,IAAIma,EAAKF,EAAWd,GAClCoB,EAASvoB,KAAKgO,IAAIoa,EAAKH,EAAWb,GAClCoB,EAASxoB,KAAKgO,IAAIqa,EAAKJ,EAAWf,GAE/BlsB,EAAImtB,EAAIntB,EAAIstB,EAAQttB,IAC3B,IAAK,IAAIgN,EAAIogB,EAAIpgB,EAAIugB,EAAQvgB,IAAK,CAGhC,IAFA,IAAIygB,GAAM,EAEDtd,GAAIkd,EAAIld,GAAIqd,EAAQrd,KAAK,CAChC,IAAMud,GAAe1oB,KAAKgO,IAAIka,EAAItB,EAAY,GAAKc,EAC7CiB,GAAe3oB,KAAKgO,IAAIka,EAAIrB,EAAY,GAAKkB,EAKnDU,IAHInB,EAAUoB,GAAe1tB,EAAI2sB,EAAaxc,GAAIyc,GAE9CL,EAAUpc,GAAI0c,EAAa7f,EAAI8f,EAAaa,IAGlDX,EAAQE,EAAK5gB,GAAQtM,EAAIosB,EAAWpf,KAAOygB,GAYvD,OAJA/nB,EAAQ2D,8BAA8B2iB,GACtCtmB,EAAQ2D,8BAA8B4iB,GAG/BvmB,EAAQ5B,eACXgK,EAAU9P,EAAO+C,MAAO/C,EAAO8D,OACrC,CAEO,IAAM8rB,GAAkC,CAC7CzoB,WAAY0oB,cACZxoB,YAAa,MACbC,WAAY6lB,ICxEP,IAAM2C,GAAmC,CAC9C3oB,WAAY4oB,eACZ1oB,YAAa,MACbC,oBAzC2BC,WASvByoB,EACAC,EACAC,EANGzmB,WAAQ/B,YAASwD,UACjBc,MAAGvN,MAAG0xB,SAAMxD,2BACZS,eAAYC,eAAYX,eAAYE,mBAMrCwD,EAA8B,GAIpCJ,EADI7C,GAAY,CAAC1jB,OAAQ,CAACuC,IAAGvN,KAAIyM,MAAO,CAACkiB,aAAYC,cAAa3lB,YAG9DyoB,IACFF,EAASniB,EAAI,CAACrE,OAAQ,CAACuC,EAAGgkB,EAASvxB,EAAG0xB,GAAOzoB,YAC7C0oB,EAAczuB,KAAKquB,GACnBA,EAAUC,GAERvD,IACFwD,EAAgBzD,GACZ/kB,EAASsoB,EAAStD,EAAYC,EAAwBC,GAC1DwD,EAAczuB,KAAKquB,GACnBA,EAAUE,OAGZ,IAAgB,IAAAG,EAAAvS,EAAAsS,iCAAe,CAA1B,IAAMpuB,UACT0F,EAAQ2D,8BAA8BrJ,qGAGxC,OAAOguB,CACT,GCxCaM,GAAOnhB,EAAgBohB,QAAM,SAAC9gB,GAAO,OAAAzI,KAAKspB,KAAK7gB,MAE/C+gB,GAA2B,CACtCrpB,WAAYopB,OACZlpB,YAAa,MACbC,WAAYgpB,ICLDG,GAAQthB,EAAgBuhB,SAAO,SAACjhB,GAAO,OAAAzI,KAAKypB,MAAMhhB,MAElDkhB,GAA4B,CACvCxpB,WAAYupB,QACZrpB,YAAa,MACbC,WAAYmpB,ICiBP,IAAMG,GAA2B,CACtCzpB,WAAY0pB,OACZxpB,YAAa,MACbC,oBAxBmBC,GAEZ,IAAAkC,WAAQ/B,YACTopB,EAAUrnB,EAEhBjH,EAAiBiH,EAAQ,QAMzB,IAJA,IAAM5C,EACFiqB,EAAQlsB,KAAI,SAAApE,GAAK,OAAAkH,EAAQtE,KAAKc,IAAI1D,EAAE6D,QAAQP,UAC1CiL,EAASpJ,SAAOmrB,EAAQ,GAAG/sB,MAAO+sB,EAAQ,GAAG/tB,OAC7CyL,EAAUO,EAAOjL,OACd9B,EAAI,EAAGA,EAAI8uB,EAAQpvB,OAAQM,IAElC,IADA,IAAM+uB,EAAWlqB,EAAK7E,GACbgN,EAAI,EAAGA,EAAIR,EAAQ9M,OAAQsN,IAClCR,EAAQQ,IAAM+hB,EAAS/hB,GAI3B,OAAOtH,EAAQ5B,eAAeiJ,EAAOhL,MAAOgL,EAAOhM,MAAOgM,EAAOjL,OACnE,GCqCO,IAAMktB,GAA0B,CACrC7pB,WAAY8pB,MACZ5pB,YAAa,MACbC,oBAxDEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA+P,SAAMC,aAEbhV,EAAiBgF,EAAG,OAEpB,IAAM0pB,EAAWruB,OAAK6U,eAAeH,EAAM/P,EAAEzD,OACzC0T,EAAOyZ,EACLC,EAAehtB,eAAayT,mBAAmBH,EAAMjQ,EAAEzD,MAAMrC,QAC/D0vB,EAAK5pB,EACW,MAAhB2pB,IACFC,EAAKxa,GAAU,CAACnN,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACoL,KAAM6a,KACpD1Z,EAAOtT,eAAa4T,iBAAiBN,EAAK/V,OAAQ8F,EAAEzD,MAAMrC,SAG5DyC,eAAaktB,2BAA2B,MAAO5Z,EAAM2Z,EAAGrtB,MAAMrC,QAO9D,IANM,IAAAqJ,2DAAC+E,OAAUmH,OAEX7C,EAAavR,OAAK8E,cAAcsP,GAChCpQ,EAAOhE,OAAKmH,oBAAoBnH,OAAK8E,cAAcmI,GAAWshB,EAAGruB,OAEjEiF,EAAQN,EAAQtE,KAAKc,IAAIktB,EAAG/sB,QAAQP,OACjC9B,EAAI,EAAGA,EAAI6E,EAAKnF,SAAUM,EAAG,CAGpC,IAFA,IAAMqS,EAASrS,EAAIoS,EACfkd,EAAMtpB,EAAMqM,GACPrF,EAAI,EAAGA,EAAIoF,IAAcpF,EAAG,CACnC,IAAMrP,EAAQqI,EAAMqM,EAASrF,GAC7BsiB,EAAMA,GAAO3xB,EAEfkH,EAAK7E,GAAKsvB,EAGQ,MAAhBH,GACFzpB,EAAQ2D,8BAA8B+lB,GAGxC,IAAMpxB,EAAS0H,EAAQ5B,eAAegK,EAAUshB,EAAGruB,MAAO8D,GAE1D,GAAI2Q,EAAU,CACZ,IACM+Z,EACFzU,GAAQ,CAACrT,OAAQ,CAACjC,EAAGxH,GAAS0H,UAASwD,MAAO,CAACnH,MAF7BI,eAAa6T,qBAAqBlI,EAAUohB,MAMlE,OAFAxpB,EAAQ2D,8BAA8BrL,GAE/BuxB,EAGT,OAAOvxB,CACT,GCEO,IAAMwxB,GAA0B,CACrCrqB,WAAYsqB,MACZpqB,YAAa,MACbC,oBAxDEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA+P,SAAMC,aAEbhV,EAAiBgF,EAAG,OAEpB,IAAM0pB,EAAWruB,OAAK6U,eAAeH,EAAM/P,EAAEzD,OACzC0T,EAAOyZ,EACLC,EAAehtB,eAAayT,mBAAmBH,EAAMjQ,EAAEzD,MAAMrC,QAC/D0vB,EAAK5pB,EACW,MAAhB2pB,IACFC,EAAKxa,GAAU,CAACnN,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACoL,KAAM6a,KACpD1Z,EAAOtT,eAAa4T,iBAAiBN,EAAK/V,OAAQ8F,EAAEzD,MAAMrC,SAG5DyC,eAAaktB,2BAA2B,MAAO5Z,EAAM2Z,EAAGrtB,MAAMrC,QAO9D,IANM,IAAAqJ,2DAAC+E,OAAUmH,OAEX7C,EAAavR,OAAK8E,cAAcsP,GAChCpQ,EAAOhE,OAAKmH,oBAAoBnH,OAAK8E,cAAcmI,GAAWshB,EAAGruB,OAEjEiF,EAAQN,EAAQtE,KAAKc,IAAIktB,EAAG/sB,QAAQP,OACjC9B,EAAI,EAAGA,EAAI6E,EAAKnF,SAAUM,EAAG,CAGpC,IAFA,IAAMqS,EAASrS,EAAIoS,EACfsd,EAAS1pB,EAAMqM,GACVrF,EAAI,EAAGA,EAAIoF,IAAcpF,EAAG,CACnC,IAAMrP,EAAQqI,EAAMqM,EAASrF,GAC7B0iB,EAASA,GAAU/xB,EAErBkH,EAAK7E,GAAK0vB,EAGQ,MAAhBP,GACFzpB,EAAQ2D,8BAA8B+lB,GAGxC,IAAMpxB,EAAS0H,EAAQ5B,eAAegK,EAAUshB,EAAGruB,MAAO8D,GAE1D,GAAI2Q,EAAU,CACZ,IACM+Z,EACFzU,GAAQ,CAACrT,OAAQ,CAACjC,EAAGxH,GAAS0H,UAASwD,MAAO,CAACnH,MAF7BI,eAAa6T,qBAAqBlI,EAAUohB,MAMlE,OAFAxpB,EAAQ2D,8BAA8BrL,GAE/BuxB,EAGT,OAAOvxB,CACT,GCJO,IAAM2xB,GAA6B,CACxCxqB,WAAYyqB,SACZvqB,YAAa,MACbC,oBAnDEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA+P,SAEP/U,EAAiBgF,EAAG,UAEpB,IAAIiQ,EAAO5U,OAAK6U,eAAeH,EAAM/P,EAAEzD,OACjCotB,EAAehtB,eAAayT,mBAAmBH,EAAMjQ,EAAEzD,MAAMrC,QAC/D0vB,EAAK5pB,EACHsQ,EAA0B,GACZ,MAAhBqZ,IACFC,EAAKxa,GAAU,CAACnN,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACoL,KAAM6a,KACpDrZ,EAAwBnW,KAAKyvB,GAC7B3Z,EAAOtT,eAAa4T,iBAAiBN,EAAK/V,OAAQ0vB,EAAGrtB,MAAMrC,SAG7D+V,EAAO,CAACA,EAAK,IACbtT,eAAaktB,2BAA2B,SAAU5Z,EAAM2Z,EAAGrtB,MAAMrC,QASjE,IARM,IAAAqJ,2DAAC+E,OAAUmH,OAGX4a,EAAUhvB,OAAK8E,cAAcmI,GAC7BjJ,EAAOhE,OAAKmH,oBAAoB6nB,EAAS,SACzCzd,EAAavR,OAAK8E,cAAcsP,GAEhCjP,EAAQN,EAAQtE,KAAKc,IAAIktB,EAAG/sB,QAAQP,OACjC9B,EAAI,EAAGA,EAAI6E,EAAKnF,SAAUM,EAAG,CAIpC,IAHA,IAAMqS,EAASrS,EAAIoS,EACfE,EAAMtM,EAAMqM,GACZyd,EAAW,EACN9iB,EAAI,EAAGA,EAAIoF,IAAcpF,EAAG,CACnC,IAAMrP,EAAQqI,EAAMqM,EAASrF,GACzBrP,EAAQ2U,IACVA,EAAM3U,EACNmyB,EAAW9iB,GAGfnI,EAAK7E,GAAK8vB,EAMZ,OAHAha,EAAwBlV,SACpB,SAAApC,GAAK,OAAAkH,EAAQ2D,8BAA8B7K,MAExCkH,EAAQ5B,eAAegK,EAAU,QAASjJ,EACnD,GCEO,IAAMkrB,GAA6B,CACxC5qB,WAAY6qB,SACZ3qB,YAAa,MACbC,oBAnDEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA+P,SAEP/U,EAAiBgF,EAAG,UAEpB,IAAIiQ,EAAO5U,OAAK6U,eAAeH,EAAM/P,EAAEzD,OACjCotB,EAAehtB,eAAayT,mBAAmBH,EAAMjQ,EAAEzD,MAAMrC,QAC/D0vB,EAAK5pB,EACHsQ,EAA0B,GACZ,MAAhBqZ,IACFC,EAAKxa,GAAU,CAACnN,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACoL,KAAM6a,KACpDrZ,EAAwBnW,KAAKyvB,GAC7B3Z,EAAOtT,eAAa4T,iBAAiBN,EAAK/V,OAAQ0vB,EAAGrtB,MAAMrC,SAG7D+V,EAAO,CAACA,EAAK,IACbtT,eAAaktB,2BAA2B,SAAU5Z,EAAM2Z,EAAGrtB,MAAMrC,QASjE,IARM,IAAAqJ,2DAAC+E,OAAUmH,OAGX4a,EAAUhvB,OAAK8E,cAAcmI,GAC7BjJ,EAAOhE,OAAKmH,oBAAoB6nB,EAAS,SACzCzd,EAAavR,OAAK8E,cAAcsP,GAEhCjP,EAAQN,EAAQtE,KAAKc,IAAIktB,EAAG/sB,QAAQP,OACjC9B,EAAI,EAAGA,EAAI6E,EAAKnF,SAAUM,EAAG,CAIpC,IAHA,IAAMqS,EAASrS,EAAIoS,EACfY,EAAMhN,EAAMqM,GACZ4d,EAAW,EACNjjB,EAAI,EAAGA,EAAIoF,IAAcpF,EAAG,CACnC,IAAMrP,EAAQqI,EAAMqM,EAASrF,GACzBrP,EAAQqV,IACVA,EAAMrV,EACNsyB,EAAWjjB,GAGfnI,EAAK7E,GAAKiwB,EAMZ,OAHAna,EAAwBlV,SACpB,SAAApC,GAAK,OAAAkH,EAAQ2D,8BAA8B7K,MAExCkH,EAAQ5B,eAAegK,EAAU,QAASjJ,EACnD,GCjDaqrB,GAAO/iB,EAAgBgjB,QAAM,SAAC1iB,GAAO,OAAAzI,KAAKkrB,KAAKziB,MAE/C2iB,GAA2B,CACtCjrB,WAAYgrB,OACZ9qB,YAAa,MACbC,WAAY4qB,ICLDG,GAAQljB,EAAgBmjB,SAAO,SAAC7iB,GAAO,OAAAzI,KAAKqrB,MAAM5iB,MAElD8iB,GAA4B,CACvCprB,WAAYmrB,QACZjrB,YAAa,MACbC,WAAY+qB,ICLDG,GAAOrjB,EAAgBsjB,QAAM,SAAChjB,GAAO,OAAAzI,KAAKwrB,KAAK/iB,MAE/CijB,GAA2B,CACtCvrB,WAAYsrB,OACZprB,YAAa,MACbC,WAAYkrB,ICLDG,GAAY9qB,GACrB,SAAC6M,EAAQC,GAAW,OAAA3N,KAAK4rB,MAAMle,EAAkBC,MAExCie,GAAQhnB,EAAiBinB,QAAOF,IAEhCG,GAA4B,CACvC3rB,WAAY0rB,QACZxrB,YAAa,MACbC,WAAYsrB,ICRDG,GAAQ5jB,EAAgB6jB,SAAO,SAACvjB,GAAO,OAAAzI,KAAK+rB,MAAMtjB,MAElDwjB,GAA4B,CACvC9rB,WAAY6rB,QACZ3rB,YAAa,MACbC,WAAYyrB,aCPEG,GACZC,EAAqBzd,EAAkB3S,EAAiB8O,EACxDuhB,EACAC,GAsBF,IArBA,IAAMC,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCC,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQxK,KAE3B2K,EACY,QAAbX,EAAqB9e,OAAO0f,kBACP1f,OAAO2f,kBAE3BtQ,EAASje,SAAOytB,EAAStjB,SAAU/M,GACnCoxB,EAAavQ,EAAO9f,OAEpBswB,EACFhB,EAAStjB,SAAS,GAAKsjB,EAAStjB,SAAS,GAAKsjB,EAAStjB,SAAS,GAC9DukB,EAAmBjB,EAAStjB,SAAS,GAAKsjB,EAAStjB,SAAS,GAC5DwkB,EAAmBlB,EAAStjB,SAAS,GAElCrR,EAAI,EAAGA,EAAI20B,EAASrL,YAAatpB,EAGxC,IAFA,IAAM81B,EAAoB91B,EAAI21B,EACxBI,EAAmB/1B,EAAIoT,EAAQ,GAC5BrT,EAAI,EAAGA,EAAI40B,EAASqB,aAAcj2B,EACzC,IAAK,IAAIk2B,EAAK,EAAGA,EAAKtB,EAASuB,YAAaD,EAM1C,IALA,IAAME,EAAWF,EAAKpB,EAAeM,EAC/BiB,EAAQ7tB,KAAKsN,IAAI,EAAGsgB,GACpBE,EACF9tB,KAAKgO,IAAIoe,EAAS2B,SAAUrB,EAAwBkB,GAClDI,EAAkBT,EAAoBG,EAAKL,EACxCY,EAAK,EAAGA,EAAK7B,EAAS8B,WAAYD,EAAI,CAQ7C,IAPA,IAAME,EAAWF,EAAK1B,EAAcQ,EAC9BqB,EAAQpuB,KAAKsN,IAAI,EAAG6gB,GACpBE,EACFruB,KAAKgO,IAAIoe,EAASkC,QAAS3B,EAAuBwB,GAClDI,EAAcvB,EACdwB,EAAW,EACXC,EAAQ,EACHC,EAAKb,EAAOa,EAAKZ,EAAOY,GAAMlC,EAAgB,CAErD,IADA,IAAMmC,EAAWnB,EAAmBkB,EAAK7jB,EAAQ,GACxC+jB,EAAKR,EAAOQ,EAAKP,EAAOO,GAAMnC,EAAe,CACpD,IACMoC,EAAQ1C,EADGwC,EAAWC,EAAK/jB,EAAQ,GACRrT,GACf,QAAb60B,GAAsBwC,EAAQN,EACjCA,EAAcM,EACQ,QAAbxC,IACTmC,GAAYK,EACZJ,KAGJ,GAAIjhB,MAAM+gB,GACR,MAIJpB,EADqBa,EAAkBC,EAAKX,EAAmB91B,GAE9C,QAAb60B,EAAqBmC,EAAWC,EAAQF,EAKpD,OAAO3R,CACT,UAEgBkS,GACZ3C,EAAqBzd,EAAkB3S,EACvCqwB,EAAmC2C,EACnCC,gBADmCD,mBACnCC,MAYF,IAXA,IAAMC,EAAetwB,SAAOytB,EAAStjB,SAAU,SACzCwjB,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCC,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQxK,KAE3B3a,EAAO/I,SAAO+P,EAAQ3S,EAAOowB,GAC1B10B,EAAI,EAAGA,EAAI20B,EAASrL,YAAatpB,EACxC,IAAK,IAAID,EAAI,EAAGA,EAAI40B,EAASqB,aAAcj2B,EACzC,IAAK,IAAIk2B,EAAK,EAAGA,EAAKtB,EAASuB,YAAaD,EAAI,CAG9C,IAFA,IAAME,EAAWF,EAAKpB,EAAeM,EACjCiB,EAAQD,EACLC,EAAQ,GACbA,GAASrB,EAKX,IAFA,IAAMsB,EACF9tB,KAAKgO,IAAIoe,EAAS2B,SAAUrB,EAAwBkB,GAC/CK,EAAK,EAAGA,EAAK7B,EAAS8B,WAAYD,EAAI,CAG7C,IAFA,IAAME,EAAWF,EAAK1B,EAAcQ,EAChCqB,EAAQD,EACLC,EAAQ,GACbA,GAAS3B,EAOX,IALA,IAAM4B,EACFruB,KAAKgO,IAAIoe,EAASkC,QAAS3B,EAAuBwB,GAClDe,EAAW3hB,OAAO0f,kBAClBkC,GAAe,EAEVT,EAAKb,EAAOa,EAAKZ,EAAOY,GAAMlC,EAErC,IADA,IAAM4C,EAAKV,EAAKd,EACPgB,EAAKR,EAAOQ,EAAKP,EAAOO,GAAMnC,EAAe,CACpD,IAAM4C,EAAKT,EAAKT,EACVU,EAAQnnB,EAAKxK,IAAIzF,EAAGi3B,EAAIE,EAAIp3B,GAC9Bq3B,EAAQK,IACVA,EAAWL,EAETM,EADEJ,EACYC,IACRv3B,EAAI20B,EAAS2B,SAAWW,GAAMtC,EAASkC,QAAUM,GAC3CxC,EAASqB,WACbj2B,GACHk3B,EAAKtC,EAASkC,QAAUM,GAAMxC,EAASqB,WAAaj2B,EAE3C43B,EAAKzC,EAAuB0C,GAKlDJ,EAAa1xB,IAAI4xB,EAAa13B,EAAGi2B,EAAIO,EAAIz2B,IAKjD,OAAOy3B,CACT,UAEgBK,GACZnD,EAAqBzd,EAAkB3S,EAAiB8O,EACxDuhB,EACAC,GA4BF,IA3BA,IAAMkD,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBiD,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBgD,EAAuBrD,EAASqD,qBAChC/C,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChC+C,EAAWtD,EAASS,QAAQ8C,MAC5B/C,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQxK,KAE3B2K,EACY,QAAbX,EAAqB9e,OAAO0f,kBACP1f,OAAO2f,kBAE3BtQ,EAASje,SAAOytB,EAAStjB,SAAU/M,GACnCoxB,EAAavQ,EAAO9f,OAEpBswB,EAAqBhB,EAAStjB,SAAS,GAAKsjB,EAAStjB,SAAS,GAChEsjB,EAAStjB,SAAS,GAAKsjB,EAAStjB,SAAS,GACvC8mB,EACFxD,EAAStjB,SAAS,GAAKsjB,EAAStjB,SAAS,GAAKsjB,EAAStjB,SAAS,GAC9DukB,EAAmBjB,EAAStjB,SAAS,GAAKsjB,EAAStjB,SAAS,GAC5DwkB,EAAmBlB,EAAStjB,SAAS,GAElCga,EAAQ,EAAGA,EAAQsJ,EAASrL,YAAa+B,EAGhD,IAFA,IAAMyK,EAAoBzK,EAAQsK,EAC5BI,EAAmB1K,EAAQjY,EAAQ,GAChCglB,EAAU,EAAGA,EAAUzD,EAASqB,aAAcoC,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAAS1D,EAAS2D,WAAYD,EAAQ,CAGzD,IAFA,IAAME,EAAeF,EAASP,EAAcG,EACxCO,EAAYD,EACTC,EAAY,GACjBA,GAAaT,EAMf,IAJA,IAAMU,EACFlwB,KAAKgO,IAAIoe,EAAS+D,QAASV,EAAuBO,GAChDI,EACF7C,EAAoBuC,EAASF,EACxBS,EAAO,EAAGA,EAAOjE,EAASuB,YAAa0C,EAAM,CAGpD,IAFA,IAAMC,EAAaD,EAAO/D,EAAeM,EACrC2D,EAAUD,EACPC,EAAU,GACfA,GAAW/D,EAKb,IAHA,IAAMgE,EACFxwB,KAAKgO,IAAIoe,EAAS2B,SAAUrB,EAAwB4D,GAClDtC,EAAkBoC,EAAoBC,EAAOhD,EAC1CoD,EAAO,EAAGA,EAAOrE,EAAS8B,WAAYuC,EAAM,CAGnD,IAFA,IAAMC,EAAaD,EAAOlE,EAAcQ,EACpC4D,EAAUD,EACPC,EAAU,GACfA,GAAWlE,EASb,IAPA,IAAMmE,EACF5wB,KAAKgO,IAAIoe,EAASkC,QAAS3B,EAAuB+D,GAEhDG,EAAkB7C,EAAkByC,EAAOnD,EAC7CiB,EAAcvB,EACdwB,EAAW,EACXC,EAAQ,EACHqC,EAASb,EAAWa,EAASZ,EACjCY,GAAUtB,EAAe,CAE5B,IADA,IAAMuB,EAAevD,EAAmBsD,EAASjmB,EAAQ,GAChDmmB,EAAOT,EAASS,EAAOR,EAASQ,GAAQxE,EAAgB,CAE/D,IADA,IAAMyE,EAAaF,EAAeC,EAAOnmB,EAAQ,GACxCqmB,EAAOP,EAASO,EAAON,EAC3BM,GAAQzE,EAAe,CAC1B,IACMoC,EAAQ1C,EADK8E,EAAaC,EAAOrmB,EAAQ,GACZglB,GAOnC,GANkB,QAAbxD,GAAsBwC,EAAQN,EACjCA,EAAcM,EACQ,QAAbxC,IACTmC,GAAYK,EACZJ,KAEEjhB,MAAM+gB,GACR,MAGJ,GAAI/gB,MAAM+gB,GACR,MAGJ,GAAI/gB,MAAM+gB,GACR,MAIJpB,EADqB0D,EAAkBhB,GAEtB,QAAbxD,EAAqBmC,EAAWC,EAAQF,IAOtD,OAAO3R,CACT,CCxMO,IAAMuU,GAA8B,CACzChxB,WAAYixB,UACZ/wB,YAAa,MACbC,oBAnCEC,GAGK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACPhF,EAAiBgF,EAAG,WACb,IAAA6wB,eAAYxmB,YAASymB,QAAKC,oBAGjC11B,OAAKC,OACDqB,eAAaq0B,+BAA+B3mB,EAH9B,IAId,WAAM,MAAA,wEACaA,0BAEvB,IAGImE,EAHEod,EAAWjvB,eAAas0B,kBAC1BjxB,EAAEzD,MAA2Cs0B,EAAYxmB,EAR3C,EASHymB,EAAKC,GAGpB,GAA6B,IAAzBnF,EAASsF,aAA+C,IAA1BtF,EAASuF,cACvC91B,OAAK+1B,YAAYxF,EAASyF,QAASzF,EAAStjB,UAC9CkG,EAAM/L,EAAS,CAACR,OAAQ,CAACjC,KAAIE,gBACxB,CACL,IAAMyrB,EAAUzrB,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACrCg1B,EAAUj2B,OAAKyF,eAAed,EAAEzD,OAChC4B,EAASutB,GAAKC,EAAS3rB,EAAEzD,MAAOyD,EAAEzE,MAAO+1B,EAAS1F,EAAU,OAClEpd,EAAMtO,EAAQ5B,eACVstB,EAAStjB,SAAUtI,EAAEzE,MAAO4C,EAAO7B,QAEzC,OAAOkS,CACT,GCTO,IAAM+iB,GAAgC,CAC3C5xB,WAAY6xB,YACZ3xB,YAAa,MACbC,oBAzBwBC,GAKjB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA6wB,eAAYxmB,YAASymB,QAAKC,oBAAiBU,eAElDz2B,EAAiBgF,EAAG,aAEpB,IAAM4rB,EAAWjvB,eAAa+0B,kBAC1B1xB,EAAEzD,MAAmDs0B,EAAYxmB,EACjE,EAAmBymB,EAAKC,EAAiBU,GAGvClqB,EAASunB,GADC5uB,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OAE9B0D,EAAEzD,MAAOyD,EAAEzE,MAAOF,OAAKyF,eAAed,EAAEzD,OAAQqvB,EAAU,OAEvE,OAAO1rB,EAAQ5B,eAAeiJ,EAAOhL,MAAO,UAAWgL,EAAOjL,OAChE,GCgEO,IAAMq1B,GAAoC,CAC/ChyB,WAAYiyB,gBACZ/xB,YAAa,MACbC,oBAxF4BC,GAKrB,IAAAkC,WAAQ/B,YAASwD,UACjBmuB,OAAIhvB,UACJguB,eAAYxmB,YAASymB,QAAKC,oBAEjC/1B,EAAiB,CAAC62B,EAAIhvB,GAAQ,iBA2B9B,IAzBA,IAAM+oB,EAAWjvB,eAAa+0B,kBAC1B7uB,EAAMtG,MAAmDs0B,EACzDxmB,EAAS,EAAmBymB,EAAKC,GAE/BhC,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvB+F,EAAclG,EAASkG,YACvBX,EAAevF,EAASuF,aACxBD,EAActF,EAASsF,YACvBlC,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBgD,EAAuBrD,EAASqD,qBAChC/C,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChC+C,EAAWD,EAAuB,EAAIrD,EAASS,QAAQ8C,MACvD5C,EAAUJ,EAAuB,EAAIP,EAASS,QAAQxK,KACtDuK,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtDyF,EAAK5zB,SAAO0E,EAAMtG,MAAO,WAEzBy1B,EAAgB,GAAKF,EAAcX,EAAeD,GAElDe,EAAQ/xB,EAAQgyB,WAA4BL,GAEzCvP,EAAQ,EAAGA,EAAQsJ,EAASrL,YAAa+B,EAChD,IAAK,IAAI+M,EAAU,EAAGA,EAAUzD,EAASqB,aAAcoC,EACrD,IAAK,IAAI8C,EAAU,EAAGA,EAAUvG,EAAS+D,UAAWwC,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQxG,EAAS2B,WAAY6E,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQzG,EAASkC,UAAWuE,EAAO,CAMrD,IAJA,IAAMC,EAAgBH,EAAUjD,EAC1BqD,EAAcH,EAAQhG,EACtBoG,EAAcH,EAAQ9F,EACxBkG,EAAU,EACLC,EAAS,EAAGA,EAASzD,EACzByD,GAAU1D,EAAe,CAC5B,IAAM2D,GAAWL,EAAgBI,GAAU3D,EAC3C,KAAI4D,EAAU,GAAKA,GAAW/G,EAAS2D,UACnC/vB,KAAKoK,MAAM+oB,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAO1G,EACrB0G,GAAQ5G,EAAgB,CAC3B,IAAM6G,GAASN,EAAcK,GAAQ9G,EACrC,KAAI+G,EAAQ,GAAKA,GAASjH,EAASuB,WAC/B3tB,KAAKoK,MAAMipB,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAO3G,EACrB2G,GAAQ7G,EAAe,CAC1B,IAAM8G,GAASP,EAAcM,GAAQ/G,EACrC,KAAIgH,EAAQ,GAAKA,GAASnH,EAAS8B,UAC/BluB,KAAKoK,MAAMmpB,KAAWA,GAM1BN,GADIR,EAAMv1B,IAAI4lB,EAAOqQ,EAASE,EAAOE,EAAO1D,KAKlD0C,EAAGh1B,IACC01B,EAAUT,EAAe1P,EAAO6P,EAASC,EAAOC,EAAOhD,GAOrE,OAAOnvB,EAAQ5B,eAAeyzB,EAAGx1B,MAAOw1B,EAAGx2B,MAAOw2B,EAAGz1B,OACvD,GClBO,IAAM02B,GAAkC,CAC7CrzB,WAAYszB,cACZpzB,YAAa,MACbC,oBArE0BC,GAKnB,IAAAkC,WAAQ/B,YAASwD,UACjBmuB,OAAIhvB,UACL7C,EAAI6C,EACV7H,EAAiB,CAAC62B,EAAIhvB,GAAQ,eAyB9B,IAxBO,IAAAguB,eAAYxmB,YAASymB,QAEtBlF,EAAWjvB,eAAas0B,kBAC1BjxB,EAAEzD,MAA2Cs0B,EAAYxmB,EACzD,EAAmBymB,GACjBhF,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBoF,EAAevF,EAASuF,aACxBD,EAActF,EAASsF,YACvBlF,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCI,EAAUJ,EAAuB,EAAIP,EAASS,QAAQxK,KACtDuK,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtDyF,EACF5zB,SAAgB6B,EAAEzD,MAA2C,WAE3Dy1B,EAAgB,GAAKb,EAAeD,GAEpCgC,EAAShzB,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OACrC21B,EAAQ9zB,SACV0zB,EAAGt1B,MAA2C,UAAW22B,GAEpDj8B,EAAI,EAAGA,EAAI20B,EAASrL,YAAatpB,EACxC,IAAK,IAAID,EAAI,EAAGA,EAAI40B,EAASqB,aAAcj2B,EACzC,IAAK,IAAIm8B,EAAM,EAAGA,EAAMvH,EAAS2B,WAAY4F,EAC3C,IAAK,IAAIC,EAAM,EAAGA,EAAMxH,EAASkC,UAAWsF,EAAK,CAK/C,IAHA,IAAMC,EAAYF,EAAM/G,EAClBkH,EAAYF,EAAM7G,EACpBkG,EAAU,EACL7D,EAAK,EAAGA,EAAK1C,EAAuB0C,GAAM5C,EAAgB,CACjE,IAAMuH,GAAOF,EAAYzE,GAAM9C,EAC/B,KAAIyH,EAAM,GAAKA,GAAO3H,EAASuB,WAC3B3tB,KAAKoK,MAAM2pB,KAASA,GAGxB,IAAK,IAAI1E,EAAK,EAAGA,EAAK1C,EAAsB0C,GAAM5C,EAAe,CAC/D,IAAMuH,GAAOF,EAAYzE,GAAM9C,EAC/B,KAAIyH,EAAM,GAAKA,GAAO5H,EAAS8B,UAC3BluB,KAAKoK,MAAM4pB,KAASA,GAKxBf,GADcR,EAAMv1B,IAAIzF,EAAGs8B,EAAKC,EAAKx8B,IAIzC+6B,EAAGh1B,IAAI01B,EAAUT,EAAe/6B,EAAGk8B,EAAKC,EAAKp8B,GAKrD,OAAOkJ,EAAQ5B,eAAeyzB,EAAGx1B,MAAOw1B,EAAGx2B,MAAOw2B,EAAGz1B,OACvD,GCIO,IAAMm3B,GAAgC,CAC3C9zB,WAAY+zB,iBACZ7zB,YAAa,MACbC,oBAtEwBC,GAKjB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAG2zB,UAAO9mB,WAAQ+mB,SAAMC,aAE/Bx4B,OAAKC,OACDs4B,EAAKr3B,MAAMrC,SAAW25B,EAASt3B,MAAMrC,QACrC,WAAM,MAAA,kFAEVmB,OAAKC,OACS,MAAVuR,GAAkB+mB,EAAKr3B,MAAMrC,SAAW2S,EAAOtQ,MAAMrC,QACrD,WAAM,MAAA,gFAEVmB,OAAKC,OACQ,MAATq4B,GAAiBC,EAAKr3B,MAAMrC,SAAWy5B,EAAMp3B,MAAMrC,QACnD,WAAM,MAAA,+EAGVc,EAAiB,CAACgF,EAAG4zB,EAAMC,EAAUF,EAAO9mB,GAAS,aAEhD,IAAAinB,oBACkB,MAAnBA,IACFA,EAAkB,MAsBpB,IAnBA,IAAMptB,EAAQxG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACnCy3B,EAAQ7zB,EAAQtE,KAAKc,IAAIk3B,EAAK/2B,QAAQP,OACtC03B,EAAU9zB,EAAQtE,KAAKc,IAAIm3B,EAASh3B,QAAQP,OAC5C23B,EAAQN,EAAQzzB,EAAQtE,KAAKc,IAAIi3B,EAAM92B,QAAQP,OAC/B,IAAIiD,aAAa,CAAC,IAClC20B,EAAUrnB,EACZ3M,EAAQtE,KAAKc,IAAImQ,EAAOhQ,QAAQP,OAChC,IAAIiD,aAAa,CAAC,IAChByH,EAAU,IAAIzH,aAAamH,EAAMxM,QAEjCi6B,EAAgBD,EAAQh6B,OACxBk6B,EAAcH,EAAM/5B,OACpBm6B,EAAgBL,EAAQ95B,OACxBo6B,EAAcP,EAAM75B,OAEtBq6B,EAAO,EACPC,EAAK,EACLC,EAAK,EACLC,EAAK,EACAl6B,EAAI,EAAGA,EAAIkM,EAAMxM,SAAUM,EAClCwM,EAAQxM,GAAK05B,EAAQK,MAChB7tB,EAAMlM,GAAKu5B,EAAMS,MAASP,EAAMQ,KAC7Bj1B,KAAKqX,KAAKmd,EAAQU,KAAQZ,GAC9BS,GAAQJ,IACVI,EAAO,GAELC,GAAMF,IACRE,EAAK,GAEHC,GAAML,IACRK,EAAK,GAEHC,GAAML,IACRK,EAAK,GAGT,OAAOx0B,EAAQ5B,eAAe0B,EAAEzD,MAAOyD,EAAEzE,MAAOyL,EAClD,GCtBO,IAAM2tB,GAAqC,CAChDh1B,WAAYi1B,iBACZ/0B,YAAa,MACbC,oBA3C6BC,GAKtB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA60B,eAAYC,UAEnB95B,EAAiB,CAACgF,GAAI,kBAEtB,IAAM+0B,EAAOF,EAAW1Y,QAAO,SAAC3X,EAAGvN,GAAM,OAAAuN,EAAIvN,KAEvC+9B,EAAWr4B,eAAas4B,YAAYj1B,EAAEzD,MAAOs4B,EAAYE,GACzDG,EAAWv4B,eAAaw4B,YAAYH,EAAS96B,OAAQ26B,EAAW36B,QAChEk7B,EACFz4B,eAAa04B,oBAAoBr1B,EAAEzD,MAAOs4B,EAAYE,GACpDO,EACF34B,eAAa44B,oBAAoBT,EAAOD,EAAW36B,QACjDkQ,EACFzN,eAAa64B,aAAaJ,EAAkBN,EAAOD,EAAW36B,QAE5Du7B,EAAYngB,GAAQ,CAACrT,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACnH,MAAOy4B,KAC1DU,EACFtmB,GAAU,CAACnN,OAAQ,CAACjC,EAAGy1B,GAAYv1B,UAASwD,MAAO,CAACoL,KAAMomB,KACxDS,EAAsBrgB,GACxB,CAACrT,OAAQ,CAACjC,EAAG01B,GAAcx1B,UAASwD,MAAO,CAACnH,MAAO64B,KACjD58B,EAASmJ,GAAM,CACnBM,OAAQ,CAACjC,EAAG21B,GACZz1B,UACAwD,MAAO,CAACoU,MAAOwd,EAAkBxuB,KAAMsD,KAOzC,OAJAlK,EAAQ2D,8BAA8B4xB,GACtCv1B,EAAQ2D,8BAA8B6xB,GACtCx1B,EAAQ2D,8BAA8B8xB,GAE/Bn9B,CACT,GCvBO,IAAMo9B,GAA+B,CAC1Cj2B,WAAYk2B,WACZh2B,YAAa,MACbC,oBArBuBC,GAKhB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAG81B,YACHhvB,SAKDE,EACFP,EAJUvG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACrB4D,EAAQtE,KAAKc,IAAIo5B,EAAQj5B,QAAQP,OAGhBw5B,EAAQv6B,MAAOu6B,EAAQv5B,MAAOuK,GAEnE,OAAO5G,EAAQ5B,eAAe,CAACwI,GAAOgvB,EAAQv6B,MAAOyL,EACvD,GCAO,IAAM+uB,GAAoC,CAC/Cp2B,WAAYq2B,gBACZn2B,YAAa,MACbC,oBApB4BC,GAIrB,IAAAkC,WAAQ/B,YACR+1B,OAAIC,OAELC,EAASj2B,EAAQtE,KAAKc,IAAIu5B,EAAGp5B,QAAQP,OACrC85B,EAASl2B,EAAQtE,KAAKc,IAAIw5B,EAAGr5B,QAAQP,OAErC+5B,EAAiB15B,eAAagE,2BAChCtJ,MAAM+L,KAAK+yB,GAAS9+B,MAAM+L,KAAKgzB,IAEnC,OAAOl2B,EAAQ5B,eACX,CAAC+3B,EAAen8B,QAAS,QAASiJ,WAAWC,KAAKizB,GACxD,GCfaC,GAAc3uB,EAAgB4uB,eAAa,SAACtuB,EAAIvE,GAC3D,IAAM8yB,EAAY9yB,EAClB,OAAIuE,EAAKuuB,EAAUC,aACVD,EAAUC,aAEZxuB,EAAKuuB,EAAUE,aAAeF,EAAUE,aAAezuB,CAChE,IAEa0uB,GAAkC,CAC7Ch3B,WAAY42B,cACZ12B,YAAa,MACbC,WAAYw2B,ICQDM,GAAiC,CAC5Cj3B,WAAYk3B,aACZh3B,YAAa,MACbC,WArBE,SAACC,GASC,IARO,IAAAC,aACDC,EAAaF,EAAKG,QAClBZ,EAAe,IAAIC,aAAalE,OAAK8E,cAAcH,EAAEzD,QACrDu6B,EAAc72B,EAAWrE,KAAKc,IAAIsD,EAAEnD,QACpCgB,EAAOi5B,EAAYn5B,mBAAmBE,KACtCE,EAAO+4B,EAAYn5B,mBAAmBI,KACtCmE,EAAWjC,EAAWrE,KAAKc,IAAImB,EAAKhB,QAAQP,OAC5C6F,EAAWlC,EAAWrE,KAAKc,IAAIqB,EAAKlB,QAAQP,OACzC9B,EAAI,EAAGA,EAAI0H,EAAShI,OAAQM,IAAK,CACxC,IAAMu8B,EAAO70B,EAAS1H,GAChBw8B,EAAO70B,EAAS3H,GACtB8E,EAAa9E,GAAKgF,KAAKy3B,MAAMF,EAAMC,GAGrC,OAAO/2B,EAAWG,WAAWd,EAAcU,EAAEzD,MAAO,UACtD,YCjBYwB,GAAKgC,GAEZ,IAAAkC,WAAQ/B,YACR2C,UAED9E,EAAOmC,EAAQtE,KAAKc,IAAImG,EAAMhG,QAAQc,mBAAmBI,KACzDm5B,EAAUh3B,EAAQtE,KAAKc,IAAIqB,EAAKlB,QAAQP,OAK9C,OAAO4D,EAAQ5B,eAAeP,EAAKxB,MAAOwB,EAAKxC,MAAO27B,EACxD,CAEO,IAAMC,GAA2B,CACtCx3B,WAAYy3B,OACZv3B,YAAa,MACbC,WAAY/B,aCVEhD,GACZgF,GAEK,IAAAkC,WAAQ/B,YACR6P,eAEDgT,EAAQ1nB,OAAK6U,eAAeH,EAAM9N,EAAO,GAAG1F,OAAO,GACrD+L,EAAW3L,eAAa06B,gBAAgBp1B,EAAO7E,KAAI,SAAApE,GAAK,OAAAA,EAAEuD,SAAQwmB,GAEtE,GAAqC,IAAjC1nB,OAAK8E,cAAcmI,GACrB,OAAOpI,EAAQ5B,eAAegK,EAAUrG,EAAO,GAAG1G,MAAO,IAI3D,IAAM+7B,EAAUr1B,EAAOs1B,QAAO,SAAAv+B,GAAK,OAAAqC,OAAK8E,cAAcnH,EAAEuD,OAAS,KACjE,GAAuB,IAAnB+6B,EAAQp9B,OACV,OAAOuI,EAAS,CAACR,OAAQ,CAACjC,EAAGs3B,EAAQ,IAAKp3B,YAG5C,IAAMs3B,EAASF,EAAQl6B,KAAI,SAAApE,GAAK,OAAAA,EAAEuD,SAGlC,GAFAI,eAAa86B,uBAAuBD,EAAQzU,GAEnB,cAArBuU,EAAQ,GAAG/7B,MAAuB,CACpC,IAAMm8B,EAAQJ,EAAQl6B,KAAI,SAACpE,GAAM,OAAA6E,EAAK,CAACoE,OAAQ,CAACY,MAAO7J,GAAIkH,eACrDy3B,EAAQL,EAAQl6B,KAAI,SAACpE,GAAM,OAAA+E,GAAK,CAACkE,OAAQ,CAACY,MAAO7J,GAAIkH,eAErD03B,EAAe78B,GAAO,CAACkH,OAAQy1B,EAAOx3B,UAASwD,MAAO,CAACqM,KAAMgT,KAC7D8U,EAAe98B,GAAO,CAACkH,OAAQ01B,EAAOz3B,UAASwD,MAAO,CAACqM,KAAMgT,KAE7DvqB,EACFwJ,EAAQ,CAACC,OAAQ,CAACpE,KAAM+5B,EAAc75B,KAAM85B,GAAe33B,YAO/D,OALAw3B,EAAMt8B,SAAQ,SAAAV,GAAK,OAAAwF,EAAQ2D,8BAA8BnJ,MACzDi9B,EAAMv8B,SAAQ,SAAAZ,GAAK,OAAA0F,EAAQ2D,8BAA8BrJ,MACzD0F,EAAQ2D,8BAA8B+zB,GACtC13B,EAAQ2D,8BAA8Bg0B,GAE/Br/B,EAUT,IAAMs/B,EAAWR,EAAQl6B,KAAI,SAAApE,GAC3B,IAAM++B,EAAY18B,OAAK8E,cAAcnH,EAAEuD,MAAMoF,MAAMohB,IAEnD,OAAOzN,GAAQ,CAACrT,OAAQ,CAACjC,EAAGhH,GAAIkH,UAASwD,MAAO,CAACnH,MADnC,EAAE,EAAGw7B,SAIfC,EAAkBF,EAAS16B,KAAI,SAAApE,GACnC,MAAO,CAACqG,KAAMa,EAAQtE,KAAKc,IAAI1D,EAAE6D,QAAQP,OAAQC,MAAOvD,EAAEuD,UAI5D+L,EACI3L,eAAa06B,gBAAgBS,EAAS16B,KAAI,SAAApE,GAAK,OAAAA,EAAEuD,SAAQ,GAC7D,IAAMgM,EAAwC,IAAzBuvB,EAAS,GAAGv7B,MAAM,GACjCyK,EACFqB,EAAW2vB,EAAiB1vB,EAAUrG,EAAO,GAAG1G,MAAOgN,GAErD0vB,EACFt7B,eAAa06B,gBAAgBC,EAAQl6B,KAAI,SAAApE,GAAK,OAAAA,EAAEuD,SAAQwmB,GAEtDmV,EACFh4B,EAAQ5B,eAAe25B,EAAeh2B,EAAO,GAAG1G,MAAOyL,GAI3D,OAFA8wB,EAAS18B,SAAQ,SAAApC,GAAK,OAAAkH,EAAQ2D,8BAA8B7K,MAErDk/B,CACT,CAEO,IAAMC,GAA6B,CACxCx4B,WAAYy4B,SACZv4B,YAAa,MACbC,WAAY/E,aCpFEs9B,GACZt4B,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAGu3B,WACHltB,YAASymB,QAAKW,eAAY6G,cAAWvH,oBAE5C/1B,EAAiB,CAACgF,EAAGu3B,GAAS,UAkC9B,IAhCA,IAAMgB,EAAc57B,eAAa67B,wBAAwB/G,GACnD7F,EAAWjvB,eAAa87B,kBAC1Bz4B,EAAEzD,MACFg7B,EAAOh7B,MAA2C8N,EAASiuB,EAAWxH,EACtEC,GAAiB,EAAuBwH,GAEtCpH,EAAevF,EAASuF,aACxBD,EAActF,EAASsF,YACvBlF,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBM,EAAUX,EAASS,QAAQxK,KAC3BuK,EAASR,EAASS,QAAQC,IAC1BoM,EAAyC,iBAAxB9M,EAAS6F,WAE1B14B,EAAI,IAAImqB,eAAa0I,EAAStjB,SAAUtI,EAAEzE,OAE1CyT,EAAW3T,OAAKyF,eAAed,EAAEzD,OACjCo8B,EAAgBt9B,OAAKyF,eAAey2B,EAAOh7B,OAE3Cq8B,EAAe5pB,EAAS,GACxB6pB,EAAaH,EAAiB1pB,EAAS,GAAKA,EAAS,GACrD8pB,EAAaJ,EAAiB1pB,EAAS,GAAK,EAC5C+pB,EAAiBL,EAAiB,EAAI1pB,EAAS,GAC/CgqB,EAAejgC,EAAEsR,QAAQ,GACzB4uB,EAAaP,EAAiB3/B,EAAEsR,QAAQ,GAAKtR,EAAEsR,QAAQ,GACvD6uB,EAAaR,EAAiB3/B,EAAEsR,QAAQ,GAAK,EAC7C8uB,EAAiBT,EAAiB,EAAI3/B,EAAEsR,QAAQ,GAEhD3D,EAAQxG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACnC88B,EAAQl5B,EAAQtE,KAAKc,IAAI66B,EAAO16B,QAAQP,OACxC+8B,EAAQtgC,EAAEuD,OAEPrF,EAAI,EAAGA,EAAI20B,EAASrL,YAAatpB,EAGxC,IAFA,IAAMqiC,EAAWriC,EAAI2hC,EACfW,EAAWtiC,EAAI+hC,EACZ9L,EAAK,EAAGA,EAAKtB,EAASuB,YAAaD,EAG1C,IAFA,IAAMsM,EAAWD,EAAWrM,EAAK+L,EAC3B7L,EAAWF,EAAKtB,EAASE,aAAeM,EACrCwC,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,IAAMV,EAAKd,EAAWwB,EAAK5C,EAC3B,KAAIkC,EAAK,GAAKA,GAAMtC,EAAS2B,UAK7B,IAFA,IAAMkM,EAAW7K,EAAK+J,EAAc,GAC9Be,EAAWJ,EAAWpL,EAAK2K,EACxBpL,EAAK,EAAGA,EAAK7B,EAAS8B,WAAYD,EAGzC,IAFA,IAAMkM,EAAWH,EAAW/L,EAAKyL,EAC3BvL,EAAWF,EAAK7B,EAASG,YAAcQ,EACpCsC,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,IAAMT,EAAKT,EAAWkB,EAAK5C,EAC3B,KAAImC,EAAK,GAAKA,GAAMxC,EAASkC,SAM7B,IAHA,IACM8L,EAAWF,EAAWtL,EAAK0K,EAC7Be,EAFaJ,EAAW5K,EAAK8J,EAAc,GAGtCmB,EAAK,EAAGA,EAAKlO,EAASqB,aAAc6M,EAAI,CAE/C,IADA,IAAMC,GAAOrzB,EAAMkzB,EAAWE,EAAKf,GAC1BiB,GAAK,EAAGA,GAAKpO,EAASqO,cAAeD,GAC5CX,EAAMM,EAAWK,GAAKb,IAClBY,GAAOX,EAAMS,EAAWG,IAE9BH,GAAYjO,EAASqO,cAQjC,OAAO/5B,EAAQ5B,eAAevF,EAAEwD,MAAOxD,EAAEwC,MAAO89B,EAClD,CAEO,IAAMa,GAA6B,CACxCv6B,WAAYw6B,SACZt6B,YAAa,MACbC,WAAYu4B,ICnBP,IAAM+B,GAA2C,CACtDz6B,WAAY06B,uBACZx6B,YAAa,MACbC,oBArEmCC,GAK5B,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAG6xB,OACHxnB,YAASymB,QAAKW,eAAYV,oBAAiBuJ,gBAElDt/B,EAAiB,CAACgF,EAAG6xB,GAAK,wBAoB1B,IAlBA,IAAM0G,EAAc57B,eAAa67B,wBAAwB/G,GACnD7F,EAAWjvB,eAAa87B,kBAC1Bz4B,EAAEzD,MAA2C+9B,EAAajwB,EAC1D,EAAmBymB,EAAKC,GAAiB,EACzCwH,GAEGzM,iBAAcC,gBAAaoF,iBAAcD,gBAC1CwH,EAAyC,iBAAxB9M,EAAS6F,WAC1B8I,EAAK,IAAIrX,eAAa0I,EAAS0O,YAAa,WAE5C/c,EAAUqO,EAASS,QAAQxK,KAC3B2Y,EAAS5O,EAASS,QAAQC,IAC1B5lB,EAAQxG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACnCm+B,EAASv6B,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OAErC4K,EAAO,IAAIgc,eAAaljB,EAAEzD,MAAOyD,EAAEzE,MAAOmL,GAC1CurB,EAAQ,IAAI/O,eAAa2O,EAAGt1B,MAAOs1B,EAAGt2B,MAAOk/B,GAE1C7L,EAAK,EAAGA,EAAKuC,IAAgBvC,EAKpC,IAJA,IAAM8L,EAAQl7B,KAAKsN,IAAI,EAAGtN,KAAK0I,MAAMsyB,EAAS5L,GAAM9C,IAC9C6O,EAAQn7B,KAAKgO,IACfoe,EAASuB,WAAYvB,EAAS2B,SAAWiN,EAAS5L,GAAM9C,GAEnD+C,EAAK,EAAGA,EAAKqC,IAAerC,EAKnC,IAJA,IAAM+L,EAAQp7B,KAAKsN,IAAI,EAAGtN,KAAK0I,MAAMqV,EAAUsR,GAAM9C,IAC/C8O,EAAQr7B,KAAKgO,IACfoe,EAAS8B,UAAW9B,EAASkC,QAAUvQ,EAAUsR,GAAM9C,GAElD+N,EAAK,EAAGA,EAAKlO,EAASqB,aAAc6M,EAC3C,IAAK,IAAIE,EAAK,EAAGA,EAAKpO,EAASqO,cAAeD,EAAI,CAEhD,IADA,IAAIvH,EAAU,EACLx7B,EAAI,EAAGA,EAAI20B,EAASrL,YAAatpB,EACxC,IAAK,IAAIi2B,EAAKwN,EAAOxN,EAAKyN,IAASzN,EAEjC,IADA,IAAMgB,EAAKU,EAAK1B,EAAKpB,EAAe0O,EAC3B/M,EAAKmN,EAAOnN,EAAKoN,IAASpN,EAAI,CACrC,IAAMW,EAAKS,EAAKpB,EAAK1B,EAAcxO,EAEjCkV,GADEiG,EACUxxB,EAAKxK,IAAIzF,EAAGi3B,EAAIE,EAAI0L,GAC3B7H,EAAMv1B,IAAIzF,EAAGi2B,EAAIO,EAAIuM,GAEd9yB,EAAKxK,IAAIzF,EAAG6iC,EAAI5L,EAAIE,GAC3B6D,EAAMv1B,IAAIzF,EAAG+iC,EAAI9M,EAAIO,GAKlC8M,EAAGx9B,IAAI01B,EAAS7D,EAAIC,EAAIiL,EAAIE,GAMpC,OAAO95B,EAAQ5B,eAAei8B,EAAGh+B,MAAOg+B,EAAGh/B,MAAOg/B,EAAGj+B,OACvD,GC8BO,IAAMw+B,GAA0C,CACrDn7B,WAAYo7B,sBACZl7B,YAAa,MACbC,oBAjGkCC,GAK3B,IAAAkC,WAAQ/B,YAASwD,UACjBmuB,OAAI0F,WACJ/c,eAAYnQ,YAASymB,QAAKW,eAAYV,oBAE7C/1B,EAAiB,CAAC62B,EAAI0F,GAAS,uBAE/B,IAAMoB,EAAgBt9B,OAAKyF,eAAey2B,EAAOh7B,OAC3Cy+B,EAAY3/B,OAAKyF,eAAe+wB,EAAGt1B,OAErCg8B,EAAc57B,eAAa67B,wBAAwB/G,GACjD7F,EAAWjvB,eAAa87B,kBAC1Bje,EAAY+c,EAAOh7B,MAA2C8N,EAC9D,EAAmBymB,EAAKC,GAAiB,EAAOwH,GAE9CxG,EAAK,IAAI7O,eAAa0I,EAASyF,QAAS,WACxC4J,EAAWlJ,EAAGz1B,OACd4+B,EAAWh7B,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OACvC6+B,EAAYj7B,EAAQtE,KAAKc,IAAI66B,EAAO16B,QAAQP,OAC5CiH,SAAC63B,OAAOC,OAAOC,OAEnB/a,cACA4Q,iBACAD,gBACAjE,eACAM,aACAO,YACAmM,gBACA9M,cACAO,aACA5B,iBACAC,gBAEFwM,EAAc3M,EAAS6F,WAcvB,IAbA,IAAM+I,EAASrJ,EAAe,EAAIvF,EAASS,QAAQC,IAC7C/O,EAAU2T,EAAc,EAAItF,EAASS,QAAQxK,KAE7C6W,EAAiC,iBAAhBH,EACjBK,EAAe7G,EAAG1nB,QAAQ,GAC1BwuB,EAAaH,EAAiB3G,EAAG1nB,QAAQ,GAAK0nB,EAAG1nB,QAAQ,GACzDyuB,EAAaJ,EAAiB3G,EAAG1nB,QAAQ,GAAK,EAC9C0uB,EAAiBL,EAAiB,EAAI3G,EAAG1nB,QAAQ,GACjD2uB,EAAegC,EAAU,GACzB/B,EAAaP,EAAiBsC,EAAU,GAAKA,EAAU,GACvD9B,EAAaR,EAAiBsC,EAAU,GAAK,EAC7C7B,EAAiBT,EAAiB,EAAIsC,EAAU,GAE7C/jC,EAAI,EAAGA,EAAIspB,IAAatpB,EAC/B,IAAK,IAAI6iC,EAAK,EAAGA,EAAK7M,IAAc6M,EAClC,IAAK,IAAI5L,EAAK,EAAGA,EAAKX,IAAYW,EAMhC,IALA,IAAMd,EAAWc,EAAKsM,EAChBnN,EAAQ7tB,KAAKsN,IAAI,EAAGtN,KAAK0I,KAAKklB,EAAWtB,IACzC6O,EACFn7B,KAAKgO,IAAI2f,GAAYgE,EAAe/D,GAAYtB,GAE3CsC,GAAK,EAAGA,GAAKN,IAAWM,GAAI,CAOnC,IANA,IAAMT,GAAWS,GAAK7Q,EAChBqQ,GAAQpuB,KAAKsN,IAAI,EAAGtN,KAAK0I,KAAKylB,GAAW5B,IACzC8O,GACFr7B,KAAKgO,IAAIkgB,GAAWwD,EAAcvD,IAAY5B,GAE9C0G,GAAU,EACLvF,GAAKG,EAAOH,GAAKyN,IAASzN,GAGjC,IAFA,IAAM0B,GAAK1B,GAAKpB,EAAesB,EAEtBK,GAAKG,GAAOH,GAAKoN,KAASpN,GAOjC,IANA,IACM8N,GACFvC,EAAe/hC,EAAIgiC,EAAa/L,GAAKgM,EAAazL,GAChD+N,GAAYJ,GAASjK,EAAe,EAAIvC,IAC1CyM,GAASnK,EAAc,GAJhBzD,GAAK1B,EAAc4B,KAIO2N,EAAQxB,EAEpCE,GAAK,EAAGA,GAAKC,IAAeD,GAAI,CAGvCvH,IAFcyI,EAASK,GAAWpC,EAAiBa,IACpCmB,EAAUK,GAAYxB,IAO3CiB,EAFiBrC,EAAe3hC,EAAI4hC,EAAa3K,EAC7C4K,EAAa1K,GAAK2K,EAAiBe,GAClBrH,GAM7B,OAAOvyB,EAAQ5B,eAAeyzB,EAAGx1B,MAAOw1B,EAAGx2B,MAAOw2B,EAAGz1B,OACvD,GCJO,IAAMm/B,GAA6B,CACxC97B,WAAY+7B,SACZ77B,YAAa,MACbC,oBA1FEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAGu3B,WACHltB,YAASymB,QAAKwH,cAErBt9B,EAAiB,CAACgF,EAAGu3B,GAAS,UA4B9B,IA1BA,IAAM3L,EAAWjvB,eAAag/B,kBAC1B37B,EAAEzD,MACFg7B,EAAOh7B,MAAmD8N,EAC1DiuB,EAAWxH,GAGbgB,gBACAX,iBACAD,gBACAlC,kBACAhD,mBACAC,kBACAI,YAEI6C,EAAW7C,EAAQ8C,MACnB5C,EAAUF,EAAQxK,KAClBuK,EAASC,EAAQC,IACjBvzB,EAAI,IAAImqB,eAAa0I,EAAStjB,SAAUtI,EAAEzE,OAE1CmL,EAAQxG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACnC88B,EAAQl5B,EAAQtE,KAAKc,IAAI66B,EAAO16B,QAAQP,OACxC+8B,EAAQtgC,EAAEuD,OAEV0S,EAAW3T,OAAKyF,eAAed,EAAEzD,OACjCo8B,EAAgBt9B,OAAKyF,eAAey2B,EAAOh7B,OAExCtF,EAAI,EAAGA,EAAI20B,EAASrL,YAAatpB,EAGxC,IAFA,IAAMqiC,EAAWriC,EAAI+X,EAAS,GACxBuqB,EAAWtiC,EAAI8B,EAAEsR,QAAQ,GACtBuxB,EAAK,EAAGA,EAAKhQ,EAAS2D,WAAYqM,EAGzC,IAFA,IAAMpC,EAAWD,EAAWqC,EAAK7iC,EAAEsR,QAAQ,GACrCwxB,EAAWD,EAAKhQ,EAASmD,YAAcG,EACpC4M,EAAK,EAAGA,EAAKhK,IAAegK,EAAI,CACvC,IAAMC,EAAKF,EAAWC,EAAK9M,EAC3B,KAAI+M,EAAK,GAAKA,GAAMnQ,EAAS+D,SAM7B,IAHA,IAAM8J,EAAWqC,EAAKnD,EAAc,GAC9Be,EAAWJ,EAAWyC,EAAK/sB,EAAS,GAEjCke,EAAK,EAAGA,EAAKtB,EAASuB,YAAaD,EAG1C,IAFA,IAAMyM,EAAWH,EAAWtM,EAAKn0B,EAAEsR,QAAQ,GACrC+iB,EAAWF,EAAKtB,EAASE,aAAeM,EACrCwC,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,IAAMV,EAAKd,EAAWwB,EAAK5C,EAC3B,KAAIkC,EAAK,GAAKA,GAAMtC,EAAS2B,UAK7B,IAFA,IAAMyO,EAAWvC,EAAW7K,EAAK+J,EAAc,GACzCiB,EAAWF,EAAWxL,EAAKlf,EAAS,GACjCye,EAAK,EAAGA,EAAK7B,EAAS8B,WAAYD,EAGzC,IAFA,IAAMwO,EAAWtC,EAAWlM,EAAK7B,EAASqO,YACpCtM,EAAWF,EAAK7B,EAASG,YAAcQ,EACpCsC,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,IAAMT,EAAKT,EAAWkB,EAAK5C,EAC3B,KAAImC,EAAK,GAAKA,GAAMxC,EAASkC,SAM7B,IAHA,IAAM+L,EAAWmC,EAAWnN,EAAK8J,EAAc,GACzCuD,EAAWtC,EAAWxL,EAAKxC,EAASqB,WACtCkP,EAAWtC,EACNC,EAAK,EAAGA,EAAKlO,EAASqB,aAAc6M,EAAI,CAE/C,IADA,IAAMC,GAAOrzB,EAAMw1B,EAAWpC,GACrBE,GAAK,EAAGA,GAAKpO,EAASqO,cAAeD,GAC5CX,EAAM4C,EAAWjC,KAAOD,GAAOX,EAAM+C,EAAWnC,IAElDmC,GAAYvQ,EAASqO,eAUrC,OAAO/5B,EAAQ5B,eAAevF,EAAEwD,MAAOxD,EAAEwC,MAAOxC,EAAEuD,OACpD,GCQO,IAAM8/B,GAA6C,CACxDz8B,WAAY08B,yBACZx8B,YAAa,MACbC,oBAjGqCC,GAK9B,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAG6xB,OACHxnB,YAASymB,QAAKwJ,gBAErBt/B,EAAiB,CAACgF,EAAG6xB,GAAK,0BA4B1B,IA1BA,IAAM7iB,EAAW3T,OAAKyF,eAAed,EAAEzD,OACjCy+B,EAAY3/B,OAAKyF,eAAe+wB,EAAGt1B,OAEnCqvB,EAAWjvB,eAAag/B,kBAC1B37B,EAAEzD,MAAmD+9B,EAAajwB,EAClE,EAAmBymB,GAEjB/B,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvB+F,EAAclG,EAASkG,YACvBX,EAAevF,EAASuF,aACxBD,EAActF,EAASsF,YAEvBoL,EAAK,IAAIpZ,eAAa0I,EAAS0O,YAAa,WAC5CiC,EAAWD,EAAGhgC,OACdiH,iBAACi5B,OAAMC,OAAMC,OAAMC,OACnBzB,EAAWh7B,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OACvCoB,SAACk/B,OAAMC,OAAMC,OAAMC,OACnBpR,EAAUzrB,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACrCuJ,SAACm3B,OAAKC,OAAKC,OAAKC,OAEhBC,EAAWxR,EAASS,QAAQ8C,MAC5B5R,EAAUqO,EAASS,QAAQxK,KAC3B2Y,EAAS5O,EAASS,QAAQC,IAEvBwP,EAAK,EAAGA,EAAKhK,IAAegK,EAMnC,IALA,IAAMuB,EAAQ79B,KAAKsN,IAAI,EAAGtN,KAAK0I,MAAMk1B,EAAWtB,GAAM/M,IAChDuO,EAAQ99B,KAAKgO,IACfoe,EAAS2D,UAAW3D,EAAS+D,QAAUyN,EAAWtB,GAAM/M,GACtD0K,EAAWqC,EAAKU,EAEb5N,EAAK,EAAGA,EAAKuC,IAAgBvC,EAMpC,IALA,IAAM8L,EAAQl7B,KAAKsN,IAAI,EAAGtN,KAAK0I,MAAMsyB,EAAS5L,GAAM9C,IAC9C6O,EAAQn7B,KAAKgO,IACfoe,EAASuB,WAAYvB,EAAS2B,SAAWiN,EAAS5L,GAAM9C,GACtDkQ,EAAWpN,EAAK6N,EAAOhD,EAEpB5K,EAAK,EAAGA,EAAKqC,IAAerC,EAMnC,IALA,IAAM+L,EAAQp7B,KAAKsN,IAAI,EAAGtN,KAAK0I,MAAMqV,EAAUsR,GAAM9C,IAC/C8O,EAAQr7B,KAAKgO,IACfoe,EAAS8B,UAAW9B,EAASkC,QAAUvQ,EAAUsR,GAAM9C,GACrD8N,GAAWhL,EAAK6N,EAAOV,EAEpBlC,GAAK,EAAGA,GAAKlO,EAASqB,aAAc6M,GAG3C,IAFA,IAAMqC,GAAWrC,GAAK6C,EAAO9C,GAEpBG,GAAK,EAAGA,GAAKpO,EAASqO,cAAeD,GAAI,CAEhD,IADA,IAAIvH,GAAU,EACLx7B,GAAI,EAAGA,GAAI20B,EAASrL,YAAatpB,GAIxC,IAHA,IAAMqiC,GAAWriC,GAAI+lC,EACfzD,GAAWtiC,GAAI2lC,EAEZhB,GAAKyB,EAAOzB,GAAK0B,IAAS1B,GAKjC,IAJA,IACMlC,IADKoC,EAAKF,GAAK7M,EAAcqO,GACbH,EAAM3D,GACtBE,GAAWoC,GAAKiB,EAAOtD,GAEpBrM,GAAKwN,EAAOxN,GAAKyN,IAASzN,GAKjC,IAJA,IACM0M,IADKhL,EAAK1B,GAAKpB,EAAe0O,GACd0C,EAAMxD,GACtBC,GAAWzM,GAAK4P,EAAOtD,GAEpB/L,GAAKmN,EAAOnN,GAAKoN,IAASpN,GAAI,CACrC,IAEMwO,GAAWxO,GAAKsP,EAAOpD,GAE7BlH,IAAW9G,GAJAkD,EAAKpB,GAAK1B,EAAcxO,GACb4f,EAAMvD,GAGEE,IAAMoB,EAASe,GAAWjC,IAKhEuC,EAASJ,GAAWnC,IAAMvH,GAOpC,OAAOvyB,EAAQ5B,eAAeg+B,EAAG//B,MAAO+/B,EAAG/gC,MAAO+gC,EAAGhgC,OACvD,GCSO,IAAMihC,GAA4C,CACvD59B,WAAY69B,wBACZ39B,YAAa,MACbC,oBAxGoCC,GAK7B,IAAAkC,WAAQ/B,YAASwD,UACjBmuB,OAAI0F,WACJzG,QAAKzmB,YAASmQ,eAErBxf,EAAiB,CAAC62B,GAAK,yBAqCvB,IAnCA,IAAMmJ,EAAY3/B,OAAKyF,eAAe+wB,EAAGt1B,OACnCo8B,EAAgBt9B,OAAKyF,eAAey2B,EAAOh7B,OAE3CqvB,EAAWjvB,eAAag/B,kBAC1BnhB,EAAY+c,EAAOh7B,MACnB8N,EAAS,EAAmBymB,GAE1BiB,EAAK,IAAI7O,eAAa0I,EAASyF,QAAS,WACxC4J,EAAWlJ,EAAGz1B,OACdiH,iBAACk6B,OAAMC,OAAMC,OAAMC,OACnB1C,EAAWh7B,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OACvCoB,SAACk/B,OAAMC,OAAMC,OAAMC,OACnB5B,EAAYj7B,EAAQtE,KAAKc,IAAI66B,EAAO16B,QAAQP,OAC5CuJ,SAACu1B,OAAOC,OAAOC,OAAOuC,OAE1Btd,cACAuR,gBACAX,iBACAD,gBACAjE,eACA0C,YACApC,aACAO,YACAmM,gBACA1K,aACApC,cACAO,aACAqB,gBACAjD,iBACAC,gBAEIqR,EAAWtL,EAAc,EAAIlG,EAASS,QAAQ8C,MAC9CqL,EAASrJ,EAAe,EAAIvF,EAASS,QAAQC,IAC7C/O,EAAU2T,EAAc,EAAItF,EAASS,QAAQxK,KAE1C5qB,EAAI,EAAGA,EAAIspB,IAAatpB,EAC/B,IAAK,IAAI6iC,EAAK,EAAGA,EAAK7M,IAAc6M,EAElC,IAAK,IAAIiC,GAAK,EAAGA,GAAKpM,IAAWoM,GAO/B,IANA,IAAMF,GAAWE,GAAKqB,EAChBU,GAAQt+B,KAAKsN,IAAI,EAAGtN,KAAK0I,KAAK2zB,GAAW9M,IACzCuO,GACF99B,KAAKgO,IAAI+hB,GAAWuC,EAAc+J,IAAY9M,GAGzCb,GAAK,EAAGA,GAAKX,IAAYW,GAMhC,IALA,IAAMd,GAAWc,GAAKsM,EAChBnN,GAAQ7tB,KAAKsN,IAAI,EAAGtN,KAAK0I,KAAKklB,GAAWtB,IACzC6O,GACFn7B,KAAKgO,IAAI2f,GAAYgE,EAAe/D,IAAYtB,GAE3CsC,GAAK,EAAGA,GAAKN,IAAWM,GAAI,CAOnC,IANA,IAAMT,GAAWS,GAAK7Q,EAChBqQ,GAAQpuB,KAAKsN,IAAI,EAAGtN,KAAK0I,KAAKylB,GAAW5B,IACzC8O,GACFr7B,KAAKgO,IAAIkgB,GAAWwD,EAAcvD,IAAY5B,GAE9C0G,GAAU,EACLmJ,GAAKkC,GAAOlC,GAAK0B,KAAS1B,GAGjC,IAFA,IAAME,GAAKF,GAAK7M,EAAc8M,GAErB3O,GAAKG,GAAOH,GAAKyN,KAASzN,GAGjC,IAFA,IAAM0B,GAAK1B,GAAKpB,EAAesB,GAEtBK,GAAKG,GAAOH,GAAKoN,KAASpN,GAOjC,IANA,IACM8N,GAAWqB,EAAO3lC,EAAI4lC,EAAOjB,GAAKkB,EAAO5P,GAAK6P,EAAOtP,GACrD+N,GAAYJ,GAAStJ,EAAc,EAAIgK,IACzCT,GAASlK,EAAe,EAAIvC,IAC5B0M,GAASpK,EAAc,GAJhBzD,GAAK1B,EAAc4B,KAIOkQ,EAAQ/D,EAEpCE,GAAK,EAAGA,GAAKC,IAAeD,GAAI,CAGvCvH,IAFcyI,EAASK,GAAWvB,IACnBmB,EAAUK,GAAYxB,IAM7CiB,EAASwC,EAAOxmC,EAAIymC,EAAO3B,GAAK4B,EAAOzP,GAAK0P,EAAOxP,GAAK0L,GACpDrH,GAOd,OAAOvyB,EAAQ5B,eAAeyzB,EAAGx1B,MAAOw1B,EAAGx2B,MAAOw2B,EAAGz1B,OACvD,GCpGayhC,GAAMp2B,EAAgBq2B,OAAK,SAAC/1B,GAAO,OAAAzI,KAAKu+B,IAAI91B,MAE5Cg2B,GAA0B,CACrCt+B,WAAYq+B,MACZn+B,YAAa,MACbC,WAAYi+B,ICLDG,GAAOv2B,EAAgBw2B,QAAM,SAACl2B,GAAO,OAAAzI,KAAK0+B,KAAKj2B,MAE/Cm2B,GAA2B,CACtCz+B,WAAYw+B,OACZt+B,YAAa,MACbC,WAAYo+B,ICuIP,IAAMG,GAAoC,CAC/C1+B,WAAY2+B,gBACZz+B,YAAa,MACbC,oBA/I4BC,GA4B5B,IAvBO,IAAAkC,WAAQ/B,YAASwD,UACjB66B,UAAOC,UAAOC,WACdC,aAAUC,WAAQC,uBAEnBr7B,eAAC+e,OAAOuc,OAAaC,OAAYC,OACjCC,EAAWR,EAAMjiC,MAAM,GAEvBmB,SAACuhC,OAAYC,OACb9iB,EACFje,SAAO,CAAC6gC,EAAUC,EAAYC,EAAWH,GAAc,WAErDI,EAAUj/B,EAAQtE,KAAKc,IAAI8hC,EAAM3hC,QAAQP,OACzC8iC,EAAal/B,EAAQtE,KAAKc,IAAI+hC,EAAO5hC,QAAQP,OAC7C+iC,EAAYn/B,EAAQtE,KAAKc,IAAI6hC,EAAM1hC,QAAQP,OAE3CgjC,EACFjkC,OAAKyF,eAAey9B,EAAMhiC,OACxBgjC,EAAYlkC,OAAKyF,eACnBsb,EAAO7f,OAKFtF,EAAI,EAAGA,EAAI+nC,EAAU/nC,IAAK,CACjC,IAAMuoC,EAAe,EAAJvoC,EACXwoC,EAAKN,EAAQK,GACbE,EAAKP,EAAQK,EAAW,GACxBG,EAAKR,EAAQK,EAAW,GACxBI,EAAKT,EAAQK,EAAW,GAExBK,EAAeT,EAAWnoC,GAChC,KAAI4oC,GAAQvd,GASZ,IALA,IAAMwd,EACDb,EAAa,GAAMU,EAAKF,IAAOZ,EAAc,IAAMI,EAAa,GAAK,EACpEc,EACDb,EAAY,GAAMU,EAAKF,IAAOZ,EAAa,IAAMI,EAAY,GAAK,EAE9DnmC,EAAI,EAAGA,EAAIkmC,EAAYlmC,IAAK,CACnC,IAAMinC,EAAgBf,EAAa,EAC/BQ,GAAMZ,EAAc,GAAK9lC,IACzB,IAAO0mC,EAAKE,IAAOd,EAAc,GAErC,GAAImB,EAAO,GAAKA,EAAOnB,EAAc,EACnC,IAAK,IAAI7+B,EAAI,EAAGA,EAAIk/B,EAAWl/B,IAC7B,IAAK,IAAI4gB,EAAI,EAAGA,EAAIme,EAAane,IAAK,CACpC,IAAMqf,EACFrf,EAAI5gB,EAAIu/B,EAAU,GAAKxmC,EAAIwmC,EAAU,GAAKtoC,EAAIsoC,EAAU,GAC5DnjB,EAAO9f,OAAO2jC,GAAOrB,OAM3B,GAAe,aAAXD,EACF,KAAMuB,EAAS1gC,KAAKoK,MAAMo2B,GACpBG,EAAY3gC,KAAK0I,KAAK83B,GACtBI,EAAQJ,EAAOE,EAErB,IAASlgC,EAAI,EAAGA,EAAIk/B,EAAWl/B,IAAK,CAKlC,IAJMqgC,EAAQnB,EAAY,EACtBQ,GAAMZ,EAAa,GAAK9+B,EAAI+/B,EAC5B,IAAOL,EAAKE,IAAOd,EAAa,IAEzB,GAAKuB,EAAOvB,EAAa,EAClC,IAASle,EAAI,EAAGA,EAAIme,EAAane,IAAK,CAC9Bqf,EACFrf,EAAI5gB,EAAIu/B,EAAU,GAAKxmC,EAAIwmC,EAAU,GAAKtoC,EAAIsoC,EAAU,GAC5DnjB,EAAO9f,OAAO2jC,GAAOrB,MAKzB,KAAM0B,EAAU9gC,KAAKoK,MAAMy2B,GACrBE,EAAW/gC,KAAK0I,KAAKm4B,GACrBG,EAAQH,EAAOC,EAErB,IAAS1f,EAAI,EAAGA,EAAIme,EAAane,IAAK,CACpC,IAEM6f,EAAUpB,EAFZY,EAAMrf,EAAI0f,EAAUhB,EAAS,GAAKY,EAASZ,EAAS,GACpDO,EAAOP,EAAS,IAKdoB,EAAWrB,EAFjBY,EAAMrf,EAAI2f,EAAWjB,EAAS,GAAKY,EAASZ,EAAS,GACjDO,EAAOP,EAAS,IAKdqB,EAAatB,EAFnBY,EAAMrf,EAAI0f,EAAUhB,EAAS,GAAKa,EAAYb,EAAS,GACnDO,EAAOP,EAAS,IAOdhT,EAAMmU,GAAWC,EAAWD,GAAWD,EACvCI,EAASD,GAHKtB,EAFpBY,EAAMrf,EAAI2f,EAAWjB,EAAS,GAAKa,EAAYb,EAAS,GACpDO,EAAOP,EAAS,IAIuBqB,GAAcH,EAEzDP,EAAMrf,EAAI5gB,EAAIu/B,EAAU,GAAKxmC,EAAIwmC,EAAU,GAAKtoC,EAAIsoC,EAAU,GAC9DnjB,EAAO9f,OAAO2jC,GAAO3T,GAAQsU,EAAStU,GAAO8T,EAzBf,EAlBH,MA+C/B,IAASpgC,EAAI,EAAGA,EAAIk/B,IAAal/B,EAAG,CAClC,IAAMqgC,EAIN,IAJMA,EAAQnB,EAAY,EACtBQ,GAAMZ,EAAa,GAAK9+B,EAAI+/B,EAC5B,IAAOL,EAAKE,IAAOd,EAAa,IAEzB,GAAKuB,EAAOvB,EAAa,EAClC,IAASle,EAAI,EAAGA,EAAIme,EAAane,IAAK,CAC9Bqf,EACFrf,EAAI5gB,EAAIu/B,EAAU,GAAKxmC,EAAIwmC,EAAU,GAAKtoC,EAAIsoC,EAAU,GAC5DnjB,EAAO9f,OAAO2jC,GAAOrB,MAKzB,KAAMiC,EAAWrhC,KAAKshC,MAAMT,GACtBU,GAAWvhC,KAAKshC,MAAMd,GAC5B,IAASpf,EAAI,EAAGA,EAAIme,EAAane,IAAK,CACpC,IAAMogB,GAAQpgB,EAAIigB,EAAWvB,EAAS,GAAKyB,GAAWzB,EAAS,GAC3DO,EAAOP,EAAS,GACd2B,GACFrgB,EAAI5gB,EAAIu/B,EAAU,GAAKxmC,EAAIwmC,EAAU,GAAKtoC,EAAIsoC,EAAU,GAC5DnjB,EAAO9f,OAAO2kC,IAAU5B,EAAU2B,IAPH,IAczC,OAAO9gC,EAAQ5B,eAAe8d,EAAO7f,MAAO6f,EAAO7gB,MAAO6gB,EAAO9f,OACnE,GC5EO,IAAM4kC,GAA8B,CACzCvhC,WAAYwhC,UACZthC,YAAa,MACbC,oBA9DEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA+P,SAAMqxB,cAAWC,YAExBrmC,EAAiBgF,EAAG,WAEpB,IAAMmQ,EAAcxT,eAAayT,mBAAmB,CAACL,GAAO/P,EAAEzD,MAAMrC,QAChE0vB,EAAK5pB,EACU,MAAfmQ,IACFyZ,EAAKxa,GAAU,CAACnN,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACoL,KAAMqB,MAEtD,IAAMmxB,EAAe3kC,eAAa4T,iBAAiB,EAAGvQ,EAAEzD,MAAMrC,QAAQ,GAEtE,GAAIonC,IAAiB1X,EAAGrtB,MAAMrC,OAAS,EACrC,MAAM,IAAIkE,MACN,sDACQwrB,EAAGrtB,MAAMrC,OAAS,oBAAkBonC,GAYlD,IATA,IAAMC,EAAc5xB,aAAWia,EAAGruB,MAAO,SACnC8D,EAAOhE,OAAKmmC,mBACDnmC,OAAK8E,cAAcypB,EAAGrtB,OAAQglC,GAEzC/gC,EAAQN,EAAQtE,KAAKc,IAAIktB,EAAG/sB,QAAQP,OACpCmlC,EAAW7X,EAAGrtB,MAAMqtB,EAAGrtB,MAAMrC,OAAS,GACtCwnC,EAAgBL,EAClB,SAAC7mC,EAAWgN,GAAc,OAAAhN,EAAIinC,EAAWj6B,EAAI,GAC7C,SAAChN,EAAWgN,GAAc,OAAAhN,EAAIgN,GACzBhN,EAAI,EAAGA,EAAIgG,EAAMtG,OAAQM,GAAKinC,EACrC,IAAK,IAAIj6B,EAAI,EAAGA,EAAIi6B,EAAUj6B,IAAK,CACjC,IAAM+Q,EAAMmpB,EAAclnC,EAAGgN,GAC7B,GAAU,IAANA,EACFnI,EAAKkZ,GAAO6oB,EAAY,EAAI5gC,EAAM+X,OAC7B,CACL,IAAMopB,EAAUD,EAAclnC,EAAGgN,EAAI,GACrCnI,EAAKkZ,GAAO6oB,EAAY5gC,EAAMmhC,GAAWtiC,EAAKsiC,GACtBnhC,EAAM+X,GAAOlZ,EAAKsiC,IAKhD,IAAMnpC,EAAS0H,EAAQ5B,eAAesrB,EAAGrtB,MAAOglC,EAAaliC,GAE7D,GAAmB,MAAf8Q,EAAqB,CACvB,IACMyxB,EAA0BxyB,GAC5B,CAACnN,OAAQ,CAACjC,EAAGxH,GAAS0H,UAASwD,MAAO,CAACoL,KAFhBnS,eAAaklC,uBAAuB1xB,MAO/D,OAHAjQ,EAAQ2D,8BAA8BrL,GACtC0H,EAAQ2D,8BAA8B+lB,GAE/BgY,EAGT,OAAOppC,CACT,GCEO,IAAMspC,GAA6B,CACxCniC,WAAYoiC,SACZliC,YAAa,MACbC,oBA9DEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA+P,SAAMqxB,cAAWC,YAExBrmC,EAAiBgF,EAAG,UAEpB,IAAMmQ,EAAcxT,eAAayT,mBAAmB,CAACL,GAAO/P,EAAEzD,MAAMrC,QAChE0vB,EAAK5pB,EACU,MAAfmQ,IACFyZ,EAAKxa,GAAU,CAACnN,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACoL,KAAMqB,MAEtD,IAAMmxB,EAAe3kC,eAAa4T,iBAAiB,EAAGvQ,EAAEzD,MAAMrC,QAAQ,GAEtE,GAAIonC,IAAiB1X,EAAGrtB,MAAMrC,OAAS,EACrC,MAAM,IAAIkE,MACN,qDACQwrB,EAAGrtB,MAAMrC,OAAS,oBAAkBonC,GAYlD,IATA,IAAMC,EAAc5xB,aAAWia,EAAGruB,MAAO,SACnC8D,EAAOhE,OAAKmH,oBACDnH,OAAK8E,cAAcypB,EAAGrtB,OAAQglC,GAEzC/gC,EAAQN,EAAQtE,KAAKc,IAAIktB,EAAG/sB,QAAQP,OACpCmlC,EAAW7X,EAAGrtB,MAAMqtB,EAAGrtB,MAAMrC,OAAS,GACtCwnC,EAAgBL,EAClB,SAAC7mC,EAAWgN,GAAc,OAAAhN,EAAIinC,EAAWj6B,EAAI,GAC7C,SAAChN,EAAWgN,GAAc,OAAAhN,EAAIgN,GACzBhN,EAAI,EAAGA,EAAIgG,EAAMtG,OAAQM,GAAKinC,EACrC,IAAK,IAAIj6B,EAAI,EAAGA,EAAIi6B,EAAUj6B,IAAK,CACjC,IAAM+Q,EAAMmpB,EAAclnC,EAAGgN,GAC7B,GAAU,IAANA,EACFnI,EAAKkZ,GAAO6oB,EAAY,EAAI5gC,EAAM+X,OAC7B,CACL,IAAMopB,EAAUD,EAAclnC,EAAGgN,EAAI,GACrCnI,EAAKkZ,GAAO6oB,EAAY5gC,EAAMmhC,GAAWtiC,EAAKsiC,GACtBnhC,EAAM+X,GAAOlZ,EAAKsiC,IAKhD,IAAMnpC,EAAS0H,EAAQ5B,eAAesrB,EAAGrtB,MAAOglC,EAAaliC,GAE7D,GAAmB,MAAf8Q,EAAqB,CACvB,IACMyxB,EAA0BxyB,GAC5B,CAACnN,OAAQ,CAACjC,EAAGxH,GAAS0H,UAASwD,MAAO,CAACoL,KAFhBnS,eAAaklC,uBAAuB1xB,MAO/D,OAHAjQ,EAAQ2D,8BAA8BrL,GACtC0H,EAAQ2D,8BAA8B+lB,GAE/BgY,EAGT,OAAOppC,CACT,GC5BO,IAAMwpC,GAAoC,CAC/CriC,WAAYsiC,gBACZpiC,YAAa,MACbC,oBAlC4BC,GAKrB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAG81B,YACHhvB,SAAMM,iBAEb,GAAuB,IAAnBpH,EAAEzD,MAAMrC,OAAc,CACxB,IAGM8M,EACFP,EAJUvG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACrB4D,EAAQtE,KAAKc,IAAIo5B,EAAQj5B,QAAQP,OAGhBw5B,EAAQv6B,MAAOu6B,EAAQv5B,MAAOuK,GAEnE,OAAO5G,EAAQ5B,eAAe,CAACwI,GAAOgvB,EAAQv6B,MAAOyL,GAChD,GAAuB,IAAnBhH,EAAEzD,MAAMrC,OAAc,CAC/B,IAGMqN,EAASN,EAHF/G,EAAQgyB,WAA4BlyB,GAC9BE,EAAQgyB,WAA4B4D,GAEHhvB,EAAMM,GAE1D,OAAOlH,EAAQ5B,eAAeiJ,EAAOhL,MAAOu5B,EAAQv6B,MAAOgM,EAAOjL,QAGpE,MAAM,IAAI8B,MACN,qEACG4B,EAAEzD,MAAMrC,WACjB,GCoBO,IAAMgoC,GAAmC,CAC9CviC,WAAYwiC,eACZtiC,YAAa,MACbC,oBArD2BC,GAKpB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACAynB,cAAWgK,eAElBp2B,OAAKC,OACc,SAAfm2B,GACA,WAAM,MAAA,+DACFA,KAgBR,IAdA,IAAMlR,EAAYvgB,EAAEzD,MAAM,GACpB6lC,EAAcpiC,EAAEzD,MAAM,GACtB8lC,EAAariC,EAAEzD,MAAM,GACrB+lC,EAAatiC,EAAEzD,MAAM,GAErBgmC,EAAeH,EAAc3a,EAC7B+a,EAAcH,EAAa5a,EAC3Bgb,EAAcH,GAAc7a,EAAYA,GAExCkE,EAAUzrB,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACrC9D,EACF,IAAI+G,aAAaghB,EAAYgiB,EAAeC,EAAcC,GAE1DC,EAAY,EACPzrC,EAAI,EAAGA,EAAIspB,IAAatpB,EAC/B,IAAK,IAAI0rC,EAAI,EAAGA,EAAIJ,IAAgBI,EAGlC,IAFA,IAAMC,EAAMpjC,KAAKoK,MAAM+4B,EAAIlb,GACrBob,EAAWF,EAAIlb,EACZqb,EAAI,EAAGA,EAAIN,IAAeM,EAIjC,IAHA,IAAMC,EAAMvjC,KAAKoK,MAAMk5B,EAAIrb,GAErBub,GAAWH,EAAUpb,EADVqb,EAAIrb,GAC6Bgb,EACzCzrC,EAAI,EAAGA,EAAIyrC,IAAezrC,EAAG,CACpC,IACMisC,EADMjsC,EAAIgsC,EAENV,GAAcS,EAAMV,GAAcO,EAAMR,EAAcnrC,IAChEuB,EAAOkqC,KAAe/W,EAAQsX,GAMtC,OAAO/iC,EAAQ5B,eACX,CAACiiB,EAAWgiB,EAAcC,EAAaC,GAAcziC,EAAEzE,MAAO/C,EACpE,YC/CgB0qC,GAAsBnjC,GAK7B,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAGu3B,WACHltB,YAASymB,QAAKwH,cAAWvH,oBAEhC/1B,EAAiB,CAACgF,EAAGu3B,GAAS,yBAE9B,IAAMvoB,EAAW3T,OAAKyF,eAAed,EAAEzD,OACjCo8B,EAAgBt9B,OAAKyF,eAAey2B,EAAOh7B,OAE7C4mC,EAAa7K,EACC,MAAd6K,IACFA,EAAa,CAAC,EAAG,IAGnB9nC,OAAKC,OACDqB,eAAaq0B,+BAA+B3mB,EAAS84B,IACrD,WAAM,MAAA,gFACgB94B,qBAA0B84B,SAiBpD,IAfA,IAAMvX,EAAWjvB,eAAa87B,kBAC1Bz4B,EAAEzD,MACFg7B,EAAOh7B,MAA2C8N,EAAS84B,EAC3DrS,EAAKC,GAAiB,GAEnBI,iBAAcD,gBAAalF,mBAAgBC,kBAAeI,YAE3DE,EAAUF,EAAQxK,KAClBuK,EAASC,EAAQC,IACjB8W,EAAQxX,EAASqO,YAAcrO,EAASqB,WACxCl0B,EAAI,IAAImqB,eAAa0I,EAAStjB,SAAUtI,EAAEzE,OAC1CmL,EAAQxG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACnC88B,EAAQl5B,EAAQtE,KAAKc,IAAI66B,EAAO16B,QAAQP,OACxC+8B,EAAQtgC,EAAEuD,OAEPrF,EAAI,EAAGA,EAAI20B,EAASrL,YAAatpB,EAGxC,IAFA,IAAMqiC,EAAWriC,EAAI+X,EAAS,GACxBuqB,EAAWtiC,EAAI8B,EAAEsR,QAAQ,GACtB6iB,EAAK,EAAGA,EAAKtB,EAASuB,YAAaD,EAG1C,IAFA,IAAMsM,EAAWD,EAAWrM,EAAKn0B,EAAEsR,QAAQ,GACrC+iB,EAAWF,EAAKtB,EAASE,aAAeM,EACrCwC,EAAK,EAAGA,EAAKuC,IAAgBvC,EAAI,CACxC,IAAMV,EAAKd,EAAWwB,EAAK5C,EAC3B,KAAIkC,EAAK,GAAKA,GAAMtC,EAAS2B,UAK7B,IAFA,IAAMkM,EAAW7K,EAAK+J,EAAc,GAC9Be,EAAWJ,EAAWpL,EAAKlf,EAAS,GACjCye,EAAK,EAAGA,EAAK7B,EAAS8B,WAAYD,EAGzC,IAFA,IAAMkM,EAAWH,EAAW/L,EAAK10B,EAAEsR,QAAQ,GACrCsjB,EAAWF,EAAK7B,EAASG,YAAcQ,EACpCsC,EAAK,EAAGA,EAAKqC,IAAerC,EAAI,CACvC,IAAMT,EAAKT,EAAWkB,EAAK5C,EAC3B,KAAImC,EAAK,GAAKA,GAAMxC,EAASkC,SAO7B,IAJA,IAAMkO,EAAWvC,EAAW5K,EAAK8J,EAAc,GACzCiB,EAAWF,EAAWtL,EAAKxC,EAASqB,WACtCgP,EAAWtC,EACXE,EAAWmC,EACNlC,EAAK,EAAGA,EAAKlO,EAASqB,aAAc6M,EAAI,CAE/C,IADA,IAAMC,EAAOrzB,EAAMkzB,EAAWE,GACrBuJ,EAAI,EAAGA,EAAID,IAASC,EAC3BhK,EAAM4C,EAAWoH,IAAMtJ,EAAOX,EAAMS,EAAWwJ,GAEjDpH,GAAYmH,EACZvJ,GAAYuJ,IAQxB,OAAOljC,EAAQ5B,eAAevF,EAAEwD,MAAOxD,EAAEwC,MAAOxC,EAAEuD,OACpD,CAEO,IAAMgnC,GAA4C,CACvD3jC,WAAY4jC,wBACZ1jC,YAAa,MACbC,WAAYojC,ICxBP,IAAMM,GAA0D,CACrE7jC,WAAY8jC,sCACZ5jC,YAAa,MACbC,oBA/DkDC,GAK3C,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAG6xB,OACHxnB,YAASiuB,cAAWxH,QAAKC,oBAAiBuJ,gBAEjDt/B,EAAiB,CAACgF,EAAG6xB,GAAK,uCAkB1B,IAhBA,IAAMjG,EAAWjvB,eAAa87B,kBAC1Bz4B,EAAEzD,MAA2C+9B,EAAajwB,EAC1DiuB,EAAWxH,EAAKC,GAAiB,GAE9BjF,iBAAcC,gBAAaoF,iBAAcD,gBAE1CqJ,EAAK,IAAIrX,eAAa0I,EAAS0O,YAAa,WAE5C/c,EAAUqO,EAASS,QAAQxK,KAC3B2Y,EAAS5O,EAASS,QAAQC,IAC1B8W,EAAQxX,EAASqO,YAAcrO,EAASqB,WAExCvmB,EAAQxG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACnC4K,EAAO,IAAIgc,eAAaljB,EAAEzD,MAAOyD,EAAEzE,MAAOmL,GAC1C+zB,EAASv6B,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OACrC21B,EAAQ,IAAI/O,eAAa2O,EAAGt1B,MAAOs1B,EAAGt2B,MAAOk/B,GAC1C7L,EAAK,EAAGA,EAAKuC,IAAgBvC,EAKpC,IAJA,IAAM8L,EAAQl7B,KAAKsN,IAAI,EAAGtN,KAAK0I,MAAMsyB,EAAS5L,GAAM9C,IAC9C6O,EAAQn7B,KAAKgO,IACfoe,EAASuB,WAAYvB,EAAS2B,SAAWiN,EAAS5L,GAAM9C,GAEnD+C,EAAK,EAAGA,EAAKqC,IAAerC,EAKnC,IAJA,IAAM+L,EAAQp7B,KAAKsN,IAAI,EAAGtN,KAAK0I,MAAMqV,EAAUsR,GAAM9C,IAC/C8O,EAAQr7B,KAAKgO,IACfoe,EAAS8B,UAAW9B,EAASkC,QAAUvQ,EAAUsR,GAAM9C,GAElDiO,EAAK,EAAGA,EAAKpO,EAASqO,cAAeD,EAAI,CAKhD,IAJA,IAAMF,EAAKt6B,KAAK2b,MAAM6e,EAAKoJ,GACrBM,EAAK1J,EAAKoJ,EAEZ3Q,EAAU,EACLx7B,EAAI,EAAGA,EAAI20B,EAASrL,YAAatpB,EACxC,IAAK,IAAIi2B,EAAKwN,EAAOxN,EAAKyN,IAASzN,EAEjC,IADA,IAAMgB,EAAKU,EAAK1B,EAAKpB,EAAe0O,EAC3B/M,EAAKmN,EAAOnN,EAAKoN,IAASpN,EAAI,CACrC,IAAMW,EAAKS,EAAKpB,EAAK1B,EAAcxO,EACnCkV,GAAYvrB,EAAKxK,IAAIzF,EAAGi3B,EAAIE,EAAI0L,GAC3B7H,EAAMv1B,IAAIzF,EAAGi2B,EAAIO,EAAIuM,GAIhCO,EAAGx9B,IAAI01B,EAAS7D,EAAIC,EAAIiL,EAAI4J,GAKlC,OAAOxjC,EAAQ5B,eAAei8B,EAAGh+B,MAAOg+B,EAAGh/B,MAAOg/B,EAAGj+B,OACvD,GCyBO,IAAMqnC,GAAyD,CACpEhkC,WAAYikC,qCACZ/jC,YAAa,MACbC,oBAtFiDC,GAK1C,IAAAkC,WAAQ/B,YAASwD,UACjBmuB,OAAI0F,WACJltB,YAASiuB,cAAWxH,QAAKC,oBAAiBvW,eAEjDxf,EAAiB,CAAC62B,EAAI0F,GAAS,sCAiC/B,IA/BA,IAAMyD,EAAY3/B,OAAKyF,eAAe+wB,EAAGt1B,OACnCo8B,EAAgBt9B,OAAKyF,eAAey2B,EAAOh7B,OAE3CqvB,EAAWjvB,eAAa87B,kBAC1Bje,EAAY+c,EAAOh7B,MAA2C8N,EAC9DiuB,EAAWxH,EAAKC,GAAiB,GAE/BgB,EAAK,IAAI7O,eAAa0I,EAASyF,QAAS,WACxC4J,EAAWlJ,EAAGz1B,OACdiH,iBAACk6B,OAAMC,OAAMC,OACbzC,EAAWh7B,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OACvCoB,SAACk/B,OAAMC,OAAMC,OACb3B,EAAYj7B,EAAQtE,KAAKc,IAAI66B,EAAO16B,QAAQP,OAC5CuJ,SAACu1B,OAAOC,OAAOC,OAEnB/a,cACA4Q,iBACAD,gBACAjE,eACAM,aACAO,YACAmM,gBACA9M,cACAO,aACA5B,iBACAC,gBAEIyO,EAASrJ,EAAe,EAAIvF,EAASS,QAAQC,IAC7C/O,EAAU2T,EAAc,EAAItF,EAASS,QAAQxK,KAC7CuhB,EAAQnJ,EAAchN,EAEnBh2B,EAAI,EAAGA,EAAIspB,IAAatpB,EAC/B,IAAK,IAAI6iC,EAAK,EAAGA,EAAK7M,IAAc6M,EAClC,IAAK,IAAI5L,EAAK,EAAGA,EAAKX,IAAYW,EAMhC,IALA,IAAMd,EAAWc,EAAKsM,EAChBnN,EAAQ7tB,KAAKsN,IAAI,EAAGtN,KAAK0I,KAAKklB,EAAWtB,IACzC6O,EACFn7B,KAAKgO,IAAI2f,GAAYgE,EAAe/D,GAAYtB,GAE3CsC,EAAK,EAAGA,EAAKN,IAAWM,EAAI,CAOnC,IANA,IAAMT,GAAWS,EAAK7Q,EAChBqQ,GAAQpuB,KAAKsN,IAAI,EAAGtN,KAAK0I,KAAKylB,GAAW5B,IACzC8O,GACFr7B,KAAKgO,IAAIkgB,GAAWwD,EAAcvD,IAAY5B,GAE9C0G,GAAU,EACLvF,GAAKG,EAAOH,GAAKyN,IAASzN,GAGjC,IAFA,IAAM0B,GAAK1B,GAAKpB,EAAesB,EAEtBK,GAAKG,GAAOH,GAAKoN,KAASpN,GAMjC,IALA,IACM8N,GAAWqB,EAAO3lC,EAAI4lC,EAAO3P,GAAK4P,EAAOrP,GACzC+N,GAAYJ,GAASjK,EAAe,EAAIvC,IAC1CyM,GAASnK,EAAc,GAHhBzD,GAAK1B,EAAc4B,KAGO2N,EAAQxB,EAEpC4J,GAAK,EAAGA,GAAKN,IAASM,GAAI,CAIjCjR,IAFcyI,EAASK,IADZzB,EAAKsJ,EAAQM,KAETvI,EAAUK,GAAYkI,IAK3CzI,EAASwC,EAAOxmC,EAAIymC,EAAOxP,EAAKyP,EAAOvP,EAAK0L,GAAMrH,GAM1D,OAAOvyB,EAAQ5B,eAAeyzB,EAAGx1B,MAAOw1B,EAAGx2B,MAAOw2B,EAAGz1B,OACvD,GC/DO,IAAMunC,GAA2B,CACtClkC,WAAYmkC,OACZjkC,YAAa,MACbC,oBAtBmBC,GAUnB,IARO,IAAAkC,WAAQ/B,YACRF,MAED4H,EAAQvM,OAAK8E,cAAcH,EAAEzD,OAE7BmK,EAAQxG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACnCiL,EAASpJ,SAAO,CAACyJ,EAAOA,GAAQ5H,EAAEzE,OAClC8D,EAAOkI,EAAOjL,OACX9B,EAAI,EAAGA,EAAIkM,EAAMxM,OAAQM,IAChC6E,EAAK7E,EAAIoN,EAAQpN,GAAKkM,EAAMlM,GAG9B,IAAM8N,IAAetI,EAAEzD,MAAUyD,EAAEzD,OAEnC,OAAO2D,EAAQ5B,eAAegK,EAAUf,EAAOhM,MAAOgM,EAAOjL,OAC/D,GCjBaynC,GAAiC,CAC5CpkC,WAAYqkC,aACZnkC,YAAa,MACbC,WAAY,SAACyD,GAwCX,QAxCYtB,WAAQ/B,YAASwD,UACtB1D,MAAGu3B,WACHltB,YAASymB,QAAKwH,cACfr4B,EAAaC,EAEbwG,EAAQzG,EAAWrE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACtCyS,EAAQ/O,EAAEzD,MAAMrC,OAEhB+pC,EAAahkC,EAAWrE,KAAKc,IAAI66B,EAAO16B,QAAQP,OAChD4nC,EAAa3M,EAAOh7B,MAAMrC,OAE1BwD,qEACJ6iB,cACAgN,aACAO,YACAb,eACAE,cACAO,aACArB,YACAP,iBACAC,gBACAoF,iBACAD,gBACAlF,mBACAC,kBACA3jB,aAOI+hB,EAAUhvB,OAAK8E,cAAcmI,GAC7B67B,EAAU77B,EAASpO,OACnByyB,EAAatxB,OAAKwM,kBAAkB7H,EAAEzE,MAAO8uB,GAM1CpzB,EAAI,EAAGA,EAAIspB,IAAatpB,EAC/B,IAAK,IAAImtC,EAAO,EAAGA,EAAOjX,IAAaiX,EAErC,IADA,IAAMC,EAAOD,EAAOtY,EAAeO,EAAQC,IAClCgY,EAAO,EAAGA,EAAO5W,IAAY4W,EAEpC,IADA,IAAMC,EAAOD,EAAOvY,EAAcM,EAAQxK,KACjC7qB,EAAI,EAAGA,EAAIi2B,IAAcj2B,EAAG,CAEnC,IADA,IAAIwtC,EAASz3B,OAAO03B,iBACX9B,EAAI,EAAGA,EAAIxR,IAAgBwR,EAAG,CACrC,IAAM+B,EAAML,EAAO1B,EAAI3W,EACvB,GAAI0Y,GAAO,GAAKA,EAAMnX,EACpB,IAAK,IAAIuV,EAAI,EAAGA,EAAI5R,IAAe4R,EAAG,CACpC,IAAM6B,EAAMJ,EAAOzB,EAAI7W,EACvB,GAAI0Y,GAAO,GAAKA,EAAM7W,EAAS,CAC7B,IAAM8W,EAASvpC,OAAKwG,WAChB,CAAC5K,EAAGytC,EAAKC,EAAK3tC,GAAI+X,EAAO1T,OAAKyF,eAAed,EAAEzD,QAC7CsoC,EAAcxpC,OAAKwG,WACrB,CAAC8gC,EAAGG,EAAG9rC,GAAIktC,EACX7oC,OAAKyF,eAAey2B,EAAOh7B,QACzBuoC,EAAMp+B,EAAMk+B,GAAUX,EAAWY,GACnCC,EAAMN,IACRA,EAASM,KAQnBnY,EAFoBtxB,OAAKwG,WACrB,CAAC5K,EAAGmtC,EAAME,EAAMttC,GAAImtC,EAAS9oC,OAAKyF,eAAewH,KAC3Bk8B,EASlC,MAAO,CAAC3nC,OAHOoD,EAAW3C,MACtBjC,OAAKiI,aAAaqpB,EAAY3sB,EAAEzE,OAAQ+M,EAAUtI,EAAEzE,OAExCgB,MAAO+L,EAAU/M,MAAOyE,EAAEzE,SC/EjCwpC,GAA+C,CAC1DplC,WAAYqlC,2BACZnlC,YAAa,MACbC,WAAY,SAACyD,OAACtB,WAAQ/B,YAASwD,UACtB1D,MAAGu3B,WAAQ1F,OAEXxnB,YAASymB,QAAKwH,cACfr4B,EAAaC,EAEb0pB,EACFvuB,OAAK4pC,cACDjlC,EAAEzD,MAAO0D,EAAWrE,KAAKc,IAAIsD,EAAEnD,QAAQP,QAGzC4oC,EAAU7pC,OAAK4pC,cACD1N,EAAOh7B,MACP0D,EAAWrE,KAAKc,IAAI66B,EAAO16B,QAAQP,QAGjDoB,qEACJ6iB,cACAgN,aACAO,YACAb,eACAE,cACAO,aACArB,YACAP,iBACAC,gBACAoF,iBACAD,gBACAlF,mBACAC,kBACA3jB,aAOFjN,OAAKC,OACDu2B,EAAGra,OAASlP,EAASpO,QACrB,WAAM,MAAA,YAAY8qC,2BAAZ,0CACmC18B,EAASpO,oBAC3C23B,EAAGra,QAiBd,IAfA,IAAM2tB,EACF9pC,OAAK4pC,cACD38B,EAAUrI,EAAWrE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,QAK3C8oC,EAAY/pC,OAAKgqC,0BACD9N,EAAOh7B,MAAOg7B,EAAOh8B,OAOlCtE,EAAI,EAAGA,EAAIspB,IAAatpB,EAC/B,IAAK,IAAImtC,EAAO,EAAGA,EAAOjX,IAAaiX,EAErC,IADA,IAAMC,EAAOD,EAAOtY,EAAeO,EAAQC,IAClCgY,EAAO,EAAGA,EAAO5W,IAAY4W,EAEpC,IADA,IAAMC,EAAOD,EAAOvY,EAAcM,EAAQxK,KACjC7qB,EAAI,EAAGA,EAAIi2B,IAAcj2B,EAAG,CAInC,IAHA,IAAIwtC,EAASz3B,OAAO03B,iBAChBa,EAAO,EACPC,EAAO,EACF5C,EAAI,EAAGA,EAAIxR,IAAgBwR,EAAG,CACrC,IAAM+B,EAAML,EAAO1B,EAAI3W,EACvB,GAAI0Y,GAAO,GAAKA,EAAMnX,EACpB,IAAK,IAAIuV,EAAI,EAAGA,EAAI5R,IAAe4R,EAAG,CACpC,IAAM6B,EAAMJ,EAAOzB,EAAI7W,EACvB,GAAI0Y,GAAO,GAAKA,EAAM7W,EAAS,CAC7B,IAAMgX,EAAMlb,EAAG3yB,GAAGytC,GAAKC,GAAK3tC,GAAKkuC,EAAQvC,GAAGG,GAAG9rC,GAC3C8tC,EAAMN,IACRA,EAASM,EACTQ,EAAO3C,EACP4C,EAAOzC,KAMjBsC,EAAUE,GAAMC,GAAMvuC,IAAMmuC,EAAIluC,GAAGmtC,GAAME,GAAMttC,GASvD,MAAO,CAAC6F,OAHOoD,EAAW3C,MACtBjC,OAAKiI,aAAa8hC,EAAWplC,EAAEzE,OAAQg8B,EAAOh7B,MAAOg7B,EAAOh8B,OAEhDgB,MAAOg7B,EAAOh7B,MAAOhB,MAAOg8B,EAAOh8B,SC/F1CiqC,GAA8C,CACzD7lC,WAAY8lC,0BACZ5lC,YAAa,MACbC,WAAY,SAACyD,OAACtB,WAAQ/B,YAASwD,UACtB1D,MAAGu3B,WAAQ1F,OAEXxnB,YAASymB,QAAKwH,cACfr4B,EAAaC,EAEb0pB,EACFvuB,OAAK4pC,cACDjlC,EAAEzD,MAAO0D,EAAWrE,KAAKc,IAAIsD,EAAEnD,QAAQP,QAGzC4oC,EAAU7pC,OAAK4pC,cACD1N,EAAOh7B,MACP0D,EAAWrE,KAAKc,IAAI66B,EAAO16B,QAAQP,QAGjDoB,qEACJ6iB,cACAgN,aACAO,YACAb,eACAE,cACAO,aACArB,YACAP,iBACAC,gBACAoF,iBACAD,gBACAlF,mBACAC,kBACA3jB,aAOFjN,OAAKC,OACDu2B,EAAGra,OAASlP,EAASpO,QACrB,WAAM,MAAA,YAAYurC,0BAAZ,0CACmCn9B,EAASpO,oBAC3C23B,EAAGra,QAiBd,IAfA,IAAM2tB,EACF9pC,OAAK4pC,cACD38B,EAAUrI,EAAWrE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,QAK3C8oC,EACF/pC,OAAKgqC,0BAA0BrlC,EAAEzD,MAAOyD,EAAEzE,OAOrCtE,EAAI,EAAGA,EAAIspB,IAAatpB,EAC/B,IAAK,IAAImtC,EAAO,EAAGA,EAAOjX,IAAaiX,EAErC,IADA,IAAMC,EAAOD,EAAOtY,EAAeO,EAAQC,IAClCgY,EAAO,EAAGA,EAAO5W,IAAY4W,EAEpC,IADA,IAAMC,EAAOD,EAAOvY,EAAcM,EAAQxK,KACjC7qB,EAAI,EAAGA,EAAIi2B,IAAcj2B,EAAG,CAInC,IAHA,IAAIwtC,EAASz3B,OAAO03B,iBAChBiB,EAAUrB,EAAO,EAAK,EAAIA,EAC1BsB,EAAUpB,EAAO,EAAK,EAAIA,EACrB5B,EAAI,EAAGA,EAAIxR,IAAgBwR,EAAG,CACrC,IAAM+B,EAAML,EAAO1B,EAAI3W,EACvB,GAAI0Y,GAAO,GAAKA,EAAMnX,EACpB,IAAK,IAAIuV,EAAI,EAAGA,EAAI5R,IAAe4R,EAAG,CACpC,IAAM6B,EAAMJ,EAAOzB,EAAI7W,EACvB,GAAI0Y,GAAO,GAAKA,EAAM7W,EAAS,CAC7B,IAAMgX,EAAMlb,EAAG3yB,GAAGytC,GAAKC,GAAK3tC,GAAKkuC,EAAQvC,GAAGG,GAAG9rC,GAC3C8tC,EAAMN,IACRA,EAASM,EACTY,EAAShB,EACTiB,EAAShB,KAMnBS,EAAUnuC,GAAGyuC,GAAQC,GAAQ3uC,IAAMmuC,EAAIluC,GAAGmtC,GAAME,GAAMttC,GAS9D,MAAO,CAAC6F,OAHOoD,EAAW3C,MACtBjC,OAAKiI,aAAa8hC,EAAWplC,EAAEzE,OAAQyE,EAAEzD,MAAOyD,EAAEzE,OAEtCgB,MAAOyD,EAAEzD,MAAOhB,MAAOyE,EAAEzE,kBC1F7B0sB,GACZloB,GAEK,IAMH6pB,EANG3nB,WAAQ/B,YAASwD,UACjB1D,MACA+P,SAAMC,aAEbhV,EAAiBgF,EAAG,OASpB,IAAM+O,GALJ6a,EADc,SAAZ5pB,EAAEzE,MACCkI,EAAK,CAACxB,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACnI,MAAO,WAE3CkH,EAAS,CAACR,OAAQ,CAACjC,KAAIE,aAGb3D,MAAMrC,OACjB+V,EAAO5U,OAAK6U,eAAeH,EAAM6Z,EAAGrtB,OACpC4T,EAAcxT,eAAayT,mBAAmBH,EAAMlB,GAEtDS,EAAgBS,EAChBI,EAAYuZ,EACG,MAAfzZ,IACFE,EACIjB,GAAU,CAACnN,OAAQ,CAACjC,EAAG4pB,GAAK1pB,UAASwD,MAAO,CAACoL,KAAMqB,KACvDX,EAAgB7S,eAAa4T,iBAAiBf,EAActV,OAAQ6U,IAGtEpS,eAAaktB,2BACT,MAAOra,EAAea,EAAU9T,MAAMrC,QAU1C,IARM,IAAAqJ,2DAAC+E,OAAUmH,OAGbjX,EAAS+J,EAAMrC,EAASoI,EADR3L,eAAagT,WAAWU,EAAU9U,MAAO,UAEvDqR,EAAavR,OAAK8E,cAAcsP,GAChCpQ,EAAOa,EAAQtE,KAAKc,IAAIlE,EAAOqE,QAAQP,OAEvCkE,EAAQN,EAAQtE,KAAKc,IAAI2T,EAAUxT,QAAQP,OACxC9B,EAAI,EAAGA,EAAI6E,EAAKnF,SAAUM,EAAG,CAGpC,IAFA,IAAMqS,EAASrS,EAAIoS,EACfg5B,EAAM,EACDp+B,EAAI,EAAGA,EAAIoF,IAAcpF,EAChCo+B,GAAOplC,EAAMqM,EAASrF,GAExBnI,EAAK7E,GAAKorC,EAGZ,GAAI51B,EAAU,CACZ,IACM61B,EAAYrtC,EAClBA,EAAS8c,GAAQ,CAACrT,OAAQ,CAACjC,EAAGxH,GAAS0H,UAASwD,MAAO,CAACnH,MAFvCI,eAAa6T,qBAAqBhY,EAAO+D,MAAO0T,MAGjE/P,EAAQ2D,8BAA8BgiC,GASxC,OANA3lC,EAAQ2D,8BAA8B+lB,GAEnB,MAAfzZ,GACFjQ,EAAQ2D,8BAA8BwM,GAGjC7X,CACT,CAEO,IAAMstC,GAA0B,CACrCnmC,WAAYomC,MACZlmC,YAAa,MACbC,WAAYmoB,ICGP,IAAM+d,GAA6B,CACxCrmC,WAAYsmC,SACZpmC,YAAa,MACbC,oBAzEEC,eAEKkC,WAAQ/B,YACRgmC,mBACD5c,EAAUrnB,EAEV4D,kDAACsgC,YAASC,eAAYC,WAE5B1pC,eAAa2pC,oBAAoBH,EAAQjsC,OAAQmsC,EAAQ/c,GAOzD,IANM,IAAAid,2CAACC,SAAMC,UAEPC,EAASD,EAAMvsC,OACjBkc,EAAuB,KACvBuwB,EAAmBR,EAAQjsC,OACzB0sC,EAAiC,GAC9BpsC,EAAI,EAAGA,EAAIksC,IAAUlsC,EAAG,KAC/B,IAAqB,IAAAqsC,YAAAvwB,EAAAmwB,EAAMjsC,mCAAI,CAA1B,IAAMssC,UACHC,8CAACj4B,uBAA0Bk4B,eAE7BhnC,SACArD,eAAasqC,sBAAsBn4B,GACrC9O,EAAIspB,EAAQwd,IAEZ9mC,EAAIoP,GAAU,CAACnN,OAAQ,CAACjC,EAAGspB,EAAQwd,IAAU5mC,UAASwD,MAAO,CAACoL,UAC9D83B,EAAiBzsC,KAAK6F,IAGxB,IADA,IAAMya,EAAwBza,EAAEzD,MAAMoF,QAC7BgJ,EAAI,EAAGA,EAAIq8B,EAAa9sC,SAAUyQ,EACzC8P,EAAYysB,OAAOF,EAAar8B,GAAI,EAAG,GAGpCtP,OAAK+1B,YAAYpxB,EAAEzD,MAAOke,KAC7Bza,EAAIsV,GAAQ,CAACrT,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACnH,MAAOke,KAClDmsB,EAAiBzsC,KAAK6F,IAEZ,OAARoW,EACFA,EAAMpW,GAGNoW,EAAMtI,GAAS,CAAC7L,OAAQ,CAACuC,EAAGxE,EAAG/I,EAAGmf,GAAMlW,YACxC0mC,EAAiBzsC,KAAKic,sGAGtB5b,EAAIksC,EAAS,IACXF,EAAKhsC,IAAM,IACb4b,EAAM6R,GAAI,CACRhmB,OAAQ,CAACjC,EAAGoW,GACZlW,UACAwD,MAAO,CACLqM,KAAMy2B,EAAKhsC,IAAM2rC,EAAQjsC,OAASysC,GAClC32B,UAAU,KAGd42B,EAAiBzsC,KAAKic,IAExBuwB,SAKJ,IAAyB,IAAAQ,EAAA7wB,EAAAswB,iCAAkB,CAAtC,IAAMloC,UACLA,IAAe0X,GAGnBlW,EAAQ2D,8BAA8BnF,qGAGxC,OAAO0X,CACT,GCnDO,IAAMgxB,GAA8B,CACzCznC,WAAY0nC,UACZxnC,YAAa,MACbC,oBAzBsBC,GAEf,IAAAkC,WAAQ/B,YACR2xB,OAAI94B,MAEXiC,EAAiB,CAAC62B,EAAI94B,GAAI,WAK1B,IAHA,IAAMuG,EAAe,IAAIC,aAAalE,OAAK8E,cAAcpH,EAAEwD,QACrDD,EAAS4D,EAAQtE,KAAKc,IAAI3D,EAAE8D,QAAQP,OACpC4+B,EAAWh7B,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OACpC9B,EAAI,EAAGA,EAAI8B,EAAOpC,SAAUM,EAAG,CACtC,IAAMV,EAAIwC,EAAO9B,GAEf8E,EAAa9E,GADXV,GAAK,EACWohC,EAAS1gC,GAET0gC,EAAS1gC,IAAMV,EAAI,GAIzC,OAAOoG,EAAQ5B,eAAevF,EAAEwD,MAAO,UAAW+C,EACpD,GCrBMhI,GAAIqF,eAAa2qC,MACjBC,GAAK5qC,eAAa6qC,OAClBC,GAAK9qC,eAAa+qC,OAClBC,GAAKhrC,eAAairC,OAClBC,GAAKlrC,eAAamrC,OAClBC,GAAKprC,eAAaqrC,OAEXC,GAAMtgC,EACfugC,OACA,SAACjgC,GACC,IAAMga,EAAOziB,KAAKyiB,KAAKha,GACjBnO,EAAI0F,KAAKC,IAAIwI,GACbjP,EAAI,GAAO,EAAM1B,GAAIwC,GAC3B,OAAOmoB,GACF,MACK8lB,GAAK/uC,EAAI6uC,IAAM7uC,EAAK2uC,IAAM3uC,EAAIyuC,IAAMzuC,EAAIuuC,IAAMvuC,EAC/CwG,KAAK4J,KAAKtP,EAAIA,GACzB,IAGSquC,GAA0B,CACrCxoC,WAAYuoC,MACZroC,YAAa,MACbC,WAAYmoC,aCtBEG,GAAWroC,GAKlB,IAAAkC,WAAQ/B,YAASwD,UACjBb,UACA6H,QAED4Q,EAAYzY,EAAMtG,MAAMrC,OACxBwG,EAAWmC,EAAMtG,MAAMoF,QACzB0mC,EAAO39B,EAWX,OAVIA,EAAM,IAERrP,OAAKC,SACCggB,EAAY,IAAM5Q,GACpB,WAAM,MAAA,mCAAoC4Q,EAAY,QAClDA,SACR+sB,EAAO/sB,EAAY5Q,EAAM,GAE3BhK,EAASwmC,OAAOmB,EAAM,EAAG,GAElB/yB,GAAQ,CAACrT,OAAQ,CAACjC,EAAG6C,GAAQ3C,UAASwD,MAAO,CAACnH,MAAOmE,IAC9D,CAEO,IAAM4nC,GAAiC,CAC5C3oC,WAAY4oC,aACZ1oC,YAAa,MACbC,WAAYsoC,IC5BDI,GACTnoC,GAA6B,SAACmE,EAAWvN,GAAc,OAAAuN,EAAIvN,KAClDwxC,GAAMrkC,EAAiBskC,UAASF,IAEhCG,GAA8B,CACzChpC,WAAY+oC,UACZ7oC,YAAa,MACbC,WAAY2oC,aCKEG,GACZ/lC,EAAmBgmC,EACnB5oC,GAgBF,IAfA,IAAMua,EAAa3X,EAAMtG,MACnB+lB,EAAQ9H,EAAW,GACnBsuB,EAAWtuB,EAAW,GAEtBuuB,EAAY9oC,EAAWrE,KAAKc,IAAImG,EAAMhG,QAEtCmsC,EAASD,EAAUprC,mBAAmBE,KACtCorC,EAASF,EAAUprC,mBAAmBI,KAGtCiG,EAAc,CAACse,EAAOwmB,GACtB/nC,EAAa1F,OAAK8E,cAAc6D,GAChC2B,EAAatK,OAAK2F,uBAAuB,UAAWD,GACpD6E,EAAavK,OAAK2F,uBAAuB,UAAWD,GAEjD9J,EAAI,EAAGA,EAAIqrB,EAAOrrB,IAAK,CAmB9B,IAjBA,IAAMyD,EAAIiH,GAAM,CACdM,OAAQ,CAACjC,EAAGgpC,GACZ9oC,QAASD,EACTyD,MAAO,CAACoU,MAAO,CAAC7gB,EAAG,GAAI6P,KAAM,CAAC,EAAGgiC,MAE7BtuC,EAAImH,GAAM,CACdM,OAAQ,CAACjC,EAAGipC,GACZ/oC,QAASD,EACTyD,MAAO,CAACoU,MAAO,CAAC7gB,EAAG,GAAI6P,KAAM,CAAC,EAAGgiC,MAG7BI,EAAQlnC,EAAQ,CAACC,OAAQ,CAACpE,KAAMnD,EAAGqD,KAAMvD,GAAI0F,QAASD,IAGtDsD,YAACwzB,SAAMC,SACPxoB,EAAM7R,eAAaqB,uBAAuB+4B,EAAMC,GAE7ChgC,EAAI,EAAGA,EAAI8xC,EAAU9xC,IAAK,CACjC,IAAM4pB,EAAIjkB,eAAawsC,oBAAoB36B,EAAKxX,GAChD2O,EAAW1O,EAAI6xC,EAAW9xC,GAAK4pB,EAAE/iB,KACjC+H,EAAW3O,EAAI6xC,EAAW9xC,GAAK4pB,EAAE7iB,KAGnCkC,EAAW4D,8BAA8BnJ,GACzCuF,EAAW4D,8BAA8BrJ,GACzCyF,EAAW4D,8BAA8BqlC,GAG3C,IAAME,EACFnpC,EAAW3B,eAAe0F,EAAa,UAAW2B,GAChD0jC,EACFppC,EAAW3B,eAAe0F,EAAa,UAAW4B,GAEhDpN,EAASwJ,EACX,CAACC,OAAQ,CAACpE,KAAMurC,EAAWrrC,KAAMsrC,GAAYnpC,QAASD,IAK1D,OAHAA,EAAW4D,8BAA8BulC,GACzCnpC,EAAW4D,8BAA8BwlC,GAElC7wC,CACT,UAEgB8wC,GACZzmC,EAAmBgmC,EACnB5oC,GACF,IAAMspC,EAAYluC,OAAK8E,cAAc0C,EAAMtG,OAErCwsC,EAAY9oC,EAAWrE,KAAKc,IAAImG,EAAMhG,QAEtCqF,EACFjC,EAAWrE,KAAKc,IAAIqsC,EAAUprC,mBAAmBE,KAAKhB,QAAQP,OAG5D6F,EACFlC,EAAWrE,KAAKc,IAAIqsC,EAAUprC,mBAAmBI,KAAKlB,QAAQP,OAGlE,GAsD6B,KADRwK,EArDHyiC,GAsDHziC,EAAO,GAtDQ,CAC5B,IAAMtO,EACFgxC,GAAUtnC,EAAUC,EAAUonC,EAAWV,EAAS5oC,GAEhD+D,EAAc,CAACnB,EAAMtG,MAAM,GAAIsG,EAAMtG,MAAM,IAEjD,GAAIssC,EAAS,CACX,IAAMY,EACFxpC,EAAW3B,eAAe0F,EAAa,UAAWxL,EAAOqF,MACvD6rC,EACFzpC,EAAW3B,eAAe0F,EAAa,UAAWxL,EAAOuF,MAEvD4rC,EAAuB1pC,EAAW3B,eACpC,GAAI,UACJjD,OAAKgT,kBAAkBk7B,EAA8B,YACnDK,EACFnnC,EAAS,CAACR,OAAQ,CAACjC,EAAG2pC,GAAWzpC,QAASD,IAExC4pC,EACFlB,GAAc7oC,WACV,CAACmC,OAAQ,CAACuC,EAAGilC,EAAUxyC,EAAG0yC,GAAWzpC,QAASD,IAEhD6pC,EACFnB,GAAc7oC,WACV,CAACmC,OAAQ,CAACuC,EAAGklC,EAAUzyC,EAAG2yC,GAAe1pC,QAASD,IAGpD8pC,EACF9pC,EAAWrE,KAAKc,IAAImtC,EAAYhtC,QAAQP,OACtC0tC,EACF/pC,EAAWrE,KAAKc,IAAIotC,EAAYjtC,QAAQP,OAS5C,OAPA2D,EAAW4D,8BAA8B4lC,GACzCxpC,EAAW4D,8BAA8B6lC,GACzCzpC,EAAW4D,8BAA8B8lC,GACzC1pC,EAAW4D,8BAA8B+lC,GACzC3pC,EAAW4D,8BAA8BgmC,GACzC5pC,EAAW4D,8BAA8BimC,GAElC,CAACjsC,KAAMksC,EAAahsC,KAAMisC,GAGnC,OAAOxxC,EAEP,IASmBsO,EAPbmjC,EAiKV,SACIruC,EAAkBkL,EAAc+hC,GAGlC,IAFA,IAAMqB,EAAM,IAAI3qC,aAAoB,EAAPuH,GAEpBpM,EAAI,EAAGA,EAAIoM,EAAMpM,IAAK,CAG7B,IAFA,IAAIyvC,EAAO,EACPC,EAAO,EACFxpB,EAAI,EAAGA,EAAI9Z,EAAM8Z,IAAK,CAC7B,IAAMtoB,EAAIqE,eAAa0tC,SAAS3vC,EAAIkmB,EAAG9Z,EAAM+hC,GACvCyB,EAAO3tC,eAAawsC,oBAAoBvtC,EAAsBglB,GACpEupB,GAAQG,EAAKzsC,KAAOvF,EAAEuF,KAAOysC,EAAKvsC,KAAOzF,EAAEyF,KAC3CqsC,GAAQE,EAAKzsC,KAAOvF,EAAEyF,KAAOusC,EAAKvsC,KAAOzF,EAAEuF,KAEzCgrC,IACFsB,GAAQrjC,EACRsjC,GAAQtjC,GAEVnK,eAAa4tC,mBAAmBL,EAAKC,EAAMC,EAAM1vC,GAEnD,OAAOwvC,CACT,CApLQM,CAHS7tC,eAAaqB,uBAAuBkE,EAAUC,GAGxBonC,EAAWV,GAE9C,OAAOlsC,eAAa8tC,uBAAuBR,EAE/C,CAOA,SAAST,GACLtnC,EAAwBC,EAAwB2E,EAChD+hC,EACA5oC,GACF,GAAa,IAAT6G,EACF,MAAO,CAACjJ,KAAMqE,EAAUnE,KAAMoE,GAGhC,IAAMvG,EAAOe,eAAaqB,uBAAuBkE,EAAUC,GAErDuoC,EAAO5jC,EAAO,EAEd6jC,EAAchuC,eAAaiuC,qBAAqBhvC,GAEhDivC,EAAeF,EAAY9sC,KAC3BitC,EAAeH,EAAY5sC,KAE3BgtC,EAAY,CAACF,EAAa3wC,QAE1B8wC,EACF/qC,EAAW3B,eAAeysC,EAAW,UAAWF,GAC9CI,EACFhrC,EAAW3B,eAAeysC,EAAW,UAAWD,GAE9CI,EAAiBlpC,EACnB,CAACC,OAAQ,CAACpE,KAAMmtC,EAAcjtC,KAAMktC,GAAe/qC,QAASD,IAE1DkrC,EAAaxuC,eAAayuC,oBAAoBxvC,GAE9CyvC,EAAcF,EAAWttC,KACzBytC,EAAcH,EAAWptC,KAEzBwtC,EAAW,CAACF,EAAYnxC,QAExBsxC,EACFvrC,EAAW3B,eAAeitC,EAAU,UAAWF,GAC7CI,EACFxrC,EAAW3B,eAAeitC,EAAU,UAAWD,GAE7CI,EAAgB1pC,EAClB,CAACC,OAAQ,CAACpE,KAAM2tC,EAAaztC,KAAM0tC,GAAcvrC,QAASD,IAGxD0rC,EACFnC,GAAUqB,EAAcC,EAAcJ,EAAM7B,EAAS5oC,GAEnD2rC,EAAgBD,EAAa9tC,KAC7BguC,EAAgBF,EAAa5tC,KAE7B+tC,EAAa,CAACF,EAAc1xC,QAE5B6xC,EACF9rC,EAAW3B,eAAewtC,EAAY,UAAWF,GAC/CI,EACF/rC,EAAW3B,eAAewtC,EAAY,UAAWD,GAE/CI,EAAkBjqC,EAAQ,CAC9BC,OAAQ,CAACpE,KAAMkuC,EAAehuC,KAAMiuC,GACpC9rC,QAASD,IAGLisC,EACF1C,GAAU6B,EAAaC,EAAaZ,EAAM7B,EAAS5oC,GAEjDksC,EAAeD,EAAYruC,KAC3BuuC,EAAeF,EAAYnuC,KAE3BsuC,EAAY,CAACF,EAAajyC,QAE1BoyC,EACFrsC,EAAW3B,eAAe+tC,EAAW,UAAWF,GAC9CI,EACFtsC,EAAW3B,eAAe+tC,EAAW,UAAWD,GAE9CI,EAAiBxqC,EACnB,CAACC,OAAQ,CAACpE,KAAMyuC,EAAcvuC,KAAMwuC,GAAersC,QAASD,IAE1D3H,EAAIqE,eAAa8vC,UAAU3lC,EAAM+hC,GACjC6D,EAAS,CAACp0C,EAAEuF,KAAK3D,QAEjByyC,EAAY1sC,EAAW3B,eAAeouC,EAAQ,UAAWp0C,EAAEuF,MAC3D+uC,EAAY3sC,EAAW3B,eAAeouC,EAAQ,UAAWp0C,EAAEyF,MAE3DqE,EAAcJ,EAChB,CAACC,OAAQ,CAACpE,KAAM8uC,EAAW5uC,KAAM6uC,GAAY1sC,QAASD,IAEpD4sC,EACF/+B,GACI,CAAC7L,OAAQ,CAACuC,EAAGpC,EAAanL,EAAGu1C,GAAiBtsC,QAASD,IAGzD6sC,EAAUxmC,EAAI,CACFrE,OAAQ,CAACuC,EAAGynC,EAAiBh1C,EAAG41C,GAChC3sC,QAASD,IAErB8sC,EAAU3rB,GAAI,CACFnf,OAAQ,CAACuC,EAAGynC,EAAiBh1C,EAAG41C,GAChC3sC,QAASD,IAGrB+sC,EAAcnvC,EAAK,CAACoE,OAAQ,CAACY,MAAOiqC,GAAU5sC,QAASD,IACvDgtC,EAAcpvC,EAAK,CAACoE,OAAQ,CAACY,MAAOkqC,GAAU7sC,QAASD,IAEvDitC,EAAcnvC,GAAK,CAACkE,OAAQ,CAACY,MAAOiqC,GAAU5sC,QAASD,IACvDktC,EAAcpvC,GAAK,CAACkE,OAAQ,CAACY,MAAOkqC,GAAU7sC,QAASD,IAEvDmtC,EAAQryC,GAAO,CACnBkH,OAAQ,CAAC+qC,EAAuBC,GAChC/sC,QAASD,EACTyD,MAAO,CAACqM,KAAM,KAEVs9B,EAAQtyC,GAAO,CACnBkH,OAAQ,CAACirC,EAAuBC,GAChCjtC,QAASD,EACTyD,MAAO,CAACqM,KAAM,KAGVu9B,EAAYrtC,EAAWrE,KAAKc,IAAI0wC,EAAMvwC,QAAQP,OAC9CixC,GAAYttC,EAAWrE,KAAKc,IAAI2wC,EAAMxwC,QAAQP,OA2BpD,OAzBA2D,EAAW4D,8BAA8BmnC,GACzC/qC,EAAW4D,8BAA8BonC,GACzChrC,EAAW4D,8BAA8BqnC,GACzCjrC,EAAW4D,8BAA8B2nC,GACzCvrC,EAAW4D,8BAA8B4nC,GACzCxrC,EAAW4D,8BAA8B6nC,GACzCzrC,EAAW4D,8BAA8BkoC,GACzC9rC,EAAW4D,8BAA8BmoC,GACzC/rC,EAAW4D,8BAA8BooC,GACzChsC,EAAW4D,8BAA8ByoC,GACzCrsC,EAAW4D,8BAA8B0oC,GACzCtsC,EAAW4D,8BAA8B2oC,GACzCvsC,EAAW4D,8BAA8B8oC,GACzC1sC,EAAW4D,8BAA8B+oC,GACzC3sC,EAAW4D,8BAA8BzB,GACzCnC,EAAW4D,8BAA8BgpC,GACzC5sC,EAAW4D,8BAA8BipC,GACzC7sC,EAAW4D,8BAA8BkpC,GACzC9sC,EAAW4D,8BAA8BmpC,GACzC/sC,EAAW4D,8BAA8BqpC,GACzCjtC,EAAW4D,8BAA8BopC,GACzChtC,EAAW4D,8BAA8BspC,GACzCltC,EAAW4D,8BAA8BupC,GACzCntC,EAAW4D,8BAA8BwpC,GAElC,CAACxvC,KAAMyvC,EAAWvvC,KAAMwvC,GACjC,CCxQO,IAAMC,GAA0B,CACrC7tC,WAAY8tC,MACZ5tC,YAAa,MACbC,oBA/BkBC,GAEX,IAAAkC,WAAQ/B,YACR2C,UAED0mC,EAAYluC,OAAK8E,cAAc0C,EAAMtG,OAGrCmxC,EAAqB7qC,EAAMtG,MAAMsG,EAAMtG,MAAMrC,OAAS,GAGtDyzC,EAAUr4B,GAAQ,CACtBrT,OAAQ,CAACjC,EAAG6C,GACZ3C,UACAwD,MAAO,CAACnH,MAAO,CALHgtC,EAAYmE,EAKDA,MAGnBl1C,EAASowC,GAAS+E,GAAS,EAAOztC,GAElC0tC,EACFt4B,GAAQ,CAACrT,OAAQ,CAACjC,EAAGxH,GAAS0H,UAASwD,MAAO,CAACnH,MAAOsG,EAAMtG,SAKhE,OAHA2D,EAAQ2D,8BAA8B8pC,GACtCztC,EAAQ2D,8BAA8BrL,GAE/Bo1C,CACT,YC5BgB13B,GAAKnW,GAEZ,IAAAG,YAASwD,UACTnH,UAAOpE,UAERyM,WAAkBvJ,OAAKwyC,WAAW11C,GAClCmE,EAASjB,OAAKwM,kBAAkBjD,EAAQvJ,OAAK8E,cAAc5D,IAGjE,OASF,SACID,EAAoBnE,EAAsBoD,GAEzCe,EAAoB4Z,KAAK/d,EAI9B,CAlBE21C,CAAWxxC,EAAQnE,GAEZ+H,EAAQ5B,eAAe/B,EAAOqI,EAAQtI,EAC/C,CAEO,IAAMyxC,GAA2B,CACtCpuC,WAAYquC,OACZnuC,YAAa,MACbC,WAAYoW,ICdP,IAAM+3B,GAAoC,CAC/CtuC,WAAYuuC,gBACZruC,YAAa,MACbC,WAAY,SAACyD,OAACtB,mBAUZ,QAV2B/B,YACpBq+B,UACDt+B,EAAaC,EAEbkc,EAAS/gB,OAAK2F,uBAChBu9B,EAAMhjC,MAA0BF,OAAK8E,cAAco+B,EAAMhiC,QACvDmB,eAAC4kB,OAAOuc,OAAaC,OAAYC,OAEjCM,EAAYp/B,EAAWrE,KAAKc,IAAI6hC,EAAM1hC,QAAQP,OAE3C0O,EAAW,EAAGA,EAAWsX,EAAOtX,IAGvC,IAFA,IAAMmjC,EAAcnjC,EAAW8zB,EAAaD,EAAcE,EAEjDn2B,EAAM,EAAGA,EAAMi2B,EAAaj2B,IAGnC,IAFA,IAAMwlC,EAAYxlC,GAAOk2B,EAAaC,GAE7Bj2B,EAAM,EAAGA,EAAMg2B,EAAYh2B,IAGlC,IAFA,IAAMulC,EAAYvlC,EAAMi2B,EAEf1P,EAAU,EAAGA,EAAU0P,EAAa1P,IAAW,CACtD,IAAMif,EAAS9uC,KAAKshC,MAAMhC,EAAah2B,EAAM,GACvCylC,EAASJ,EAAcC,EAAYC,EAAYhf,EAEjDmf,EAAcnP,EAAUkP,GAE5B,GAAID,GAAU,GAAKA,EAASxP,EAK1B0P,EAAcnP,EADV8O,EAAcC,EAFOE,EAASvP,EAEe1P,GAGnDjT,EAAOmyB,GAAUC,EAOzB,MAAO,CAAC3xC,OADOoD,EAAW3C,MAAM8e,EAAQmiB,EAAMhiC,MAAOgiC,EAAMhjC,OAC3CgB,MAAOgiC,EAAMhiC,MAAOhB,MAAOgjC,EAAMhjC,SC1CxCkzC,GACTpuC,GAA6B,SAACmE,EAAWvN,GAAc,OAAAuI,KAAKoK,MAAMpF,EAAIvN,MAC7Dy3C,GACTtqC,EAAiBuqC,WAAUF,GAAc,KAAwB,SAExDG,GAA+B,CAC1CjvC,WAAYgvC,WACZ9uC,YAAa,MACbC,WAAY4uC,ICkEP,IAAMG,GAAkC,CAC7ClvC,WAAYmvC,cACZjvC,YAAa,MACbC,oBA1E0BC,GAKnB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAGu3B,WAAQ5O,SAAMxD,2BAEtB9a,YACAymB,QACAW,eACA6G,cACAvH,oBACA7L,eACAE,mBAGE5sB,EAAS6/B,GAAO,CAClBp2B,OAAQ,CAACjC,IAAGu3B,UACZr3B,UACAwD,MAAO,CAAC2G,UAASymB,MAAKW,aAAY6G,YAAWvH,qBAG/C,GAAIpI,EAAM,CACR,IAAMomB,EAAYv2C,EAKlB,GAAmB,SAAfi5B,GAA+C,IAAtB9I,EAAKpsB,MAAMrC,QAClB,IAAlByuB,EAAKpsB,MAAM,GAAU,CACvB,IAAMyyC,EAAe15B,GACjB,CAACrT,OAAQ,CAACjC,EAAG2oB,GAAOzoB,UAASwD,MAAO,CAACnH,MAAO,CAACosB,EAAKpsB,MAAM,GAAI,EAAG,MACnE/D,EACI8N,EAAI,CAACrE,OAAQ,CAACuC,EAAGhM,EAAQvB,EAAG+3C,GAAe9uC,YAC/CA,EAAQ2D,8BAA8BmrC,QAItCx2C,EAAS8N,EAAI,CAACrE,OAAQ,CAACuC,EAAGhM,EAAQvB,EAAG0xB,GAAOzoB,YAE9CA,EAAQ2D,8BAA8BkrC,GAGxC,GAAI7pB,EAAY,CACR6pB,EAAYv2C,EAKlB,GAAmB,SAAfi5B,GAAwC,UAAfvM,GACe,IAAxCC,EAAuB5oB,MAAMrC,QACO,IAApCirB,EAAuB5oB,MAAM,GAAU,CACzC,IAAM0yC,EAAgB35B,GAAQ,CAC5BrT,OAAQ,CAACjC,EAAGmlB,GACZjlB,UACAwD,MAAO,CAACnH,MAAO,CAAC4oB,EAAuB5oB,MAAM,GAAI,EAAG,MAEtD/D,EAASysB,GACL/kB,EAAS1H,EAAQ0sB,EAAY+pB,EAAe7pB,GAChDllB,EAAQ2D,8BAA8BorC,QAEtCz2C,EAASysB,GACL/kB,EAAS1H,EAAQ0sB,EAAYC,EAAwBC,GAE3DllB,EAAQ2D,8BAA8BkrC,GAGxC,OAAOv2C,CACT,GChCO,IAAM02C,GAA2C,CACtDvvC,WAAYwvC,uBACZtvC,YAAa,MACbC,oBAzCmCC,GAK5B,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAGu3B,WAAQ5O,SAAMxD,2BAEtB9a,YACAymB,QACAW,eACA6G,cACAvH,oBACA7L,eACAE,mBAGE5sB,EAAS0qC,GAAsB,CACjCjhC,OAAQ,CAACjC,IAAGu3B,UACZr3B,UACAwD,MAAO,CAAC2G,UAASymB,MAAKW,aAAY6G,YAAWvH,qBAG/C,GAAIpI,EAAM,CACR,IAAMkd,EAAYrtC,EAClBA,EAAS8N,EAAI,CAACrE,OAAQ,CAACuC,EAAGhM,EAAQvB,EAAG0xB,GAAOzoB,YAC5CA,EAAQ2D,8BAA8BgiC,GAExC,GAAI3gB,EAAY,CACR2gB,EAAYrtC,EAClBA,EAASysB,GACL/kB,EAAS1H,EAAQ0sB,EAAYC,EAAwBC,GACzDllB,EAAQ2D,8BAA8BgiC,GAGxC,OAAOrtC,CACT,GCZO,IAAM42C,GAA+B,CAC1CzvC,WAAY0vC,WACZxvC,YAAa,MACbC,oBA3BEC,GACK,IAAAkC,WAAQ/B,YACRovC,WAAQp4B,YAET3M,EAAalP,OAAK8E,cAAcmvC,EAAO/yC,OAEvCwc,EAAe7B,EAAQ3a,MACvB4N,EAAY4O,EAAaA,EAAa7e,OAAS,GAE/CqJ,8CAACS,OAAakG,OAAWE,OAAWC,OAE1C,GAAkB,IAAdH,EACF,OAAOhK,EAAQ5B,eAAe0F,EAAasrC,EAAO/zC,MAAO,IAG3D,IAEMgM,EAASwC,GAFK7J,EAAQtE,KAAKc,IAAIwa,EAAQra,QAAQP,OACnC4D,EAAQgyB,WAA4Bod,GAE1BA,EAAO/zC,MAAO2O,EAAWC,EAAWC,EAC5DC,EAASilC,EAAO/yC,MAAOgO,GAE3B,OAAOrK,EAAQ5B,eAAe0F,EAAasrC,EAAO/zC,MAAOgM,EAAOjL,OAClE,GC6CO,IAAMizC,GAA+B,CAC1C5vC,WAAY6vC,WACZ3vC,YAAa,MACbC,oBAtEuBC,GAKhB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAGkX,YACHnH,SAAM0/B,cAEbz0C,EAAiB,CAACgF,EAAGkX,GAAU,YAM/B,IAHA,IAAMw4B,EAAar0C,OAAK6U,eAAeH,EAAM/P,EAAEzD,OAAO,GAChDozC,EAAczvC,EAAQtE,KAAKc,IAAIwa,EAAQra,QAAQP,OAC/CszC,EAAU5vC,EAAEzD,MAAMmzC,cACfl1C,GACP,IAAMgQ,EAAQmlC,EAAYn1C,GAC1Ba,OAAKC,OACDkP,GAASolC,EAAU,GAAKplC,GAAS,GACjC,WACI,MAAA,6BAA6BA,qBAAuBolC,EAAU,WAL/Dp1C,EAAI,EAAGA,EAAIm1C,EAAYz1C,SAAUM,IAAjCA,GAQT,IAAIq1C,EAAaJ,EAEA,MAAbA,IACFI,EAAa,GAGf,IAAMC,EAAcz0C,OAAK8E,cAAc+W,EAAQ3a,OAEzCwzC,EAAYpzC,eAAaqzC,aAAaC,yBACxCjwC,EAAGkX,EAASw4B,EAAYG,GAEtBK,EAAW56B,GAAQ,CACvBrT,OAAQ,CAACjC,KACTE,UACAwD,MAAO,CACLnH,MAAO,CACLwzC,EAAUxvB,UAAWwvB,EAAUI,UAAWJ,EAAUK,QACpDL,EAAU3lC,cAKVK,EAAe6K,GAAQ,CAC3BrT,OAAQ,CAACjC,EAAGkX,GACZhX,UACAwD,MAAO,CAACnH,MAAO,CAACwzC,EAAUxvB,UAAWuvB,EAAcC,EAAUxvB,cAGzDzV,EAAqB,CACzBilC,EAAUxvB,UAAWwvB,EAAUI,UAAWL,EAAcC,EAAUxvB,UAClEwvB,EAAU3lC,WAGNS,EAAa3K,EAAQgyB,WAAWznB,GAEhClD,EAASqD,GADF1K,EAAQgyB,WAAWge,GACErlC,EAAYC,GAK9C,OAHA5K,EAAQ2D,8BAA8BqsC,GACtChwC,EAAQ2D,8BAA8B4G,GAE/BvK,EAAQ5B,eACXyxC,EAAUv7B,YAAajN,EAAOhM,MAAOgM,EAAOjL,OAClD,GCtCO,IAAM+zC,GAA2B,CACtC1wC,WAAY2wC,OACZzwC,YAAa,MACbC,oBA/BmBC,GAEZ,IAAAkC,WAAQ/B,YACR2C,UAED0mC,EAAYluC,OAAK8E,cAAc0C,EAAMtG,OAGrCmxC,EAAqB7qC,EAAMtG,MAAMsG,EAAMtG,MAAMrC,OAAS,GAGtDyzC,EAAUr4B,GAAQ,CACtBrT,OAAQ,CAACjC,EAAG6C,GACZ3C,UACAwD,MAAO,CAACnH,MAAO,CALHgtC,EAAYmE,EAKDA,MAGnBl1C,EAASowC,GAAS+E,GAAS,EAAMztC,GAEjC0tC,EACFt4B,GAAQ,CAACrT,OAAQ,CAACjC,EAAGxH,GAAS0H,UAASwD,MAAO,CAACnH,MAAOsG,EAAMtG,SAKhE,OAHA2D,EAAQ2D,8BAA8B8pC,GACtCztC,EAAQ2D,8BAA8BrL,GAE/Bo1C,CACT,GC5Ba2C,GACT5oC,EAAgB6oC,YAAU,SAACvoC,GAAO,OAAA8E,OAAOwjC,SAAStoC,GAAM,EAAI,IAAG,QAEtDwoC,GAA+B,CAC1C9wC,WAAY6wC,WACZ3wC,YAAa,MACbC,WAAYywC,ICNDG,GACT/oC,EAAgBgpC,SAAO,SAAC1oC,GAAO,OAAAzI,KAAKC,IAAIwI,KAAQ2oC,IAAW,EAAI,IAAG,QAEzDC,GAA4B,CACvClxC,WAAYgxC,QACZ9wC,YAAa,MACbC,WAAY4wC,ICND1jC,GACTrF,EAAgBmpC,SAAO,SAAC7oC,GAAO,OAAA8E,OAAOC,MAAM/E,GAAM,EAAI,IAAG,QAEhD8oC,GAA4B,CACvCpxC,WAAYmxC,QACZjxC,YAAa,MACbC,WAAYkN,ICKP,IAAMgkC,GAA+B,CAC1CrxC,WAAYsxC,WACZpxC,YAAa,MACbC,oBAbuBC,GAEhB,IAAAG,YAASwD,UAGVsD,EAAUoF,yBAEhB,OAAOlM,EAAQ5B,eAAe,CAAC0I,EAAQ9M,QAAS,UAAW8M,EAC7D,GCTakqC,GAAQvpC,EAAgBwpC,SAAO,SAAClpC,GAAO,OAAAzI,KAAK0xC,MAAMjpC,MAElDmpC,GAA4B,CACvCzxC,WAAYwxC,QACZtxC,YAAa,MACbC,WAAYoxC,ICJDG,GACThxC,GAA6B,SAACmE,EAAWvN,GAAc,OAAAuN,GAAKvN,KACnDq6C,GAAaltC,EACtBmtC,aAAYF,GAAgB,KAAwB,QAE3CG,GAAiC,CAC5C7xC,WAAY4xC,aACZ1xC,YAAa,MACbC,WAAYwxC,ICTDG,GACT9pC,EAAgB+pC,cAAY,SAACzpC,GAAO,OAAAA,EAAK,EAAI,IAAG,QAEvC0pC,GAAiC,CAC5ChyC,WAAY+xC,aACZ7xC,YAAa,MACbC,WAAY2xC,ICLDG,GACTvxC,GAA6B,SAACmE,EAAWvN,GAAc,OAAAuN,GAAKvN,KACnD46C,GACTztC,EAAiB0tC,YAAWF,GAAe,KAAwB,QAE1DG,GAAgC,CAC3CpyC,WAAYmyC,YACZjyC,YAAa,MACbC,WAAY+xC,ICgCP,IAAMG,GAA0B,CACrCryC,WAAYsyC,MACZpyC,YAAa,MACbC,oBA1CEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACAkyC,gBAAavpB,SAAMxE,UAAOguB,SAEjCn3C,EAAiBgF,EAAG,OAEpB,IAAMoyC,EAAWpyC,EAAEzD,MAAM,GACnB81C,EAAOD,EAAW,EAClBzmB,EAAUzrB,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACrCwK,EAAOzL,OAAK8E,cAAcH,EAAEzD,OAC5B/D,EAAS,IAAI+G,aAAauH,GAEhC,SAASwrC,EAAkBzlC,GAQzB,IAPA,IAAM0lC,EAAiB1lC,EAASulC,EAC5BI,EACA3lC,EAAS0lC,EAAiB/yC,KAAKsN,IAAI,EAAGylC,EAAiBL,GACrDO,EACF5lC,EAAS0lC,EAAiB/yC,KAAKgO,IAAI+kC,EAAiBL,EAAaG,GAEjEpqB,EAAM,EACHuqB,GAAkBC,EAAcD,IAAkB,CACvD,IAAMzwB,EAAI4J,EAAQ6mB,GAClBvqB,GAAOlG,EAAIA,EAEb,OAAOkG,EAGT,IAAK,IAAIpb,EAAS,EAAGA,EAAS/F,EAAM+F,IAAU,CAC5C,IAAMob,EAAMqqB,EAAkBzlC,GACxBi4B,EAAMnZ,EAAQ9e,GAAUrN,KAAKkzC,IAAI/pB,EAAOxE,EAAQ8D,GAAMkqB,GAC5D35C,EAAOqU,GAAUi4B,EAGnB,OAAO5kC,EAAQ5B,eAAe0B,EAAEzD,MAAOyD,EAAEzE,MAAO/C,EAClD,GCSO,IAAMm6C,GAA8B,CACzChzC,WAAYizC,UACZ/yC,YAAa,MACbC,oBAhDEC,GAGK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAGjH,MAAG84B,OACNqgB,gBAAavpB,SAAMxE,UAAOguB,SAEjCn3C,EAAiB62B,EAAI,WAWrB,IATA,IAAMghB,EAASx3C,OAAK8E,cAAc0xB,EAAGt1B,OAE/B61C,EAAWvgB,EAAGt1B,MAAM,GACpB2+B,EAAWh7B,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OACvCqvB,EAAUzrB,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACrCw2C,EAAU5yC,EAAQtE,KAAKc,IAAI3D,EAAE8D,QAAQP,OACrC9D,EAAS,IAAI+G,aAAaszC,GAC1B/rC,EAAO+rC,EAEJhmC,EAAS,EAAGA,EAAS/F,EAAM+F,IAAU,CAQ5C,IAPA,IAAM0lC,EAAiB1lC,EAASulC,EAC1BW,EACDlmC,EAAS0lC,EAAkB/yC,KAAKsN,IAAI,EAAGylC,EAAiBL,GACvDc,EAAYnmC,EAAS0lC,EACvB/yC,KAAKgO,IAAI4kC,EAAUG,EAAiBL,EAAc,GAElDe,EAAO,EACFtoC,EAAIooC,EAAYpoC,EAAIqoC,EAAUroC,IACrCsoC,GAAQzzC,KAAKkzC,IAAI/mB,EAAQhhB,GAAI,GAE/BsoC,EAAO9uB,EAAQ8uB,EAAOtqB,EAEtB,IAAShe,EAAIooC,EAAYpoC,EAAIqoC,EAAUroC,IAAK,CAC1C,IAAIuoC,GAAO,EAAI/uB,EAAQguB,EAAOxmB,EAAQhhB,GAAKmoC,EAAQjmC,GAAUomC,EACzDpmC,IAAWlC,IACbuoC,GAAO1zC,KAAKkzC,IAAIO,GAAOd,IAEzBe,GAAOhY,EAASruB,GAChBrU,EAAOmS,IAAMuoC,GAIjB,OAAOhzC,EAAQ5B,eAAeuzB,EAAGt1B,MAAOyD,EAAEzE,MAAO/C,EACnD,YCtCgBsU,GACZ/M,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACAmzC,qBAAkBnjC,aACnB/P,EAAaC,EACfgO,EAASlO,EAAEzD,MACTwS,EAAQb,EAAOhU,OAEfwvB,EAAWruB,OAAK6U,eAAeijC,EAAkBjlC,GACnD+B,EAAOyZ,EACLC,EAAehtB,eAAayT,mBAAmBH,EAAMlB,GACvDrI,EAAQzG,EAAWrE,KAAKc,IAAIsD,EAAEnD,QAAQP,OAC1C,GAAoB,MAAhBqtB,EAAsB,CAExB,IADA,IAAMjpB,EAAqB,IAAIrJ,MAAM0X,GAC5BvU,EAAI,EAAGA,EAAIkG,EAASxG,OAAQM,IACnCkG,EAASlG,GAAK0T,EAAOyb,EAAanvB,IAGpCkM,EAAQmI,GAAcnI,EAAOwH,EAAQlO,EAAEzE,MAAOouB,EAAcjpB,GAC5DuP,EAAOtT,eAAa4T,iBAAiBN,EAAK/V,OAAQ6U,GAElDb,EAASxN,EAGX1F,EAAiBgF,EAAG,OACpBrD,eAAaktB,2BAA2B,MAAO5Z,EAAMlB,GAC/C,IAAAxL,qDAAC6vC,OAAa3jC,OAKdjX,EAASmU,GAAQjG,EAFJrL,OAAK8E,cAAcsP,GAEI2jC,EAAapzC,EAAEzE,OACnDsB,EAASoD,EAAW3C,MAAM9E,EAAQ46C,EAAapzC,EAAEzE,OAEnD+M,EAAW8qC,EACXpjC,IAGF1H,EADM5H,EAAW/D,eAAa6T,qBAAqB4iC,EAAa1pB,IAIlE,MAAO,CAAC7sB,SAAQN,MAAO+L,EAAU/M,MAAOyE,EAAEzE,MAC5C,CAEO,IAAM83C,GAA0B,CACrC1zC,WAAY2zC,MACZzzC,YAAa,MACbC,WAAYgN,ICpBP,IAAMymC,GAA8B,CACzC5zC,WAAY6zC,UACZ3zC,YAAa,MACbC,oBAnCEC,GAGK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACPhF,EAAiBgF,EAAG,WACb,IAAA6wB,eAAYxmB,YAASymB,QAAKC,oBAGjC11B,OAAKC,OACDqB,eAAaq0B,+BAA+B3mB,EAH9B,IAId,WAAM,MAAA,wEACaA,0BAEvB,IAGImE,EAHEod,EAAWjvB,eAAas0B,kBAC1BjxB,EAAEzD,MAA2Cs0B,EAAYxmB,EAR3C,EASHymB,EAAKC,GAGpB,GAA6B,IAAzBnF,EAASsF,aAA+C,IAA1BtF,EAASuF,cACvC91B,OAAK+1B,YAAYxF,EAASyF,QAASzF,EAAStjB,UAC9CkG,EAAM/L,EAAS,CAACR,OAAQ,CAACjC,KAAIE,gBACxB,CACL,IAAMyrB,EAAUzrB,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACrCg1B,EAAUj2B,OAAKyF,eAAed,EAAEzD,OAChC4B,EAASutB,GAAKC,EAAS3rB,EAAEzD,MAAOyD,EAAEzE,MAAO+1B,EAAS1F,EAAU,OAClEpd,EAAMtO,EAAQ5B,eACVstB,EAAStjB,SAAUtI,EAAEzE,MAAO4C,EAAO7B,QAEzC,OAAOkS,CACT,GCTO,IAAMilC,GAAgC,CAC3C9zC,WAAY+zC,YACZ7zC,YAAa,MACbC,oBAzBwBC,GAKjB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA6wB,eAAYxmB,YAASymB,QAAKC,oBAAiBU,eAElDz2B,EAAiBgF,EAAG,aAEpB,IAAM4rB,EAAWjvB,eAAa+0B,kBAC1B1xB,EAAEzD,MAAmDs0B,EAAYxmB,EACjE,EAAmBymB,EAAKC,EAAiBU,GAGvClqB,EAASunB,GADC5uB,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OAE9B0D,EAAEzD,MAAOyD,EAAEzE,MAAOF,OAAKyF,eAAed,EAAEzD,OAAQqvB,EAAU,OAEvE,OAAO1rB,EAAQ5B,eAAeiJ,EAAOhL,MAAO,UAAWgL,EAAOjL,OAChE,GC2EO,IAAMq3C,GAAoC,CAC/Ch0C,WAAYi0C,gBACZ/zC,YAAa,MACbC,oBAlG4BC,GAKrB,IAAAkC,WAAQ/B,YAASwD,UACjBmuB,OAAIhvB,UACJguB,eAAYxmB,YAASymB,QAAKC,oBAEjC/1B,EAAiB,CAAC62B,EAAIhvB,GAAQ,iBAwB9B,IAtBA,IAAM+oB,EAAWjvB,eAAa+0B,kBAC1B7uB,EAAMtG,MAAmDs0B,EACzDxmB,EAAS,EAAmBymB,EAAKC,GAG/B8iB,W9D4NJ3sC,EACA0kB,GAeF,IAdA,IAAM6C,EAAetwB,SAAOytB,EAAStjB,SAAU,SACzCymB,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBiD,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBgD,EAAuBrD,EAASqD,qBAChC/C,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChC+C,EAAWtD,EAASS,QAAQ8C,MAC5B/C,EAASR,EAASS,QAAQC,IAC1BC,EAAUX,EAASS,QAAQxK,KAExBS,EAAQ,EAAGA,EAAQsJ,EAASrL,YAAa+B,EAChD,IAAK,IAAI+M,EAAU,EAAGA,EAAUzD,EAASqB,aAAcoC,EACrD,IAAK,IAAIC,EAAS,EAAGA,EAAS1D,EAAS2D,WAAYD,EAAQ,CAGzD,IAFA,IAAME,EAAeF,EAASP,EAAcG,EACxCO,EAAYD,EACTC,EAAY,GACjBA,GAAaT,EAIf,IAFA,IAAMU,EACFlwB,KAAKgO,IAAIoe,EAAS+D,QAASV,EAAuBO,GAC7CK,EAAO,EAAGA,EAAOjE,EAASuB,YAAa0C,EAAM,CAGpD,IAFA,IAAMC,EAAaD,EAAO/D,EAAeM,EACrC2D,EAAUD,EACPC,EAAU,GACfA,GAAW/D,EAIb,IAFA,IAAMgE,EACFxwB,KAAKgO,IAAIoe,EAAS2B,SAAUrB,EAAwB4D,GAC/CG,EAAO,EAAGA,EAAOrE,EAAS8B,WAAYuC,EAAM,CAGnD,IAFA,IAAMC,EAAaD,EAAOlE,EAAcQ,EACpC4D,EAAUD,EACPC,EAAU,GACfA,GAAWlE,EASb,IAPA,IAAMmE,EACF5wB,KAAKgO,IAAIoe,EAASkC,QAAS3B,EAAuB+D,GAGlDxB,EAAW3hB,OAAO0f,kBAClBkC,GAAe,EAEV2B,EAASb,EAAWa,EAASZ,EACjCY,GAAUtB,EAEb,IADA,IAAM0D,EAASpC,EAASd,EACfgB,EAAOT,EAASS,EAAOR,EAASQ,GAAQxE,EAE/C,IADA,IAAM4G,EAAOpC,EAAOV,EACXY,EAAOP,EAASO,EAAON,EAC3BM,GAAQzE,EAAe,CAC1B,IAAM6G,EAAOpC,EAAOR,EACd7B,EAAQnnB,EAAKxK,IAAI4lB,EAAOgO,EAAQE,EAAME,EAAMrB,GAC9ChB,GAASK,IACXA,EAAWL,EACXM,EACI+D,EAASxG,EAAwBC,EACjCyG,EAAO1G,EAAwB4G,GAM3CrE,EAAa1xB,IAAI4xB,EAAarM,EAAOgN,EAAQO,EAAMI,EAAMZ,KAOnE,OAAOZ,CACT,C8DtSoBqlB,CADD5zC,EAAQgyB,WAAWrvB,GACW+oB,GACzCmD,EAAcnD,EAASmD,YACvBjD,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBiD,EAAgBpD,EAASoD,cACzBhD,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBgD,EAAuBrD,EAASqD,qBAChC/C,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChC+C,EAAWD,EAAuB,EAAIrD,EAASS,QAAQ8C,MACvD5C,EAAUJ,EAAuB,EAAIP,EAASS,QAAQxK,KACtDuK,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtDyF,EAAK5zB,SAAO0E,EAAMtG,MAAO,WAEzB01B,EAAQ/xB,EAAQgyB,WAA4BL,GAEzCvP,EAAQ,EAAGA,EAAQsJ,EAASrL,YAAa+B,EAChD,IAAK,IAAI+M,EAAU,EAAGA,EAAUzD,EAASqB,aAAcoC,EACrD,IAAK,IAAI8C,EAAU,EAAGA,EAAUvG,EAAS+D,UAAWwC,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQxG,EAAS2B,WAAY6E,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQzG,EAASkC,UAAWuE,EAAO,CAMrD,IAJA,IAAMC,EAAgBH,EAAUjD,EAC1BqD,EAAcH,EAAQhG,EACtBoG,EAAcH,EAAQ9F,EACxBkG,EAAU,EACLC,EAAS,EAAGA,EAASzD,EACzByD,GAAU1D,EAAe,CAC5B,IAAM2D,GAAWL,EAAgBI,GAAU3D,EAC3C,KAAI4D,EAAU,GAAKA,GAAW/G,EAAS2D,UACnC/vB,KAAKoK,MAAM+oB,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAO1G,EACrB0G,GAAQ5G,EAAgB,CAC3B,IAAM6G,GAASN,EAAcK,GAAQ9G,EACrC,KAAI+G,EAAQ,GAAKA,GAASjH,EAASuB,WAC/B3tB,KAAKoK,MAAMipB,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAO3G,EACrB2G,GAAQ7G,EAAe,CAC1B,IAAM8G,GAASP,EAAcM,GAAQ/G,EACrC,KAAIgH,EAAQ,GAAKA,GAASnH,EAAS8B,UAC/BluB,KAAKoK,MAAMmpB,KAAWA,GAD1B,CAKA,IASMghB,EATS9kB,EAAuB/C,EAC9BC,EACJ,EACC0nB,EAAUn3C,IAAI4lB,EAAOqQ,EAASE,EAAOE,EAAO1D,KAG7CqD,EAASxG,EAAwBC,EACjCyG,EAAOzG,EAAuB2G,EAED,EAAI,EACrC,GAAa,IAATihB,EAMJthB,GADIR,EAAMv1B,IAAI4lB,EAAOqQ,EAASE,EAAOE,EAAO1D,GACzB0kB,KAIzBhiB,EAAGh1B,IAAI01B,EAASnQ,EAAO6P,EAASC,EAAOC,EAAOhD,GAOxD,OAAOnvB,EAAQ5B,eAAeyzB,EAAGx1B,MAAOw1B,EAAGx2B,MAAOw2B,EAAGz1B,OACvD,GCpBO,IAAM03C,GAAkC,CAC7Cr0C,WAAYs0C,cACZp0C,YAAa,MACbC,oBA7E0BC,GAKnB,IAAAkC,WAAQ/B,YAASwD,UACjBmuB,OAAIhvB,UACL7C,EAAI6C,EACV7H,EAAiB,CAAC6H,YAAgB,eAyBlC,IAxBO,IAAAguB,eAAYxmB,YAASymB,QAAKC,oBAE3BnF,EAAWjvB,eAAas0B,kBAC1BjxB,EAAEzD,MAA2Cs0B,EAAYxmB,EACzD,EAAmBymB,EAAKC,GACtBpF,EAAUzrB,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACrCu3C,EAAY11C,SACdytB,EAAStjB,SAAUtI,EAAEzE,MACrB+yB,GAAiB3C,EAAS3rB,EAAEzD,MAAOyD,EAAEzE,MAAOqwB,GAAUtvB,QACpDwvB,EAAeF,EAASE,aACxBC,EAAcH,EAASG,YACvBC,EAAiBJ,EAASI,eAC1BC,EAAgBL,EAASK,cACzBC,EAAwBN,EAASM,sBACjCC,EAAuBP,EAASO,qBAChCI,EAAUJ,EAAuB,EAAIP,EAASS,QAAQxK,KACtDuK,EAASF,EAAwB,EAAIN,EAASS,QAAQC,IACtDyF,EACF5zB,SAAgB6B,EAAEzD,MAA2C,WAE3D22B,EAAShzB,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OACrC21B,EAAQ9zB,SACV0zB,EAAGt1B,MAA2C,UAAW22B,GAEpDj8B,EAAI,EAAGA,EAAI20B,EAASrL,YAAatpB,EACxC,IAAK,IAAID,EAAI,EAAGA,EAAI40B,EAASqB,aAAcj2B,EACzC,IAAK,IAAIm8B,EAAM,EAAGA,EAAMvH,EAAS2B,WAAY4F,EAC3C,IAAK,IAAIC,EAAM,EAAGA,EAAMxH,EAASkC,UAAWsF,EAAK,CAK/C,IAHA,IAAMC,EAAYF,EAAM/G,EAClBkH,EAAYF,EAAM7G,EACpBkG,EAAU,EACL7D,EAAK,EAAGA,EAAK1C,EAAuB0C,GAAM5C,EAAgB,CACjE,IAAMuH,GAAOF,EAAYzE,GAAM9C,EAC/B,KAAIyH,EAAM,GAAKA,GAAO3H,EAASuB,WAC3B3tB,KAAKoK,MAAM2pB,KAASA,GAGxB,IAAK,IAAI1E,EAAK,EAAGA,EAAK1C,EAAsB0C,GAAM5C,EAAe,CAC/D,IAAMuH,GAAOF,EAAYzE,GAAM9C,EAC/B,KAAIyH,EAAM,GAAKA,GAAO5H,EAAS8B,UAC3BluB,KAAKoK,MAAM4pB,KAASA,GADxB,CAIA,IAIMugB,EAJS7nB,EAAwBC,EAAuB,EACzD0nB,EAAUn3C,IAAIzF,EAAGs8B,EAAKC,EAAKx8B,KACjB43B,EAAKzC,EAAuB0C,EAEV,EAAI,EACrC,GAAa,IAATklB,EAKJthB,GADcR,EAAMv1B,IAAIzF,EAAGs8B,EAAKC,EAAKx8B,GAClB+8C,IAGvBhiB,EAAGh1B,IAAI01B,EAASx7B,EAAGk8B,EAAKC,EAAKp8B,GAKrC,OAAOkJ,EAAQ5B,eAAeyzB,EAAGx1B,MAAOw1B,EAAGx2B,MAAOw2B,EAAGz1B,OACvD,GCtEO,IAAM43C,GAAwC,CACnDv0C,WAAYw0C,oBACZt0C,YAAa,MACbC,WAAY,SAACyD,OAACtB,WAAQyB,UAAOxD,YACpBF,MACA6wB,eAAYxmB,YAASymB,QAAKtC,wBAE3BvuB,EAAaC,EACnBlF,EAAiBgF,EAAG,qBAEpB,IAAM1D,EAAS2D,EAAWrE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACvCsvB,EAAWjvB,eAAas0B,kBAC1BjxB,EAAEzD,MAA2Cs0B,EAAYxmB,EACzD,CAAC,EAAG,GAAIymB,GACNpzB,aClBNiuB,EAAqBzd,EAAkB3S,EACvCizB,EAA8B5C,GAChC,IACMwoB,EAAW1oB,GAAKC,EAASzd,EAAQ3S,EADvBF,OAAKyF,eAAeoN,GACmB0d,EAAU,OAC3D6C,EAAeH,GACjB3C,EAASzd,EAAQ3S,EAAOqwB,GAAU,EAAM4C,GAE5C,MAAO,CAAC4lB,EAAS93C,OAAQmyB,EAAanyB,OACxC,4BDUW+3C,OAAQC,OAGTC,EACFt0C,EAAW3C,MAAM+2C,EAAwBzoB,EAAStjB,SAAUtI,EAAEzE,OAC5Di5C,EACFv0C,EAAW3C,MAAMg3C,EAAuB1oB,EAAStjB,SAAUtI,EAAEzE,OACjE,MAAO,CACL,CAACsB,OAAQ03C,EAAch4C,MAAOqvB,EAAStjB,SAAU/M,MAAOyE,EAAEzE,OAC1D,CAACsB,OAAQ23C,EAAej4C,MAAOqvB,EAAStjB,SAAU/M,MAAO,YEOxD,IAAMk5C,GAA2B,CACtC90C,WAAY+0C,OACZ70C,YAAa,MACbC,oBAhCEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA+P,SAAMC,aAEPC,EAAO5U,OAAK6U,eAAeH,EAAM/P,EAAEzD,OAEnCkT,EADS9S,eAAag4C,0BAA0B30C,EAAEzD,MAAO0T,GACpC,GACrBrD,EAAavR,OAAK8E,cAAcsP,GAChCmlC,EAAY,GACZC,EACF30C,EAAQ5B,eAAe,GAAI,UAAW,IAAIiB,aAAa,CAACqN,KAC5DgoC,EAAUz6C,KAAK06C,GAEf,IAAMjrB,EAAKnmB,EAAK,CAACxB,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACnI,MAAO,aACtDq5C,EAAUz6C,KAAKyvB,GAEf,IAAMpb,EACFi6B,GAAI,CAACxmC,OAAQ,CAACuC,EAAGolB,EAAI3yB,EAAG49C,GAAmB30C,YAC/C00C,EAAUz6C,KAAKqU,GAEf,IAAMhW,EAASyvB,GAAI,CAAChmB,OAAQ,CAACjC,EAAGwO,GAAMtO,UAASwD,MAAO,CAACqM,OAAMC,cAI7D,OAFA4kC,EAAUx5C,SAAQ,SAAApC,GAAK,OAAAkH,EAAQ2D,8BAA8B7K,MAEtDR,CACT,GC6BO,IAAMs8C,GAA0B,CACrCn1C,WAAYo1C,MACZl1C,YAAa,MACbC,oBA3DEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA+P,SAAMC,aAEbhV,EAAiBgF,EAAG,OAEpB,IAAM0pB,EAAWruB,OAAK6U,eAAeH,EAAM/P,EAAEzD,OACzC0T,EAAOyZ,EACLC,EAAehtB,eAAayT,mBAAmBH,EAAMjQ,EAAEzD,MAAMrC,QAC/D0vB,EAAK5pB,EACW,MAAhB2pB,IACFC,EAAKxa,GAAU,CAACnN,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACoL,KAAM6a,KACpD1Z,EAAOtT,eAAa4T,iBAAiBN,EAAK/V,OAAQ8F,EAAEzD,MAAMrC,SAG5DyC,eAAaktB,2BAA2B,MAAO5Z,EAAM2Z,EAAGrtB,MAAMrC,QAO9D,IANM,IAAAqJ,2DAAC+E,OAAUmH,OAEX7C,EAAavR,OAAK8E,cAAcsP,GAChCpQ,EAAOhE,OAAKmH,oBAAoBnH,OAAK8E,cAAcmI,GAAWshB,EAAGruB,OAEjEiF,EAAQN,EAAQtE,KAAKc,IAAIktB,EAAG/sB,QAAQP,OACjC9B,EAAI,EAAGA,EAAI6E,EAAKnF,SAAUM,EAAG,CAGpC,IAFA,IAAMqS,EAASrS,EAAIoS,EACfooC,EAAMx0C,EAAMqM,GACPrF,EAAI,EAAGA,EAAIoF,IAAcpF,EAAG,CACnC,IAAMrP,EAAQqI,EAAMqM,EAASrF,IACzBuF,OAAOC,MAAM7U,IACbA,EAAQ68C,KACVA,EAAM78C,GAGVkH,EAAK7E,GAAKw6C,EAGQ,MAAhBrrB,GACFzpB,EAAQ2D,8BAA8B+lB,GAGxC,IAAMpxB,EAAS0H,EAAQ5B,eAAegK,EAAUshB,EAAGruB,MAAO8D,GAE1D,GAAI2Q,EAAU,CACZ,IACM+Z,EACFzU,GAAQ,CAACrT,OAAQ,CAACjC,EAAGxH,GAAS0H,UAASwD,MAAO,CAACnH,MAF7BI,eAAa6T,qBAAqBlI,EAAUohB,MAMlE,OAFAxpB,EAAQ2D,8BAA8BrL,GAE/BuxB,EAGT,OAAOvxB,CACT,GCRO,IAAMy8C,GAAgC,CAC3Ct1C,WAAYu1C,YACZr1C,YAAa,MACbC,oBApDwBC,GAKjB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACAm1C,aAAUC,SAEjBp6C,EAAiBgF,EAAG,aAmBpB,IAjBA,IAAMsI,EAAW6sC,EAAS/3C,KACtB,SAAC9F,EAAGkD,GAAM,OAAAlD,EAAE,GAAqB0I,EAAEzD,MAAM/B,GAAKlD,EAAE,MAE9CqH,EAAQw2C,EAAS/3C,KAAI,SAAA9F,GAAK,OAAAA,EAAE,MAC5B+kB,EAAM84B,EAAS/3C,KAAI,SAAC9F,EAAGkD,GAAM,OAAAlD,EAAE,GAAK0I,EAAEzD,MAAM/B,MAC5CqS,EAAkB,YAATuoC,EAAqB,EAAI,EAElC1uC,EAAQxG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACnCyS,EAAQ/O,EAAEzD,MAAMrC,OAChB8U,EAAW3T,OAAKyF,eAAed,EAAEzD,OAEjCwE,EAAa1F,OAAK8E,cAAcmI,GAChC1H,EAAa0H,EAASpO,OACtB2G,EAAgBxF,OAAKyF,eAAewH,GACpCkf,EACFnsB,OAAK2F,uBAAuBhB,EAAEzE,MAA0BwF,GAEnDvG,EAAI,EAAGA,EAAIuG,EAAYvG,IAAK,CAEnC,IADA,IAAI66C,EAASh6C,OAAKoG,WAAWjH,EAAGoG,EAAYC,GACnCsO,EAAI,EAAGA,EAAIvO,EAAYuO,IAC1BkmC,EAAOlmC,GAAKxQ,EAAMwQ,GACpBkmC,EAAOlmC,GAAgB,EAAXxQ,EAAMwQ,GAASkmC,EAAOlmC,GAAKtC,EAC9BwoC,EAAOlmC,IAAMkN,EAAIlN,KAC1BkmC,EAAOlmC,GAAoB,GAAdkN,EAAIlN,GAAK,GAASkmC,EAAOlmC,GAAKtC,GAG/CwoC,EAASA,EAAOj4C,KAAI,SAACwjB,EAAGpmB,GAAM,OAAAomB,EAAIjiB,EAAMnE,MAExC,IAAM86C,EAAUj6C,OAAKwG,WAAWwzC,EAAQtmC,EAAOC,GAE/CwY,EAAQhtB,GAAKkM,EAAM4uC,GAKrB,MAAO,CAACz4C,OAFMqD,EAAQ5C,MAAMkqB,EAASlf,EAAUtI,EAAEzE,OAE1BgB,MAAO+L,EAAU/M,MAAOyE,EAAEzE,MACnD,GC/Cag6C,GACTl1C,YAA+B6M,EAAgBC,GAC7C,IAAMqoC,EAAMtoC,EAASC,EACrB,OAAKD,EAAS,GAAKC,EAAS,GAAOD,GAAU,GAAKC,GAAU,EACnDqoC,GAECA,EAAMroC,GAAUA,CAE3B,IAEQsoC,GAAMrxC,EAAiBsxC,MAAKH,IAE5BI,GAA0B,CACrCh2C,WAAY+1C,MACZ71C,YAAa,MACbC,WAAY21C,aCTEG,GACZ71C,GAGK,IAAAkC,WAAQ/B,YAASwD,UACjBmyC,WACAnrC,QAEDorC,EAAaD,EAAOt5C,MAAMrC,OAE5BmuC,EAAO39B,EAIX,IAHc,IAAV29B,IACFA,EAAOyN,EAAa,GAElBzN,IAASyN,EAAa,EACxB,MAAM13C,MACF,4EACmB03C,kBAA0BzN,GAGnD,IAAMp4B,EAAO5U,OAAK6U,eAAe,CAACm4B,GAAOwN,EAAOt5C,OAC1Cw5C,EAAWjpC,GAAI,CACnB7K,OAAQ,CAACjC,EAAG61C,GACZ31C,UACAwD,MAAO,CAACyvC,iBAAkBljC,EAAMD,UAAU,KAEtCgmC,EAAgBr5C,eAAa6T,qBAAqBulC,EAASx5C,MAAO0T,GAElEgmC,EACF3gC,GAAQ,CAACrT,OAAQ,CAACjC,EAAG+1C,GAAW71C,UAASwD,MAAO,CAACnH,MAAOy5C,KACtDxxC,EACF4c,GAAI,CAACnf,OAAQ,CAACuC,EAAGqxC,EAAQ5+C,EAAGg/C,GAAmB/1C,YAC7CjJ,EAAImS,EAAI,CAACnH,OAAQ,CAACjC,EAAGwE,GAAItE,YACzBg2C,EACFjuB,GAAI,CAAChmB,OAAQ,CAACjC,EAAG/I,GAAIiJ,UAASwD,MAAO,CAACqM,KAAME,EAAMD,UAAU,KAC1DmmC,EACF7gC,GAAQ,CAACrT,OAAQ,CAACjC,EAAGk2C,GAASh2C,UAASwD,MAAO,CAACnH,MAAOy5C,KAEpDx9C,EAASiwC,GAAI,CAACxmC,OAAQ,CAACuC,EAAGvN,EAAGA,EAAGk/C,GAAcj2C,YASpD,OAPAA,EAAQ2D,8BAA8BkyC,GACtC71C,EAAQ2D,8BAA8BoyC,GACtC/1C,EAAQ2D,8BAA8BW,GACtCtE,EAAQ2D,8BAA8B5M,GACtCiJ,EAAQ2D,8BAA8BqyC,GACtCh2C,EAAQ2D,8BAA8BsyC,GAE/B39C,CACT,CAEO,IAAM49C,GAA8B,CACzCz2C,WAAY02C,UACZx2C,YAAa,MACbC,WAAY81C,ICAP,IAAMU,GAAkC,CAC7C32C,WAAY42C,cACZ12C,YAAa,MACbC,oBA3D0BC,GAKnB,IAAAkC,WAAQ/B,YAASwD,UACjBmyC,WACAW,eAAYC,SAAMC,eAEzB17C,EAAiB66C,EAAQ,eAazB,IAXA,IAAMc,EAAgBD,EAClBb,EACAD,GAAQ,CAAC3zC,OAAQ,CAAC4zC,UAAS31C,UAASwD,MAAO,CAACgH,KAAM,KAEhD6V,EAAYo2B,EAAcp6C,MAAM,GAChCq6C,EAAYD,EAAcp6C,MAAM,GAChCs6C,EAAW32C,EAAQtE,KAAKc,IAAIi6C,EAAc95C,QAAQP,OAClDw6C,EAAW,CAACv2B,EAAWi2B,GACvBhvB,EACFnsB,OAAKmH,oBAAoBnH,OAAK8E,cAAc22C,GAAW,SAElD7/C,EAAI,EAAGA,EAAIspB,IAAatpB,EAAG,CAClC,IAAM4V,EAAS5V,EAAI2/C,EAGbG,EAAM,IAAIx3C,aAAaq3C,EAAY,GACzCG,EAAI,GAAKF,EAAShqC,GAClB,IAAK,IAAImqC,EAAQ,EAAGA,EAAQD,EAAI78C,SAAU88C,EACxCD,EAAIC,GAASD,EAAIC,EAAQ,GAAKH,EAAShqC,EAASmqC,GAKlD,IAFA,IAAMC,EAASC,EAAWC,KAAKV,EAAKnzB,YAC9BX,EAAY1rB,EAAIu/C,EACbY,EAAW,EAAGA,EAAWZ,IAAcY,EAAU,CACxD,IAAM18C,EAAIu8C,IAGVzvB,EAAQ7E,EAAYy0B,GAAYL,EAAI78C,OAEpC,IAAS88C,EAAQ,EAAGA,EAAQD,EAAI78C,OAAQ88C,IACtC,GAAIt8C,EAAIq8C,EAAIC,GAAQ,CAClBxvB,EAAQ7E,EAAYy0B,GAAYJ,EAChC,QAUR,OAJKN,GACHx2C,EAAQ2D,8BAA8B8yC,GAGjCz2C,EAAQ5B,eAAew4C,EAAU,QAAStvB,EACnD,GC5DM6vB,GAA0B57C,eAAa47C,wBA0BtC,IAAMC,GAA0C,CACrD33C,WAAY43C,sBACZ13C,YAAa,MACbC,oBAxBkCC,GAK3B,IAAAkC,WAAQ/B,YAASwD,UACjB86B,UAAOgZ,WACPC,kBAAeC,iBAAcC,mBAEpC38C,EAAiBwjC,EAAO,qBAExB,IAAMoZ,EAAY13C,EAAQtE,KAAKc,IAAI8hC,EAAM3hC,QAAQP,OAC3Cu7C,EAAa33C,EAAQtE,KAAKc,IAAI86C,EAAO36C,QAAQP,OAE5Cw7C,gCAGP,OAAO53C,EAAQ5B,eACX,CAACw5C,EAAgB59C,QAAS,QAAS,IAAIiJ,WAAW20C,GACxD,GCxBMC,GAA0Bt8C,eAAas8C,wBA6BtC,IAAMC,GAA0C,CACrDr4C,WAAYs4C,sBACZp4C,YAAa,MACbC,oBA5BkCC,GAK3B,IAAAkC,WAAQ/B,YAASwD,UACjB86B,UAAOgZ,WACPC,kBAAeC,iBAAcC,mBAAgBO,uBAGpDl9C,EAAiBwjC,EAAO,2BAExB,IAAMoZ,EAAY13C,EAAQtE,KAAKc,IAAI8hC,EAAM3hC,QAAQP,OAC3Cu7C,EAAa33C,EAAQtE,KAAKc,IAAI86C,EAAO36C,QAAQP,OAE7CiH,kBAACu0C,oBAAiBK,iBAIxB,MAAO,CACLj4C,EAAQ5B,eACJ,CAACw5C,EAAgB59C,QAAS,QAAS,IAAIiJ,WAAW20C,IACtD53C,EAAQ5B,eAAe,GAAI,QAAS,IAAI6E,WAAW,CAACg1C,KAExD,GC5BMC,GAA0B38C,eAAa28C,wBAmCtC,IAAMC,GAA0C,CACrD14C,WAAY24C,sBACZz4C,YAAa,MACbC,oBAlCkCC,GAK3B,IAAAkC,WAAQ/B,YAASwD,UACjB86B,UAAOgZ,WACPC,kBAAeC,iBAAcC,mBAAgBY,iBAEpDv9C,EAAiBwjC,EAAO,8BAExB,IAAMoZ,EAAY13C,EAAQtE,KAAKc,IAAI8hC,EAAM3hC,QAAQP,OAC3Cu7C,EAAa33C,EAAQtE,KAAKc,IAAI86C,EAAO36C,QAAQP,OAO7CiH,SALmBk0C,EACDC,EACEC,EACFY,GAEjBT,oBAAiBU,mBAIxB,MAAO,CACLt4C,EAAQ5B,eACJ,CAACw5C,EAAgB59C,QAAS,QAAS,IAAIiJ,WAAW20C,IACtD53C,EAAQ5B,eACJ,CAACk6C,EAAet+C,QAAS,UAAW,IAAIqF,aAAai5C,IAE7D,GCNO,IAAMC,GAA6B,CACxC94C,WAAY+4C,SACZ74C,YAAa,MACbC,oBA1BEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjBwT,YACA3b,UAAOo9C,UAAOC,YAASC,aAE9B79C,EAAiBkc,EAAS,UAE1B,IAAM44B,EAAcz0C,OAAK8E,cAAc+W,EAAQ3a,OAEzCiS,EAAM,IAAIjP,aAAauwC,EAAc6I,GAC3CnqC,EAAI0H,KAAK2iC,GAGT,IAFA,IAAMC,EAAa54C,EAAQtE,KAAKc,IAAIwa,EAAQra,QAAQP,OAE3C06C,EAAQ,EAAGA,EAAQlH,IAAekH,EACrC8B,EAAW9B,IAAU,GAAK8B,EAAW9B,GAAS2B,IAChDnqC,EAAIwoC,EAAQ2B,EAAQG,EAAW9B,IAAU4B,GAI7C,OAAO14C,EAAQ5B,iBAAmB4Y,EAAQ3a,OAAOo8C,IAAQp9C,EAAOiT,EAClE,YClBgBuqC,GACZh5C,GACK,IAAAkC,WAAQ/B,YACRF,MAEP,GAAgB,WAAZA,EAAEzE,MACJ,MAAM,IAAI6C,MAAM,iDACX,GAAgB,cAAZ4B,EAAEzE,MAAuB,CAClC,IAAMuI,EAAWjG,EAAK,CAACoE,OAAQ,CAACY,MAAO7C,GAAIE,YACrCxF,EAAIq+C,GAAU,CAAC92C,OAAQ,CAACjC,EAAG8D,GAAW5D,YACtC84C,EAAWj7C,GAAK,CAACkE,OAAQ,CAACY,MAAO7C,GAAIE,YACrC1F,EAAIu+C,GAAU,CAAC92C,OAAQ,CAACjC,EAAGg5C,GAAW94C,YAEtC1H,EAASwJ,EAAQ,CAACC,OAAQ,CAACpE,KAAMnD,EAAGqD,KAAMvD,GAAI0F,YAOpD,OALAA,EAAQ2D,8BAA8BC,GACtC5D,EAAQ2D,8BAA8BnJ,GACtCwF,EAAQ2D,8BAA8Bm1C,GACtC94C,EAAQ2D,8BAA8BrJ,GAE/BhC,EAEP,OAAO0d,GAAK,CAAChW,UAASwD,MAAO,CAACnH,MAAOyD,EAAEzD,MAAOpE,MAAO,EAAGoD,MAAOyE,EAAEzE,QAErE,CAEO,IAAM09C,GAAgC,CAC3Ct5C,WAAYu5C,YACZr5C,YAAa,MACbC,WAAYi5C,ICHP,IAAMI,GAA+B,CAC1Cx5C,WAAYy5C,WACZv5C,YAAa,MACbC,oBA7Bcu5C,EACZt5C,GACK,IAAAkC,WAAQ/B,YACRF,MAEP,GAAgB,WAAZA,EAAEzE,MACJ,MAAM,IAAI6C,MAAM,gDACX,GAAgB,cAAZ4B,EAAEzE,MAAuB,CAClC,IAAMuI,EAAWjG,EAAK,CAACoE,OAAQ,CAACY,MAAO7C,GAAIE,YACrCxF,EAAI2+C,EAAS,CAACp3C,OAAQ,CAACjC,EAAG8D,GAAW5D,YACrC84C,EAAWj7C,GAAK,CAACkE,OAAQ,CAACY,MAAO7C,GAAIE,YACrC1F,EAAIu+C,GAAU,CAAC92C,OAAQ,CAACjC,EAAGg5C,GAAW94C,YAEtC1H,EAASwJ,EAAQ,CAACC,OAAQ,CAACpE,KAAMnD,EAAGqD,KAAMvD,GAAI0F,YAOpD,OALAA,EAAQ2D,8BAA8BC,GACtC5D,EAAQ2D,8BAA8BnJ,GACtCwF,EAAQ2D,8BAA8Bm1C,GACtC94C,EAAQ2D,8BAA8BrJ,GAE/BhC,EAEP,OAAO0d,GAAK,CAAChW,UAASwD,MAAO,CAACnH,MAAOyD,EAAEzD,MAAOpE,MAAO,EAAGoD,MAAOyE,EAAEzE,QAErE,YC3BgB+9C,GACZv5C,GAEK,IAAAkC,WAAQ/B,YACR6P,eAEP,GAAsB,IAAlB9N,EAAO/H,OACT,OAAOkuC,GACH,CAACnmC,OAAQ,CAACY,MAAOZ,EAAO,IAAK/B,UAASwD,MAAO,CAACgH,IAAKqF,KAGzD,IAAMxT,EAAQ0F,EAAO,GAAG1F,MAClBhB,EAAQ0G,EAAO,GAAG1G,MAExB0G,EAAO7G,SAAQ,SAAApC,GACbqC,OAAKk+C,kBACDh9C,EAAOvD,EAAEuD,MACT,yDACJlB,OAAKC,OACDC,IAAUvC,EAAEuC,OACZ,WAAM,MAAA,8DAGZ,IAAM+U,EAAwC,GAQxC9X,EAASuC,GAAO,CAACkH,OAPCA,EAAO7E,KAAI,SAAApE,GACjC,IAAMwgD,EACFpR,GAAW,CAACnmC,OAAQ,CAACY,MAAO7J,GAAIkH,UAASwD,MAAO,CAACgH,IAAKqF,KAE1D,OADAO,EAAwBnW,KAAKq/C,GACtBA,KAGuCt5C,UAASwD,MAAO,CAACqM,UAKjE,OAHAO,EAAwBlV,SACpB,SAAApC,GAAK,OAAAkH,EAAQ2D,8BAA8B7K,MAExCR,CACT,CAEO,IAAMihD,GAA2B,CACtC95C,WAAY+5C,OACZ75C,YAAa,MACbC,WAAYw5C,ICDP,IAAMK,GAA4B,CACvCh6C,WAAYi6C,QACZ/5C,YAAa,MACbC,oBA5CEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACAm1C,aAAU0E,kBAEjB7+C,EAAiBgF,EAAG,OAEpB,IAAMsI,EAAW6sC,EAAS/3C,KACtB,SAAC9F,EAAGkD,GAAM,OAAAlD,EAAE,GAAqB0I,EAAEzD,MAAM/B,GAAKlD,EAAE,MAE9CqH,EAAQw2C,EAAS/3C,KAAI,SAAA9F,GAAK,OAAAA,EAAE,MAE5BoP,EAAQxG,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACnCsL,EAAQvM,OAAK8E,cAAcH,EAAEzD,OAC7BwS,EAAQ/O,EAAEzD,MAAMrC,OAChB8U,EAAW3T,OAAKyF,eAAed,EAAEzD,OAEjCwE,EAAa1F,OAAK8E,cAAcmI,GAChC1H,EAAa0H,EAASpO,OACtB2G,EAAgBxF,OAAKyF,eAAewH,GACpCkf,EACFnsB,OAAK2F,uBAAuBhB,EAAEzE,MAA0BwF,GAEtC,IAAlB84C,GACFryB,EAAQtR,KAAK2jC,GAGf,IAAK,IAAIr/C,EAAI,EAAGA,EAAIoN,EAAOpN,IAAK,CAC9B,IACMs/C,EADSz+C,OAAKoG,WAAWjH,EAAGuU,EAAOC,GAChB5R,KAAI,SAACwjB,EAAGpmB,GAAM,OAAAomB,EAAIjiB,EAAMnE,MAGjDgtB,EAFiBnsB,OAAKwG,WAAWi4C,EAAWl5C,EAAYC,IAEpC6F,EAAMlM,GAK5B,MAAO,CAACqC,OAFMqD,EAAQ5C,MAAMkqB,EAASlf,EAAUtI,EAAEzE,OAE1BgB,MAAO+L,EAAU/M,MAAOyE,EAAEzE,MACnD,GCxCaw+C,GACT15C,GAA6B,SAACmE,EAAWvN,GAAc,OAAAuI,KAAKkzC,IAAIluC,EAAGvN,MAC1Dy7C,GAAMtuC,EAAiB41C,MAAKD,IAE5BE,GAA0B,CACrCt6C,WAAYq6C,MACZn6C,YAAa,MACbC,WAAY4yC,ICkBP,IAAMwH,GAA2C,CACtDv6C,WAAYw6C,uBACZt6C,YAAa,MACbC,oBA3BmCC,GAK5B,IAAAkC,WAAQ/B,YAASwD,UACjBnH,UAAOD,WAAQuU,iBAAcupC,wBAC7BlpC,sBAEDmU,EAASnlB,EAAQtE,KAAKc,IAAIH,EAAMM,QAAQP,OACxC+9C,EAAUn6C,EAAQtE,KAAKc,IAAIJ,EAAOO,QAAQP,OAC1Cg+C,EACFp6C,EAAQtE,KAAKc,IAAImU,EAAahU,QAAQP,OACpCi+C,EAAsBH,EAAoBh9C,KAC5C,SAAApE,GAAK,OAAAkH,EAAQtE,KAAKc,IAAI1D,EAAE6D,QAAQP,UAC9B0U,EAA2BopC,EAAoBh9C,KAAI,SAAApE,GAAK,OAAAA,EAAEuD,SAE1DgH,uDAACiR,OAAa4H,OAIpB,OAAOlc,EAAQ5B,eAAekW,EAAalY,EAAOf,MAAO6gB,EAC3D,GCdO,IAAMo+B,GAA4B,CACvC76C,WAAY86C,QACZ56C,YAAa,MACbC,oBAZoBC,GAEb,IAAAG,YAASwD,UACT/E,UAAO0N,SAAM9Q,UAEde,EAASoa,GAAU/X,EAAO0N,SAAY9Q,GAC5C,OAAO2E,EAAQ5B,eAAe,CAAChC,EAAOpC,QAASqB,EAAOe,EACxD,GCRao+C,GAAa/yC,EAAgBgzC,cAAY,SAAC1yC,GAAO,OAAA,EAAIA,KAErD2yC,GAAiC,CAC5Cj7C,WAAYg7C,aACZ96C,YAAa,MACbC,WAAY46C,ICgFP,IAAMG,GAAqC,CAChDl7C,WAAYm7C,iBACZj7C,YAAa,MACbC,oBAvF6BC,GAKtB,IAAAkC,WAAQ/B,YAASwD,UACjBq3C,WACAC,iBAAcC,qBAAkBn0C,SAEvC9L,EAAiB+/C,EAAQ,kBAsBzB,IApBA,IAAMG,EAAgB7/C,OAAKyF,eAAei6C,EAAOx+C,OAC3CgH,SAAC43C,OAAWC,OAEZ19C,eAAC4kB,OAAO+4B,OAAWC,OAAUvc,OAC7BpT,EAAUzrB,EAAQtE,KAAKc,IAAIq+C,EAAOl+C,QAAQP,OAC1C9D,EAAS,IAAI+G,aACflE,OAAK8E,cAAc,CAACmiB,EAAO64B,EAAWC,EAAUrc,KAE9Cwc,EAAuC,CAC1CP,GAAgBG,EAAY,EAAKE,EAAY,EAAIA,EACjDL,GAAgBI,EAAW,EAAKE,EAAW,EAAIA,GAG5CE,EAAwC,CAC3CR,GAAgBG,EAAY,EAAKA,EAAY,EAAIA,EACjDH,GAAgBI,EAAW,EAAKA,EAAW,EAAIA,GAE9C1Y,EAAY,EACV+Y,EAAwBF,EAAmB,GAAKC,EAAoB,GACpEE,EAAwBH,EAAmB,GAAKC,EAAoB,GACjEvkD,EAAI,EAAGA,EAAIqrB,EAAOrrB,IACzB,IAAK,IAAIyD,EAAI,EAAGA,EAAIygD,EAAWzgD,IAAK,CAClC,IAAIihD,SAEFA,EADEV,EACcQ,GAAyB/gD,EAAI,IAAO,GAEpC+gD,EAAwB/gD,EAU1C,IAPA,IAAMkhD,EAAiBp8C,KAAKsN,IAAI,EAAGtN,KAAKoK,MAAM+xC,IACxCE,EAAUF,EAAgBC,EAC1BE,EAAgBt8C,KAAKgO,IAAI6tC,EAAY,EAAG77C,KAAK0I,KAAKyzC,IAClDI,EACF9kD,EAAIikD,EAAc,GAAKU,EAAiBV,EAAc,GACpDc,EACF/kD,EAAIikD,EAAc,GAAKY,EAAgBZ,EAAc,GAChDt6B,EAAI,EAAGA,EAAIw6B,EAAUx6B,IAAK,CACjC,IAAIq7B,SAEFA,EADEhB,EACcS,GAAyB96B,EAAI,IAAO,GAEpC86B,EAAwB96B,EAS1C,IAPA,IAAMs7B,EAAiB18C,KAAKsN,IAAI,EAAGtN,KAAKoK,MAAMqyC,IACxCE,EAAUF,EAAgBC,EAC1BE,EAAgB58C,KAAKgO,IAAI8tC,EAAW,EAAG97C,KAAK0I,KAAK+zC,IACjDI,EAAgBN,EAAeG,EAAiBhB,EAAc,GAC9DoB,EAAgBN,EAAeE,EAAiBhB,EAAc,GAC9DqB,EAAiBR,EAAeK,EAAgBlB,EAAc,GAC9DsB,EAAiBR,EAAeI,EAAgBlB,EAAc,GAC3DlkD,EAAI,EAAGA,EAAI+nC,EAAa/nC,IAAK,CAIpC,IAAMypC,EAAU9U,EAAQ0wB,EAAgBrlD,GAClC2pC,EAAahV,EAAQ2wB,EAAgBtlD,GAIrCs1B,EAAMmU,GAHK9U,EAAQ4wB,EAAiBvlD,GAGRypC,GAAW0b,EAEvCM,EAAWnwB,GADFqU,GAHKhV,EAAQ6wB,EAAiBxlD,GAGF2pC,GAAcwb,EACxB7vB,GAAOuvB,EAExCrjD,EAAOkqC,KAAe+Z,IAM9B,OAAOv8C,EAAQ5B,eACX,CAACgkB,EAAO64B,EAAWC,EAAUrc,GAAc,UAAWvmC,EAC5D,GCOO,IAAMkkD,GAAyC,CACpD/8C,WAAYg9C,qBACZ98C,YAAa,MACbC,oBA5FiCC,GAK1B,IAAAkC,WAAQ/B,YAASwD,UACjBq3C,WAAQlpB,OACRmpB,iBAEPhgD,EAAiB,CAAC62B,EAAIkpB,GAAS,sBAgC/B,IA9BA,IAAMG,EAAgB7/C,OAAKyF,eAAei6C,EAAOx+C,OAE3CgH,eAAC+e,OAAOs6B,OAASC,OAAQlE,OACzBj7C,eAAGo/C,OAASC,OAEZ3gC,EAAS,IAAI7c,aAAa+iB,EAAQs6B,EAAUC,EAASlE,GAOrDqE,EAAmC,CACtChC,GAAgB8B,EAAU,EAAKF,EAAU,EAAIA,EAC7C5B,GAAgB+B,EAAS,EAAKF,EAAS,EAAIA,GAGxCI,EAAmC,CACtCjC,GAAgB8B,EAAU,EAAKA,EAAU,EAAIA,EAC7C9B,GAAgB+B,EAAS,EAAKA,EAAS,EAAIA,GAGxCjd,EAAckd,EAAe,GAAKC,EAAe,GACjDld,EAAaid,EAAe,GAAKC,EAAe,GAKhD/hB,EAAWh7B,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OACzCuQ,EAAS,EACJ5V,EAAI,EAAGA,EAAIqrB,EAAOrrB,IAEzB,IADA,IAAMimD,EAAUjmD,EAAIikD,EAAc,GACzBxgD,EAAI,EAAGA,EAAIoiD,EAASpiD,IAU3B,IATA,IAAMy4B,EAAMz4B,EAAIolC,EACVqd,EAAc39C,KAAKoK,MAAMupB,GACzBiqB,EAAiB59C,KAAKgO,IAAIhO,KAAK0I,KAAKirB,GAAMypB,EAAU,GAEpDS,EAAeH,EAAUC,EAAcjC,EAAc,GACrDoC,EAAkBJ,EAAUE,EAAiBlC,EAAc,GAE3DqC,EAAUpqB,EAAMgqB,EAChBK,EAAiB,EAAMD,EACpB38B,EAAI,EAAGA,EAAIm8B,EAAQn8B,IAoB1B,IAnBA,IAAMwS,EAAMxS,EAAImf,EACV0d,EAAej+C,KAAKoK,MAAMwpB,GAC1BsqB,EAAgBl+C,KAAKgO,IAAIhO,KAAK0I,KAAKkrB,GAAMypB,EAAS,GAClDc,EAAUvqB,EAAMqqB,EAChBG,EAAiB,EAAMD,EAEvBE,EAAkBR,EAAeI,EAAevC,EAAc,GAC9D4C,EACFT,EAAeK,EAAgBxC,EAAc,GAC3C6C,EACFT,EAAkBG,EAAevC,EAAc,GAC7C8C,EACFV,EAAkBI,EAAgBxC,EAAc,GAE9C+C,EACFT,EAAiBI,EACfM,EAA6BV,EAAiBG,EAC9CQ,EAA6BZ,EAAUK,EACvCQ,EAAsBb,EAAUI,EAC7B3mD,EAAI,EAAGA,EAAI2hD,EAAO3hD,IAAK,CAC9B,IAAMqnD,EAAQnjB,EAASruB,KACvBuP,EAAOyhC,EAAkB7mD,IACrBqnD,EAAQJ,EACZ7hC,EAAO0hC,EAAmB9mD,IAAMqnD,EAAQH,EACxC9hC,EAAO2hC,EAAqB/mD,IAAMqnD,EAAQF,EAC1C/hC,EAAO4hC,EAAsBhnD,IAAMqnD,EAAQD,EAMnD,OAAOl+C,EAAQ5B,eACX,CAACgkB,EAAOu6B,EAAQD,EAASjE,GAAQ,UAAWv8B,EAClD,GChBO,IAAMkiC,GAA4C,CACvD3+C,WAAY4+C,wBACZ1+C,YAAa,MACbC,oBA1EoCC,GAK7B,IAAAkC,WAAQ/B,YAASwD,UACjBq3C,WACAC,iBAAcC,qBAAkBn0C,SAEvC9L,EAAiB+/C,EAAQ,yBAuBzB,IArBA,IAAMG,EAAgB7/C,OAAKyF,eAAei6C,EAAOx+C,OAC3CgH,SAAC43C,OAAWC,OAEZ19C,eAAC4kB,OAAO+4B,OAAWC,OAAUvc,OAC7BpT,EAAUzrB,EAAQtE,KAAKc,IAAIq+C,EAAOl+C,QAAQP,OAC1C8f,EAAS,IAAI7c,aAAa+iB,EAAQ64B,EAAYC,EAAWrc,GAEzDwc,EAAuC,CAC1CP,GAAgBG,EAAY,EAAKE,EAAY,EAAIA,EACjDL,GAAgBI,EAAW,EAAKE,EAAW,EAAIA,GAG5CE,EAAwC,CAC3CR,GAAgBG,EAAY,EAAKA,EAAY,EAAIA,EACjDH,GAAgBI,EAAW,EAAKA,EAAW,EAAIA,GAG5CK,EAAwBF,EAAmB,GAAKC,EAAoB,GACpEE,EAAwBH,EAAmB,GAAKC,EAAoB,GAEtEgD,EAAe,EACVvnD,EAAI,EAAGA,EAAIqrB,EAAOrrB,IAEzB,IADA,IAAMk3C,EAAcl3C,EAAIikD,EAAc,GAC7BxgD,EAAI,EAAGA,EAAIygD,EAAWzgD,IAAK,CAClC,IAAMihD,EAAgBV,EAClBQ,GAAyB/gD,EAAI,IAC7B+gD,EAAwB/gD,EACxB+jD,EAAmBj/C,KAAKgO,IACxB6tC,EAAY,EACZL,EAAex7C,KAAKshC,MAAM6a,GAAiBn8C,KAAKoK,MAAM+xC,IACtDV,IACFwD,EAAmBj/C,KAAKsN,IAAI,EAAG2xC,IAGjC,IADA,IAAMrQ,EAAYD,EAAcsQ,EAAmBvD,EAAc,GACxDt6B,EAAI,EAAGA,EAAIw6B,EAAUx6B,IAAK,CACjC,IAAMq7B,EAAgBhB,EAClBS,GAAyB96B,EAAI,IAC7B86B,EAAwB96B,EACxB89B,EAAmBl/C,KAAKgO,IACxB8tC,EAAW,EACXN,EAAex7C,KAAKshC,MAAMmb,GACXz8C,KAAKoK,MAAMqyC,IAC1BhB,IACFyD,EAAmBl/C,KAAKsN,IAAI,EAAG4xC,IAGjC,IADA,IAAMrQ,EAAYD,EAAYsQ,EAAmBxD,EAAc,GACtDlkD,EAAI,EAAGA,EAAI+nC,EAAa/nC,IAAK,CAGpC,IAAM2nD,EAAShzB,EAAQ0iB,EAAYr3C,GACnColB,EAAOoiC,KAAkBG,IAMjC,OAAOz+C,EAAQ5B,eACX,CAACgkB,EAAO64B,EAAWC,EAAUrc,GAAcgc,EAAOx/C,MAAO6gB,EAC/D,GCsCO,IAAMwiC,GAAgD,CAC3Dj/C,WAAYk/C,4BACZh/C,YAAa,MACbC,oBA9GwCC,GAKjC,IAAAkC,WAAQ/B,YAASwD,UACjBq3C,WAAQlpB,OACRmpB,iBAEPhgD,EAAiB,CAAC62B,EAAIkpB,GAAS,6BAmC/B,IAjCA,IAAMG,EAAgB7/C,OAAKyF,eAAei6C,EAAOx+C,OAC3Cy+B,EAAY3/B,OAAKyF,eAAe+wB,EAAGt1B,OACnCgH,eAAC+e,OAAOs6B,OAASC,OAAQlE,OACzBj7C,eAAGo/C,OAASC,OAEZ3gC,EAAS,IAAI7c,aAAa+iB,EAAQs6B,EAAUC,EAASlE,GACrDzd,EAAWh7B,EAAQtE,KAAKc,IAAIm1B,EAAGh1B,QAAQP,OAKvC0gD,EAAmC,CACtChC,GAAgB8B,EAAU,EAAKF,EAAU,EAAIA,EAC7C5B,GAAgB+B,EAAS,EAAKF,EAAS,EAAIA,GAGxCI,EAAmC,CACtCjC,GAAgB8B,EAAU,EAAKA,EAAU,EAAIA,EAC7C9B,GAAgB+B,EAAS,EAAKA,EAAS,EAAIA,GAGxCjd,EAAckd,EAAe,GAAKC,EAAe,GACjDld,EAAaid,EAAe,GAAKC,EAAe,GAEhD6B,EAAiB,EAAIhf,EACrBif,EAAgB,EAAIhf,EAIpBif,EAAyC,EAA5Bx/C,KAAK0I,KAAK42C,GAAuB,EAC9CG,EAAuC,EAA3Bz/C,KAAK0I,KAAK62C,GAAsB,EAGzC9nD,EAAI,EAAGA,EAAIqrB,EAAOrrB,IAEzB,IADA,IAAMk3C,EAAcl3C,EAAIikD,EAAc,GAC7BxgD,EAAI,EAAGA,EAAIkiD,EAASliD,IAM3B,IALA,IAAM0zC,EAAYD,EAAczzC,EAAIwgD,EAAc,GAG5CgE,EAAa1/C,KAAKoK,MAAMlP,EAAIokD,GAC5BK,EAAW3/C,KAAKoK,MAAMs1C,EAAcF,EAAY,GAC7Cp+B,EAAI,EAAGA,EAAIi8B,EAAQj8B,IAO1B,IANA,IAAMytB,EAAYD,EAAYxtB,EAAIs6B,EAAc,GAG1CkE,EAAa5/C,KAAKoK,MAAMgX,EAAIm+B,GAC5BM,EAAW7/C,KAAKoK,MAAMw1C,EAAcH,EAAW,GAE5CjoD,EAAI,EAAGA,EAAI2hD,EAAO3hD,IAAK,CAI9B,IAHA,IAAIsoD,EAAQ,EAGHC,EAAW,EAAGA,EAAWP,EAAWO,IAAY,CACvD,IAAMhsB,EAAMgsB,EAAWJ,EAEvB,KAAI5rB,EAAM,GAAKA,GAAOupB,GAAtB,CAIA,IAAM0C,EAAYrR,EAAc5a,EAAMyH,EAAU,GAC1C2gB,EAAgBpoB,EAAMuM,EAK5B,GAAIplC,IAJqB8E,KAAKgO,IAC1BovC,EAAU,EACV5B,EAAex7C,KAAKshC,MAAM6a,GACXn8C,KAAKoK,MAAM+xC,IAI9B,IAAK,IAAI8D,EAAW,EAAGA,EAAWR,EAAUQ,IAAY,CACtD,IAAMjsB,EAAMisB,EAAWJ,EAEvB,KAAI7rB,EAAM,GAAKA,GAAOupB,GAAtB,CAIA,IAAM2C,EAAYF,EAAYhsB,EAAMwH,EAAU,GACxCihB,EAAgBzoB,EAAMuM,EAMxBnf,IALqBphB,KAAKgO,IAC1BqvC,EAAS,EACT7B,EAAex7C,KAAKshC,MAAMmb,GACXz8C,KAAKoK,MAAMqyC,MAG5BqD,GAASpkB,EAASwkB,EAAY1oD,OAIpColB,EAAOiyB,EAAYr3C,GAAKsoD,EAMhC,OAAOp/C,EAAQ5B,eAAey8C,EAAOx+C,MAAOw+C,EAAOx/C,MAAO6gB,EAC5D,GC1EO,IAAMujC,GAA8B,CACzChgD,WAAYigD,UACZ//C,YAAa,MACbC,oBAhCEC,GAGK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA6/C,SAEP7kD,EAAiBgF,EAAG,WAEpB,IAAM+O,EAAQ/O,EAAEzD,MAAMrC,OAEhB4lD,EAAQzkD,OAAK6U,eAAe2vC,EAAM7/C,EAAEzD,OAC1C,GAAc,IAAVwS,EACF,OAAOtM,EAAS,CAACR,OAAQ,CAACjC,KAAIE,YAMhC,IAHA,IAAMqH,EAAS,IAAI2b,eAAaljB,EAAEzD,MAAOyD,EAAEzE,OACrC2L,EAAOhH,EAAQgyB,WAAWlyB,cAEvBxF,GACP,IAAM6d,EAAS9Q,EAAO9F,WAAWjH,GAC3B8d,EAAQD,EAAO1W,QACrBm+C,EAAM1kD,SAAQ,SAAApE,GAAK,OAAAshB,EAAMthB,GAAKgJ,EAAEzD,MAAMvF,GAAK,EAAIshB,EAAMthB,MACrDuQ,EAAOxK,UAAPwK,KAAWL,EAAKxK,UAALwK,IAAYoR,KAAWD,KAJ3B7d,EAAI,EAAGA,EAAI+M,EAAOT,KAAMtM,MAAxBA,GAOT,OAAO0F,EAAQ5B,eAAeiJ,EAAOhL,MAAOgL,EAAOhM,MAAOgM,EAAOjL,OACnE,GC7BayjD,GAAuC,CAClDpgD,WAAYqgD,mBACZngD,YAAa,MACbC,WAAY,SAACyD,GAiBX,QAjBYtB,WAAQyB,UAAOxD,YACpBq+B,UACA0hB,YAASC,cAAWC,WACrBlgD,EAAaC,EAEbkc,EAAS/gB,OAAK2F,uBAChBu9B,EAAMhjC,MAA0BF,OAAK8E,cAAco+B,EAAMhiC,QACvDmB,eAAC4kB,OAAOuc,OAAaC,OAAYC,OAEjCl5B,4CAACu6C,OAASC,OAIVC,EAAY9gD,KAAK+gD,IAAIN,GACrBO,EAAYhhD,KAAKu+B,IAAIkiB,GACrB5gB,EAAYp/B,EAAWrE,KAAKc,IAAI6hC,EAAM1hC,QAAQP,OAE3C0O,EAAW,EAAGA,EAAWsX,EAAOtX,IAGvC,IAFA,IAAMmjC,EAAcnjC,EAAW8zB,EAAaD,EAAcE,EAEjDn2B,EAAM,EAAGA,EAAMi2B,EAAaj2B,IAGnC,IAFA,IAAMwlC,EAAYxlC,GAAOk2B,EAAaC,GAE7Bj2B,EAAM,EAAGA,EAAMg2B,EAAYh2B,IAGlC,IAFA,IAAMulC,EAAYvlC,EAAMi2B,EAEf1P,EAAU,EAAGA,EAAU0P,EAAa1P,IAAW,CACtD,IAAMgmB,EAAS,CAAC/yB,EAAO1Z,EAAKE,EAAKumB,GAE3BrvB,EAAIq1C,EAAO,GACXt8C,EAAIs8C,EAAO,GAGb/G,GAAUtuC,EAAIogD,GAAWI,GAAaznD,EAAIsnD,GAAWC,EACrDG,GAAUzgD,EAAIogD,GAAWE,GAAavnD,EAAIsnD,GAAWG,EACzDlS,EAAS9uC,KAAKshC,MAAMwN,EAAS8R,GAC7BK,EAASjhD,KAAKshC,MAAM2f,EAASJ,GAE7B,IAAI7R,EAAc0R,EAUlB,GATyB,iBAAdA,IAEP1R,EADc,IAAZnf,EA7BW,IAgCC6wB,EAAU7wB,IAKxBif,GAAU,GAAKA,EAASxP,GAAc2hB,GAAU,GAChDA,EAAS5hB,EAMX2P,EAAcnP,EADV8O,EAHqBsS,GAAU3hB,EAAaC,GACvBuP,EAASvP,EAEsB1P,GAK1DjT,EADe+xB,EAAcC,EAAYC,EAAYhf,GACpCmf,EAOzB,MAAO,CAAC3xC,OADOoD,EAAW3C,MAAM8e,EAAQmiB,EAAMhiC,MAAOgiC,EAAMhjC,OAC3CgB,MAAOgiC,EAAMhiC,MAAOhB,MAAOgjC,EAAMhjC,SCtExCulC,GAAQn5B,EAAgB+4C,SAAO,SAACz4C,GAE3C,IAAM04C,EAAOnhD,KAAKoK,MAAM3B,GACxB,OAAIA,EAAK04C,EAAO,GACPnhD,KAAKoK,MAAM3B,GACTA,EAAK04C,EAAO,GACdnhD,KAAK0I,KAAKD,GAEb04C,EAAO,GAAQ,EACVA,EAEAA,EAAO,CAGpB,IAEaC,GAA4B,CACvCjhD,WAAY+gD,QACZ7gD,YAAa,MACbC,WAAYghC,ICKP,IAAM+f,GAAgC,CAC3ClhD,WAAYmhD,YACZjhD,YAAa,MACbC,oBA1BwBC,GAKjB,IAAAkC,WAAQ/B,YAASwD,UACjBwT,YAASC,YACT5a,UAEDgH,wCAAC4G,cAAWiN,eAAYhN,cAAWC,YAASkJ,eAO5ChM,EAAS0P,GAHI/W,EAAQgyB,WAA0Bhb,GAClChX,EAAQgyB,WAAoC/a,GAGnC5a,EAAOgX,EAAYnJ,EAAWgN,EACtDjN,EAAWE,EAAS,GAPD,GASvB,OAAOnK,EAAQ5B,eAAe/B,EAAOgL,EAAOhM,MAAOgM,EAAOjL,OAC5D,GCxBA,SAASykD,GAAWn/B,EAAmBzpB,GAIrC,IAHA,IAAI0pB,EAAO,EACPC,EAAQF,EAAM1nB,OACd8mD,EAAM,EACHn/B,EAAOC,GAERF,EADJo/B,EAAMxhD,KAAKoK,OAAOiY,EAAOC,GAAS,IACjB3pB,EACf0pB,EAAOm/B,EAAM,EAEbl/B,EAAQk/B,EAGZ,OAAOl/B,CACT,CAEA,SAASm/B,GAAWr/B,EAAmBzpB,GAIrC,IAHA,IAAI0pB,EAAO,EACPC,EAAQF,EAAM1nB,OACd8mD,EAAM,EACHn/B,EAAOC,GAERF,EADJo/B,EAAMxhD,KAAKoK,OAAOiY,EAAOC,GAAS,KAChB3pB,EAChB0pB,EAAOm/B,EAAM,EAEbl/B,EAAQk/B,EAGZ,OAAOl/B,CACT,CCLO,IAAMo/B,GAAmC,CAC9CvhD,WAAYwhD,eACZthD,YAAa,MACbC,oBAtB2BC,GAKpB,IAAAkC,WAAQ/B,YAASwD,UACjB09C,mBAAgB9kD,WAChB+kD,SAMDjlC,WDcJklC,EAA0BhlD,EAAoBikB,EAC9CghC,EAAmBC,EAAmBH,GAGxC,IAFA,IAAMjlC,EACF/gB,OAAKwM,kBAAkB,QAAS0Y,EAAYihC,GACvCvqD,EAAI,EAAGA,EAAIspB,IAAatpB,EAI/B,IAHA,IAAMwqD,EACFH,EAAa3/C,MAAM1K,EAAIsqD,GAAYtqD,EAAI,GAAKsqD,GAC1C/C,EAAevnD,EAAIuqD,EAChBhnD,EAAI,EAAGA,EAAIgnD,IAAahnD,EAC/B4hB,EAAOoiC,EAAehkD,GAAc,SAAT6mD,EACvBN,GAAWU,EAAmBnlD,EAAO9B,EAAIgkD,IACzCyC,GAAWQ,EAAmBnlD,EAAO9B,EAAIgkD,IAGjD,OAAOpiC,CACT,CC7BiBslC,CAHXxhD,EAAQtE,KAAKc,IAAI0kD,EAAevkD,QAAQP,OAC5B4D,EAAQtE,KAAKc,IAAIJ,EAAOO,QAAQP,OAGlB8kD,EAAe7kD,MAAM,GAC/C6kD,EAAe7kD,MAAM,GAAID,EAAOC,MAAM,GAAI8kD,GAC9C,OAAOnhD,EAAQ5B,eAAehC,EAAOC,MAAO,QAAS6f,EACvD,GCgBO,IAAMulC,GAA6B,CACxChiD,WAAYiiD,SACZ/hD,YAAa,MACbC,oBArCqBC,GAEd,IAAAkC,WAAQ/B,YACRlB,cAAWhG,MAAGV,MAErB0C,EAAiB,CAACgE,EAAWhG,EAAGV,GAAI,UAgBpC,IAfA,IAAMupD,EAAgB7iD,EAAUzC,MAAMrC,OAEhCoC,EAAS4D,EAAQtE,KAAKc,IAAIsC,EAAUnC,QAAQP,OAC5CwlD,EAAU5hD,EAAQtE,KAAKc,IAAI1D,EAAE6D,QAAQP,OACrCylD,EAAU7hD,EAAQtE,KAAKc,IAAIpE,EAAEuE,QAAQP,OACrCilC,EAAc5xB,aAAW3W,EAAEuC,MAAOjD,EAAEiD,OACpCmM,EACFrM,OAAKmH,oBAAoBnH,OAAK8E,cAAcnH,EAAEuD,OAAQglC,GAEtD/2B,EAAQ,EACNqC,EACgB,IAAlBg1C,GAAuBA,EAAgB,GAAwB,IAAnB7oD,EAAEuD,MAAMrC,OACpD,EACAmB,OAAK8E,cAAcnH,EAAEuD,MAAMoF,MAAM,IAE5BnH,EAAI,EAAGA,EAAI8B,EAAOpC,OAAQM,IACjC,IAAK,IAAIgN,EAAI,EAAGA,EAAIqF,EAAQrF,IACR,IAAdlL,EAAO9B,GACTkN,EAAU8C,KAAWs3C,EAAQtnD,GAE7BkN,EAAU8C,KAAWu3C,EAAQvnD,GAKnC,OAAO0F,EAAQ5B,eAAetF,EAAEuD,MAAOglC,EAAa75B,EACtD,GCjCMs6C,GAAarlD,eAAaslD,gBAC1BtuB,GAAQh3B,eAAaulD,WAEdC,GAAOx6C,EAAgBy6C,QAAM,SAACn6C,GACzC,OAAIA,GAAM,EACD0rB,GAAQ1rB,EAER+5C,IAAcxiD,KAAK4J,IAAInB,GAAM,EAExC,IAEao6C,GAA2B,CACtC1iD,WAAYyiD,OACZviD,YAAa,MACbC,WAAYqiD,ICdDlgC,GAAOta,EAAgB26C,QAAM,SAACr6C,GACzC,OAAIA,EAAK,GACC,EACCA,EAAK,EACP,EAEA,CAEX,IAEas6C,GAA2B,CACtC5iD,WAAY2iD,OACZziD,YAAa,MACbC,WAAYmiB,ICbDs+B,GAAM54C,EAAgB66C,OAAK,SAACv6C,GAAO,OAAAzI,KAAK+gD,IAAIt4C,MAE5Cw6C,GAA0B,CACrC9iD,WAAY6iD,MACZ3iD,YAAa,MACbC,WAAYygD,ICLDmC,GAAO/6C,EAAgBg7C,QAAM,SAAC16C,GAAO,OAAAzI,KAAKkjD,KAAKz6C,MAE/C26C,GAA2B,CACtCjjD,WAAYgjD,OACZ9iD,YAAa,MACbC,WAAY4iD,ICCRG,GAAYrjD,KAAKgN,IADP,uBACsB,EAEzBs2C,GAAWn7C,EAAgBo7C,YAAU,SAAC96C,GAGjD,IAAM+6C,EAAW/6C,GAAM46C,GAIjBI,EAAWh7C,EAAK46C,GAEhBK,EAAO1jD,KAAK4J,IAAInB,GAUtB,OAPIg7C,EACOC,EACAF,EACA/6C,EAEAzI,KAAKgN,IAAI,EAAM02C,EAG5B,IAEaC,GAA+B,CAC1CxjD,WAAYojD,WACZljD,YAAa,MACbC,WAAYgjD,IC8BP,IAAMM,GAAqC,CAChDzjD,WAAY0jD,iBACZxjD,YAAa,MACbC,oBA7D6BC,GAKtB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA60B,eAAYsgB,aAEnBn6C,EAAiB,CAACgF,GAAI,kBAEtB,IAAM+0B,EAAO15B,OAAK8E,cAAc00B,GAE1ByuB,EAA4C,CAAC,CAAC,EAAG,IACvDA,EAAiBnpD,WAAjBmpD,IAA0BnO,IAE1B,IAAK,IAAI36C,EAAI,EAAIq6B,EAAW36B,OAAQM,EAAIwF,EAAEzD,MAAMrC,SAAUM,EACxD8oD,EAAiBnpD,KAAK,CAAC,EAAG,IAG5B,IAAMopD,EAAU5J,GAAY75C,WAAW,CACrCmC,OAAQ,CAACjC,KACTE,UACAwD,MAAO,CAACyxC,SAAUmO,EAAkBzJ,cAAe,KAG/C2J,EACF7mD,eAAas4B,YAAYsuB,EAAQhnD,MAAOs4B,EAAYE,GAAM,GAExD0uB,EAAoC9mD,eAAaw4B,YACnDquB,EAAoBtpD,OAAQ26B,EAAW36B,QAAQ,GAE7Cod,EACF3a,eAAa04B,oBAAoBkuB,EAAQhnD,MAAOs4B,EAAYE,GAAM,GAIhE2uB,EACFpuC,GAAQ,CAACrT,OAHwB,CAACjC,EAAGujD,GAGLrjD,UAASwD,MAFV,CAACnH,MAAOinD,KAOrCG,EACFv0C,GAAU,CAACnN,OAJ0B,CAACjC,EAAG0jD,GAILxjD,UAASwD,MAF5B,CAACoL,KAAM20C,KAMtBjrD,EAAS8c,GACX,CAACrT,OAHsC,CAACjC,EAAG2jD,GAGbzjD,UAASwD,MAFF,CAACnH,MAAO+a,KAQjD,OAJApX,EAAQ2D,8BAA8B0/C,GACtCrjD,EAAQ2D,8BAA8B6/C,GACtCxjD,EAAQ2D,8BAA8B8/C,GAE/BnrD,CACT,GCXO,IAAMorD,GAA0C,CACrDjkD,WAAYkkD,sBACZhkD,YAAa,MACbC,oBAnDkCC,GAI3B,IAAAkC,WAAQ/B,YACRgX,YAAS5a,WAAQ2c,eAAYpI,iBACpC,GAAgC,IAA5BoI,EAAW1c,MAAMrC,OACnB,MAAM,IAAIkE,MAAM,+CACV6a,EAAW1c,OAEnB,GAA6B,IAAzB2a,EAAQ3a,MAAMrC,OAChB,MAAM,IAAIkE,MAAM,2CACV8Y,EAAQ3a,OAEhB,GAA4B,IAAxBD,EAAOC,MAAMrC,OACf,MAAM,IAAIkE,MAAM,0CACV9B,EAAOC,OAEf,GAAkC,IAA9BsU,EAAatU,MAAMrC,OACrB,MAAM,IAAIkE,MAAM,iDACVyS,EAAatU,OAGrB,IAAMunD,EAAW5jD,EAAQtE,KAAKc,IAAIwa,EAAQra,QAAQP,OAC5C+9C,EAAUn6C,EAAQtE,KAAKc,IAAIJ,EAAOO,QAAQP,OAC1CynD,EAAc7jD,EAAQtE,KAAKc,IAAIuc,EAAWpc,QAAQP,OAClDg+C,EACFp6C,EAAQtE,KAAKc,IAAImU,EAAahU,QAAQP,OAAO,GAE3CiH,2CAACgW,OAAeyqC,OAAoBxqC,OACnCJ,OAAmBC,OAI1B,MAAO,CACLnZ,EAAQ5B,eAAe0lD,EAAoB9sC,EAAQ3b,MAAOge,GAC1DrZ,EAAQ5B,eACJ,CAAC0lD,EAAmB,IAAK1nD,EAAOf,MAAOie,GAC3CtZ,EAAQ5B,eACJ,CAAC8a,EAAkBlf,QAAS,OAC5B,IAAIukB,WACArF,EAAkBhc,KAAI,SAACjF,GAAmB,OAAA4U,OAAO5U,QACzD+H,EAAQ5B,eACJ,CAAC+a,EAAgBnf,QAASgd,EAAQ3b,MAClC,IAAI4H,WAAWkW,IAEvB,GCVO,IAAM4qC,GAAoC,CAC/CtkD,WAAYukD,gBACZrkD,YAAa,MACbC,oBAtCEC,GAEK,IAAAkC,WAAQ/B,YACRma,iBAAcG,eAAY9Z,aACjC,GAAkC,IAA9B2Z,EAAa9d,MAAMrC,OACrB,MAAM,IAAIkE,MAAM,gEACVic,EAAa9d,OAErB,GAAgC,IAA5Bie,EAAWje,MAAMrC,OACnB,MAAM,IAAIkE,MAAM,8DACVoc,EAAWje,OAGnB,GAA8B,IAA1BmE,EAASnE,MAAMrC,OACjB,MAAM,IAAIkE,MACN,sDAAsDsC,EAASnE,OAGrE,IAAM4nD,EACF9sD,MAAM+L,KAAKlD,EAAQtE,KAAKc,IAAI8d,EAAW3d,QAAQP,QAC7C8nD,EACFlkD,EAAQtE,KAAKc,IAAI2d,EAAaxd,QAAQP,OACpCme,EACFpjB,MAAM+L,KAAKlD,EAAQtE,KAAKc,IAAIgE,EAAS7D,QAAQP,QAE3CiH,iCAACkY,OAAY1C,OAAcvE,OAGjC,MAAO,CACLtU,EAAQ5B,eAAeya,EAAcsB,EAAa9e,MAAOkgB,GACzDvb,EAAQ5B,eACJ,CAACkW,EAAYta,QAASwG,EAASnF,MAAO,IAAI4H,WAAWqR,IAE7D,GCJO,IAAM6vC,GAAwC,CACnD1kD,WAAY2kD,oBACZzkD,YAAa,MACbC,oBAhCEC,GAEK,IAAAkC,WAAQ/B,YACRtE,SAAMsb,YAASyE,eACtB,GAAI/f,EAAKW,MAAMrC,OAAS,EACtB,MAAM,IAAIkE,MACN,6DAEN,GAA6B,IAAzB8Y,EAAQ3a,MAAMrC,OAChB,MAAM,IAAIkE,MAAM,4DACR8Y,EAAQ3a,OAElB,GAAgC,IAA5Bof,EAAWpf,MAAMrC,OACnB,MAAM,IAAIkE,MAAM,gEACRud,EAAWpf,OAErB,GAAI2a,EAAQ3a,MAAM,KAAOof,EAAWpf,MAAM,GACxC,MAAM,IAAI6B,MAAM,iDAGlB,IAAMmmD,EAAQrkD,EAAQtE,KAAKc,IAAId,EAAKiB,QAAQP,OACtCwnD,EAAW5jD,EAAQtE,KAAKc,IAAIwa,EAAQra,QAAQP,OAC5CkoD,EAActkD,EAAQtE,KAAKc,IAAIif,EAAW9e,QAAQP,OAElDiH,oCAACkhD,OAAYC,OAEnB,OAAOxkD,EAAQ5B,eAAeomD,EAAiB9oD,EAAKL,MAAOkpD,EAC7D,GCEO,IAAME,GAAuC,CAClDhlD,WAAYilD,mBACZ/kD,YAAa,MACbC,oBAhCEC,GAEK,IAAAkC,WAAQ/B,YACRtE,SAAMsb,YAASyE,eACtB,GAAI/f,EAAKW,MAAMrC,OAAS,EACtB,MAAM,IAAIkE,MACN,6DAEN,GAA6B,IAAzB8Y,EAAQ3a,MAAMrC,OAChB,MAAM,IAAIkE,MAAM,2DACT8Y,EAAQ3a,OAEjB,GAAgC,IAA5Bof,EAAWpf,MAAMrC,OACnB,MAAM,IAAIkE,MAAM,+DACTud,EAAWpf,OAEpB,GAAI2a,EAAQ3a,MAAM,KAAOof,EAAWpf,MAAM,GACxC,MAAM,IAAI6B,MAAM,iDAGlB,IAAMmmD,EAAQrkD,EAAQtE,KAAKc,IAAId,EAAKiB,QAAQP,OACtCwnD,EAAW5jD,EAAQtE,KAAKc,IAAIwa,EAAQra,QAAQP,OAC5CkoD,EAActkD,EAAQtE,KAAKc,IAAIif,EAAW9e,QAAQP,OAElDiH,iCAACkhD,OAAYC,OAEnB,OAAOxkD,EAAQ5B,eAAeomD,EAAiB9oD,EAAKL,MAAOkpD,EAC7D,GC8BO,IAAMI,GAAoC,CAC/CllD,WAAYmlD,gBACZjlD,YAAa,MACbC,oBA9D4BC,GAKrB,IAUHwH,EAVGtF,WAAQ/B,YAASwD,UACjBqhD,kBAAeC,iBAAcn0C,iBAC7B2D,gBAEDjR,wCAAC4G,cAAWiN,eAAYhN,cAAWC,YAASkJ,eAE5C8D,GAAiB,EAEjBxM,EAAa3K,EAAQgyB,WAA0B6yB,GAGrD,OAAQC,EAAazpD,OACnB,IAAK,OAIHgM,EAAS0P,GACLpM,EAJe3K,EAAQgyB,WAAyB8yB,GAIxBxwC,EAAajB,EAAYnJ,EACjDgN,EAAYjN,EAAWE,EAHvB46C,QAAQ/kD,EAAQtE,KAAKc,IAAImU,EAAahU,QAAQP,OAAO,IAGN+a,GACnD,MAEF,IAAK,UASL,IAAK,QAIH9P,EAAS0P,GACLpM,EAJe3K,EAAQgyB,WAA0B8yB,GAIzBxwC,EAAajB,EAAYnJ,EACjDgN,EAAYjN,EAAWE,EAHvBnK,EAAQtE,KAAKc,IAAImU,EAAahU,QAAQP,OAAO,GAGE+a,GACnD,MAEF,IAAK,SAIH9P,EAAS0P,GACLpM,EAJe3K,EAAQgyB,WAA2B8yB,GAI1BxwC,EAAajB,EAAYnJ,EACjDgN,EAAYjN,EAAWE,EAJLhP,OAAK6C,aACvBgC,EAAQtE,KAAKc,IAAImU,EAAahU,QAAQP,OAAO,IAGE+a,GACnD,MAEF,QACE,MAAM,IAAIjZ,MAAM,oBAAoB4mD,EAAazpD,OAErD,OAAO2E,EAAQ5B,eAAekW,EAAajN,EAAOhM,MAAOgM,EAAOjL,OAClE,GClCO,IAAM4oD,GAA6B,CACxCvlD,WAAYwlD,SACZtlD,YAAa,MACbC,oBAxBEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACAolD,oBAAiBr1C,SAElBgT,EAAQ1nB,OAAK6U,eAAeH,EAAM/P,EAAEzD,OAAO,GAC3C8oD,EAAa1oD,eAAa2oD,iBAAiBtlD,EAAGolD,EAAiBriC,GAE/DjL,EAAQ,IAAIzgB,MAAM2I,EAAEzD,MAAMrC,QAAQgc,KAAK,GACvCpP,EAAO9G,EAAEzD,MAAMoF,QACrB,OAAO0jD,EAAWjoD,KAAI,SAAA9C,GACpB,IAAM8P,IAAgBtD,GACtBsD,EAAU2Y,GAASzoB,EACnB,IAAMirD,EACF5jD,GAAM,CAACM,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACoU,QAAOhR,KAAMsD,KAEtD,OADA0N,EAAMiL,IAAUzoB,EACTirD,IAEX,GCrBaC,GAA6B,CACxC7lD,WAAY8lD,SACZ5lD,YAAa,MACbC,WAAY,SAACyD,OAACtB,WAAQ/B,YACbF,MACDC,EAAaC,EACnBlF,EAAiBgF,EAAG,UAIpB,IAFA,IAAM1D,EAAS2D,EAAWrE,KAAKc,IAAIsD,EAAEnD,QAAQP,OACvCoL,EAAY,IAAInI,aAAajD,EAAOpC,QACjCM,EAAI,EAAGA,EAAI8B,EAAOpC,SAAUM,EAAG,CACtC,IAAMrC,EAAQmE,EAAO9B,GACrBkN,EAAUlN,GAAKrC,EAAQA,EAGzB,MAAO,CAAC0E,OADOoD,EAAW3C,MAAMoK,EAAW1H,EAAEzD,MAAOyD,EAAEzE,OACtCgB,MAAOyD,EAAEzD,MAAOhB,MAAOyE,EAAEzE,SChBhCnD,GAAOuP,EAAgB+9C,QAAM,SAACz9C,EAAIvE,GAC7C,IAAMiiD,EAAYjiD,EAClB,OAAIsJ,MAAM/E,GACD29C,IAEA39C,EAAK,EAAI,EAAI09C,EAAUxhC,KAElC,IAEa0hC,GAA2B,CACtClmD,WAAY+lD,OACZ7lD,YAAa,MACbC,WAAY1H,ICuDP,IAAM0tD,GAAmC,CAC9CnmD,WAAYomD,eACZlmD,YAAa,MACbC,oBAlE2BC,GAKpB,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAEL8X,UACAuE,QACAhS,YACA27C,cACAC,YACAC,iBACAC,gBACAC,mBAGFprD,EAAiBgF,EAAG,gBAEd,IAcFxH,EAdE+K,kDACJ8iD,qBACAC,eACAC,eACAC,cACAC,kBACAhuC,UACAiuC,QACAC,YAUF,GAAIJ,EAEF/tD,EAAS8c,GAAQ,CAACrT,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACnH,MAAO+pD,UAClD,GAAIE,GAAaC,EAAe,CAErCprD,OAAKC,OACD0E,EAAEzD,MAAMrC,QAAU,GAClB,WAAM,MAAA,yCAAyC8F,EAAEzD,MAAMrC,UAE3D,IAAM4M,EAAOkR,aAAWqf,gBAAgB5e,EAAQiuC,EAAMC,GAEhDC,EAASjlD,GAAM,CAACM,OAAQ,CAACjC,KAAIE,UAASwD,MAAO,CAACoU,MAAOW,EAAQ3R,UACnEtO,EACI8c,GAAQ,CAACrT,OAAQ,CAACjC,EAAG4mD,GAAS1mD,UAASwD,MAAO,CAACnH,MAAO+pD,KAC1DpmD,EAAQ2D,8BAA8B+iD,OACjC,CACL,IACMr/C,EAAS6V,GAAiBipC,EADnBnmD,EAAQgyB,WAA4BlyB,GACO2mD,EAAUluC,GAElEjgB,EAAS0H,EAAQ5B,eAAegoD,EAAY/+C,EAAOhM,MAAOgM,EAAOjL,QAGnE,OAAO9D,CACT,GCpCO,IAAMquD,GAAmC,CAC9ClnD,WAAYmnD,eACZjnD,YAAa,MACbC,oBA9B2BC,GAKpB,IAAAkC,WAAQ/B,YAASwD,UAEtB2Z,cACAC,gBACAC,YACAC,aACAC,aACAC,2BAEK9hB,SAAMkkB,eAIPvc,OAHQrD,EAAQtE,KAAKc,IAAId,EAAKiB,QAAQP,OACxB4D,EAAQtE,KAAKc,IAAIojB,EAAWjjB,QAAQP,uBAEjDkjB,OAAQJ,OAGf,MAAO,CACLlf,EAAQ5B,eAAe,CAACkhB,EAAOtlB,QAAS,SAAUslB,GAClDtf,EAAQ5B,eAAewhB,EAAWvjB,MAAO,QAAS6iB,GAEtD,GCQO,IAAM2nC,GAAkC,CAC7CpnD,WAAYqnD,cACZnnD,YAAa,MACbC,oBApC0BC,GAKnB,IAAAkC,WAAQ/B,YACR+f,oBACApd,UAAOwd,cAEd,GAAoB,WAAhBxd,EAAMtH,MACR,MAAM,IAAI6C,MAAM,oCAElB,GAA2B,IAAvByE,EAAMtG,MAAMrC,OACd,MAAM,IAAIkE,MAAM,sCAAsCyE,EAAMtG,OAE9D,GAA+B,IAA3B8jB,EAAU9jB,MAAMrC,OAClB,MAAM,IAAIkE,MACN,0CAA0CiiB,EAAU9jB,OAG1D,IAGMgH,OAHSrD,EAAQtE,KAAKc,IAAImG,EAAMhG,QAAQP,OAC3B4D,EAAQtE,KAAKc,IAAI2jB,EAAUxjB,QAAQP,OAAO,SAEtD4a,OAAS5a,OAAQC,OAElBgX,EAAajX,EAAOpC,OAC1B,MAAO,CACLgG,EAAQ5B,eAAe,CAACiV,EAAY,GAAI,QAAS2D,GACjDhX,EAAQ5B,eAAe,CAACiV,GAAa,SAAUjX,GAC/C4D,EAAQ5B,eAAe,CAAC,GAAI,QAAS,IAAI6E,WAAW5G,IAExD,GCTO,IAAM0qD,GAA6C,CACxDtnD,WAAYunD,yBACZrnD,YAAa,MACbC,oBAzBqCC,GAK9B,IAAAkC,WAAQ/B,YACR4gB,qBACAje,UAEP,GAAoB,WAAhBA,EAAMtH,MACR,MAAM,IAAI6C,MAAM,oCAElB,GAAI0iB,GAAc,EAChB,MAAM,IAAI1iB,MAAM,wCAGlB,IAEMge,EAASyE,GAFA3gB,EAAQtE,KAAKc,IAAImG,EAAMhG,QAAQP,OAEIwkB,GAClD,OAAO5gB,EAAQ5B,eAAeuE,EAAMtG,MAAO,QAAS6f,EACtD,GCtBa+qC,GAAMx/C,EAAgBy/C,OAAK,SAACn/C,GAAO,OAAAzI,KAAK2nD,IAAIl/C,MAE5Co/C,GAA0B,CACrC1nD,WAAYynD,MACZvnD,YAAa,MACbC,WAAYqnD,ICLDG,GAAO3/C,EAAgB4/C,QAAM,SAACt/C,GAAO,OAAAzI,KAAK8nD,KAAKr/C,MAE/Cu/C,GAA2B,CACtC7nD,WAAY4nD,OACZ1nD,YAAa,MACbC,WAAYwnD,ICUP,IAAMG,GAA2B,CACtC9nD,WAAY+nD,OACZ7nD,YAAa,MACbC,oBAfEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACAwhB,SAEPxmB,EAAiBgF,EAAG,QACpB,IAAMuH,EAASga,GAASrhB,EAAQgyB,WAAWlyB,GAAIwhB,GAE/C,OAAOthB,EAAQ5B,eAAeiJ,EAAOhL,MAAOgL,EAAOhM,MAAOgM,EAAOjL,OACnE,GCUO,IAAMqrD,GAA2B,CACtChoD,WAAYioD,OACZ/nD,YAAa,MACbC,oBAvBEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MACA2K,MAAGyX,WAEVpnB,EAAiBgF,EAAG,QAEpB,IACMuD,OADQrD,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,+BAClCimB,OAAaC,OAGpB,MAAO,CACLtiB,EAAQ5B,eACJikB,EAAYhmB,MAAOgmB,EAAYhnB,MAAOgnB,EAAYjmB,QACtD4D,EAAQ5B,eACJkkB,EAAejmB,MAAOimB,EAAejnB,MAAOinB,EAAelmB,QAEnE,GC2EO,IAAMurD,GAAgC,CAC3CloD,WAAYmoD,YACZjoD,YAAa,MACbC,oBAnGwBC,GAKjB,IAAAkC,WAAQyB,UAAOxD,YACfq+B,UAAOwpB,eACPC,kBAAeC,aAAU/H,cAAW1rC,gBAErCjR,eAAC+e,OAAOuc,OAAaC,OAAYC,OACjCrhC,uBAACyvB,OAAWO,OAEZplB,EAAW,CAACga,EAAO6K,EAAWO,EAAUqR,GAExCmpB,EAAY7sD,OAAKyF,eAAey9B,EAAMhiC,OACtC4rD,EAAgBD,EAAU,GAC1BE,EAAcF,EAAU,GACxBG,EAAcH,EAAU,GAExBI,EAAajtD,OAAKyF,eAAewH,GACjCigD,EAAiBD,EAAW,GAC5BE,EAAeF,EAAW,GAC1BG,EAAeH,EAAW,GAE1BthD,EAAU3L,OAAK2F,uBACjBu9B,EAAMhjC,MAA0BF,OAAK8E,cAAcmI,IAEvDtB,EAAQkP,KAAKgqC,GAQb,IANA,IAAM7gB,EAAYn/B,EAAQtE,KAAKc,IAAI6hC,EAAM1hC,QAAQP,OAC3CosD,EACFxoD,EAAQtE,KAAKc,IAAIqrD,EAAWlrD,QAAQP,OAI/BrF,EAAI,EAAGA,EAAIqrB,IAASrrB,EAAG,CAK9B,IAJA,IAAM0xD,EAAoC,IAAxBZ,EAAWxrD,MAAM,GAC/BmsD,EACAA,EAAc1yC,SAAa,EAAJ/e,EAAW,EAAJA,EAAQ,GAEjC2xD,EAAO,EAAGA,EAAOz7B,IAAay7B,EACrC,IAAK,IAAIC,EAAO,EAAGA,EAAOn7B,IAAYm7B,EACpC,IAAK,IAAIx5B,EAAU,EAAGA,EAAU0P,IAAe1P,EAAS,CACtD,IAAIyV,SAEEgkB,EAAaH,EAAU,GAAKE,EAAOF,EAAU,GAAKC,EAAO,EAE/D,GAAmB,IAAfE,EAAJ,CAMA,IAAMC,GACDJ,EAAU,GAAKE,EAAOF,EAAU,GAAKC,EAAOD,EAAU,IACvDG,EACEE,GACDL,EAAU,GAAKE,EAAOF,EAAU,GAAKC,EAAOD,EAAU,IACvDG,EAEE9oD,EAAIipD,GAASF,EAAKjqB,EAAYmpB,GAC9BlvD,EAAIkwD,GAASD,EAAKnqB,EAAaopB,GAErC,OAAQD,GACN,IAAK,UACHljB,EAAMokB,GACF7pB,EAAWR,EAAaC,EAAYqpB,EACpCC,EAAaC,EAAapxD,EAAG8B,EAAGiH,EAAGqvB,EAAS6wB,GAChD,MACF,IAAK,WACHpb,EAAMqkB,GACF9pB,EAAWR,EAAaC,EAAYqpB,EACpCC,EAAaC,EAAapxD,EAAG8B,EAAGiH,EAAGqvB,EAAS6wB,GAChD,MACF,QACE,MAAM,IAAI9hD,MACN,+DACuB4pD,GAO/BhhD,EAHI/P,EAAIsxD,EAAiBK,EAAOJ,EAC5BK,EAAOJ,EAAep5B,GAEXyV,GAKrB,OAAO5kC,EAAQ5B,eAAegK,EAAUi2B,EAAMhjC,MAAOyL,GAIvD,MAAO,CAACnK,OADOqD,EAAQ5C,MAAM0J,EAASsB,EAAUi2B,EAAMhjC,OACtCgB,MAAOgiC,EAAMhiC,MAAOhB,MAAOgjC,EAAMhjC,MACnD,GAQA,SAAS0tD,GACLG,EAAkBC,EAClBjU,GACF,OAAQA,GACN,IAAK,UACH,OAWN,SAAyBgU,EAAkBC,GAEzC,IAAIC,EAAUF,EACd,GAAIE,EAAU,EAAG,CACf,GAAID,GAAO,EACTC,EAAU,OAGNA,GADEC,EAAM,EAAIF,KAEdC,EAAUC,EAAM/pD,KAAK2b,OAAOmuC,EAAUC,GAAOD,GAE/CA,EAAUA,GAAWD,EAAMC,EAAUC,GAAOD,EAAU,OAEnD,GAAIA,EAAUD,EAAM,EAAG,CAI1B,IAAME,EAHR,GAAIF,GAAO,EACTC,EAAU,OAGVA,IADMC,EAAM,EAAIF,GACC7pD,KAAK2b,MAAMmuC,EAAUC,KACvBF,IACbC,EAAUC,EAAMD,EAAU,GAMhC,OAAOjuD,OAAKmuD,MAAM,EAAGF,EAASD,EAAM,EACtC,CAtCaI,CAAgBL,EAAUC,GACnC,IAAK,OACH,OAsCN,SAAsBD,EAAkBC,GAEtC,IAAIC,EAAUF,EACd,GAAIE,EAAU,EACZ,GAAID,GAAO,EACTC,EAAU,MACL,CACL,IAAMI,EAAKL,EAAM,EACjBC,GAAWD,GAAO7pD,KAAK2b,OAAOmuC,EAAUI,GAAM,QAE3C,GAAIJ,EAAUD,EAAM,EACzB,GAAIA,GAAO,EACTC,EAAU,MACL,CACCI,EAAKL,EAAM,EACjBC,GAAWD,EAAM7pD,KAAK2b,MAAMmuC,EAAUI,GAK1C,OAAOruD,OAAKmuD,MAAM,EAAGF,EAASD,EAAM,EACtC,CA3DaM,CAAaP,EAAUC,GAChC,IAAK,UACH,OA+DN,SAAyBD,EAAkBC,GACzC,OAAOhuD,OAAKmuD,MAAM,EAAGJ,EAAUC,EAAM,EACvC,CAjEaO,CAAgBR,EAAUC,GAEnC,QACE,OAwDN,SAA0BD,EAAkBC,GAC1C,OAAOD,CACT,CA1DaS,CAAiBT,GAE9B,CA8DA,SAASU,GACLzqB,EAAuBR,EAAqBC,EAC5CirB,EAAqBC,EAAmBC,EAAmB3nC,EAC3DvpB,EAAWiH,EAAWqvB,EAAiB6wB,GAEzC,OAAI,GAAKnnD,GAAKA,EAAI8lC,GAAe,GAAK7+B,GAAKA,EAAI8+B,EACtCO,EAFG/c,EAAQynC,EAAchxD,EAAIixD,EAAYhqD,EAAIiqD,EAAY56B,GAIzD6wB,CAEX,CAEA,SAASgJ,GACL7pB,EAAuBR,EAAqBC,EAC5CirB,EAAqBC,EAAmBC,EAAmB3nC,EAC3DvpB,EAAWiH,EAAWqvB,EAAiB6wB,GAIzC,OAAO4J,GACHzqB,EAAWR,EAAaC,EAAYirB,EAAaC,EAAWC,EAC5D3nC,EALO9iB,KAAKshC,MAAM/nC,GACXyG,KAAKshC,MAAM9gC,GAIHqvB,EAAS6wB,EAC9B,CAEA,SAASiJ,GACL9pB,EAAuBR,EAAqBC,EAC5CirB,EAAqBC,EAAmBC,EAAmB3nC,EAC3DvpB,EAAWiH,EAAWqvB,EAAiB6wB,GACzC,IAAMgK,EAAS1qD,KAAKoK,MAAM7Q,GACpBoxD,EAAS3qD,KAAKoK,MAAM5J,GACpBoqD,EAAQF,EAAS,EACjBG,EAAQF,EAAS,EAyBvB,OAAQC,EAAQrxD,KArBXsxD,EAAQrqD,GACL8pD,GACIzqB,EAAWR,EAAaC,EAAYirB,EAAaC,EACjDC,EAAW3nC,EAAO4nC,EAAQC,EAAQ96B,EAAS6wB,IAClDlgD,EAAImqD,GACDL,GACIzqB,EAAWR,EAAaC,EAAYirB,EAAaC,EACjDC,EAAW3nC,EAAO4nC,EAAQG,EAAOh7B,EAAS6wB,KAclBnnD,EAAImxD,KAVnCG,EAAQrqD,GACL8pD,GACIzqB,EAAWR,EAAaC,EAAYirB,EAAaC,EACjDC,EAAW3nC,EAAO8nC,EAAOD,EAAQ96B,EAAS6wB,IACjDlgD,EAAImqD,GACDL,GACIzqB,EAAWR,EAAaC,EAAYirB,EAAaC,EACjDC,EAAW3nC,EAAO8nC,EAAOC,EAAOh7B,EAAS6wB,GAIvD,CCvNO,IAAMoK,GAA6B,CACxC3qD,WAAY4qD,SACZ1qD,YAAa,MACbC,oBAnBEC,GAEK,IAAAkC,WAAQyB,UAAOxD,YACf6P,SACA/P,MACPhF,EAAiBgF,EAAG,UAEpB,IACMuD,KADSrD,EAAQtE,KAAKc,IAAIsD,EAAEnD,QAAQP,0BACnCkd,iBAAchF,gBAAa0C,YAElC,MAAO,CACLhX,EAAQ5B,eAAekW,EAAaxU,EAAEzE,MAAOie,GAC7CtZ,EAAQ5B,eAAe,CAAC4Y,EAAQhd,QAAS,QAASgd,GAEtD,GCoBO,IAAMszC,GAA6B,CACxC7qD,WAAY8qD,SACZ5qD,YAAa,MACbC,oBAtCEC,GAEK,IAAAkC,WAAQ/B,YAASwD,UACjBvL,UACF4X,SAEDA,EAAO,IACTA,GAAQ5X,EAAMoE,MAAMrC,QAQtB,IALA,IAAMwwD,EAAYvyD,EAAMoE,MAAMrC,OAExBoS,EAAMnU,EAAMoE,MAAMwT,GAClBzH,EAAqB,IAAIjR,MAAMqzD,EAAY,GAC7CnuC,EAAW,EACN/hB,EAAI,EAAGA,EAAIkwD,EAAWlwD,IACzBA,IAAMuV,IACRzH,EAASiU,KAAcpkB,EAAMoE,MAAM/B,IAIvC,IAAMsd,EAAQ,IAAIzgB,MAAMqzD,GAAWx0C,KAAK,GAClCpP,EAAO3O,EAAMoE,MAAMoF,QACzBmF,EAAKiJ,GAAQ,EACb,IAAMvB,EAAM,IAAInX,MAAMiV,GACtB,IAAS9R,EAAI,EAAGA,EAAIgU,EAAItU,OAAQM,IAAK,CACnCsd,EAAM/H,GAAQvV,EACd,IAAMmwD,EAAUhpD,GAAM,CAACM,OAAQ,CAACjC,EAAG7H,GAAQ+H,UAASwD,MAAO,CAACoU,QAAOhR,UACnE0H,EAAIhU,GAAK8a,GAAQ,CAACrT,OAAQ,CAACjC,EAAG2qD,GAAUzqD,UAASwD,MAAO,CAACnH,MAAO+L,KAChEpI,EAAQ2D,8BAA8B8mD,GAGxC,OAAOn8C,CACT,GCyBO,UAAMo8C,GAAyC,CACpDjrD,WAAYkrD,qBACZhrD,YAAa,MACbC,oBAzDiCC,GAK1B,IAAAkC,WAAQ/B,YAASwD,UACjB1D,MAAG2b,eACHmvC,gBAEP9vD,EAAiBgF,EAAG,sBAYpB,IAVA,IAEMwO,EAAM,GACNoa,EAA8B,GAI9BmiC,EAPQ/qD,EAAEzD,MAAMrC,OACCyhB,EAAWpf,MAAMrC,OAOpCsqD,EAAc7oC,EAETnhB,EAAI,EAAGA,EAAIuwD,IAAYvwD,EAAG,CACjC,IAAMwwD,EAAW5iB,GACb,CAACnmC,OAAQ,CAACY,MAAO2hD,GAActkD,UAASwD,MAAO,CAACgH,IAAKlQ,EAAI,KAC7DgqD,EAAcwG,EACdpiC,EAAczuB,KAAK6wD,GAGrB,IAASxwD,EAAI,EAAGA,EAAIswD,IAAetwD,EAAG,CACpC,IAAMywD,EAAc5vD,OAAKgT,kBAAkB7T,EAAoB,SACzD0wD,EAAYhrD,EAAQ5B,eAAe,GAAI,QAAS2sD,GAChDlX,EACF/qC,EAAM,CAAC/G,OAAQ,CAACuC,EAAG0mD,EAAWj0D,EAAGutD,GAActkD,YAC7CirD,EACF1nD,EAAK,CAACxB,OAAQ,CAACjC,EAAG+zC,GAAO7zC,UAASwD,MAAO,CAACnI,MAAO,aAC/C6vD,EACFt9C,GAAS,CAAC7L,OAAQ,CAACuC,EAAG2mD,EAAYl0D,EAAG+I,GAAIE,YACvCmrD,EACFpjC,GAAI,CAAChmB,OAAQ,CAACjC,EAAGorD,GAAMlrD,UAASwD,MAAO,CAACqM,KAAM,EAAGC,UAAU,KAC/DxB,EAAIrU,KAAKkxD,GACTziC,EAAczuB,KAAK+wD,GACnBtiC,EAAczuB,KAAK45C,GACnBnrB,EAAczuB,KAAKgxD,GACnBviC,EAAczuB,KAAKixD,GACnBxiC,EAAczuB,KAAKkxD,GAGrB,IAAM7yD,EAAS8gD,GAAK,CAACr3C,OAAQuM,EAAKtO,UAASwD,MAAO,CAACqM,KAAM,KAIzD,OAFA6Y,EAAcxtB,SAAQ,SAAApC,GAAK,OAAAkH,EAAQ2D,8BAA8B7K,MAE1DR,CACT,GC6GM8yD,GAAgC,CACpChjC,GACA5oB,EACAspB,GACAG,GACA3iB,EACA4iB,GACAI,GACAQ,GACAG,GACAI,GACAK,GACAG,GACAG,GACAI,GACAG,GACAkF,GACAY,GACAI,GACAqB,GACA5K,GACAqL,GACAkB,GACAiB,GACAG,GACA7xB,EACAkE,EACAuuB,GACAt0B,EACAu0B,GACAuB,GACA+B,GACAE,GACAU,GACAW,GACAW,GACAmB,GACAU,GACAG,GACAC,GACA6C,GACAY,GACAE,GACAE,GACAoB,GACAE,GACAG,GACAE,GACAE,GACAgB,GACAS,GACAQ,GACA/hB,GACAmjB,GACAl+B,EACAi/B,GACA7+B,EACAg/B,GACA5+B,EACA8jC,GACAO,GACAE,GACAnkC,EACA8kC,GACAC,GACAK,GACAE,GACAG,GACAhkC,GACAI,GACAhJ,EACA0tC,GACAlZ,GACAsZ,GACAI,GACAE,GACA3sB,GACArY,GACAI,GACA6kC,GACAtkC,GACA0kC,GACAI,GACAG,GACAI,GACAC,GACAW,GACAU,GACA/lC,GACAimC,GACAE,GACAE,GACAK,GACAE,GACAO,GACAK,GACAnnC,GACAsnC,GACAU,GACAW,GACAtoC,GACAM,GACAgpC,GACAU,GACAK,GACAzpC,GACA6pC,GACAU,GACAM,GACAE,GACAM,GACAx1B,GACA5U,GACAqqC,GACAM,GACAz3C,EACA4lC,GACAiS,GACA/1B,GACAG,GACAS,GACAo1B,GACA6B,GACA4B,GACAM,GACAe,GACAI,GACAa,GACA5pC,GACA6pC,GACAK,GACAS,GACAU,GACAzqC,GACA2qC,GACAE,GACAG,GACAhqC,GACAw9B,GACA+M,GACAC,GACAQ,GACAK,GACAI,GACAM,GACAE,GACAK,GACApoC,GACA0oC,GACAroC,GACA0oC,GACAC,GACAe,GACAE,GACAE,GACA3lC,GACAwkB,GACAuhB,GACAG,GACAC,GACAE,GACAE,GACAx4C,GACAi7C,GACAE,GACAI,GACA3R,QAGF,IAA2B,IAAAsS,GAAAj1C,EAAAg1C,uCAAe,CAArC,IAAME,YACTC,iBAAeD,4JCpWD"}